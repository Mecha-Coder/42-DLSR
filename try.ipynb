{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "add4e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dataset/dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33795772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1600)\n",
      "['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin']\n",
      "1600 7 4\n"
     ]
    }
   ],
   "source": [
    "courses = ['Astronomy', 'Herbology', 'Divination', 'Muggle Studies', \n",
    "            'Ancient Runes', 'History of Magic', 'Transfiguration']\n",
    "\n",
    "features = data[courses]\n",
    "features = np.array(features.fillna(features.median()))\n",
    "features = features.T\n",
    "x_test = features\n",
    "\n",
    "houses = sorted(list(set(data[\"Hogwarts House\"])))\n",
    "\n",
    "m = features.shape[1]\n",
    "n = features.shape[0]\n",
    "k = len(houses)\n",
    "\n",
    "print(features.shape)\n",
    "print(houses)\n",
    "print(m,n, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1944798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "(7, 1)\n",
      "[[  44.2069772 ]\n",
      " [   1.18903438]\n",
      " [   3.18974313]\n",
      " [-228.8462294 ]\n",
      " [ 495.05169614]\n",
      " [   3.00112491]\n",
      " [1030.42440995]]\n",
      "[[515.82921406]\n",
      " [  5.17451398]\n",
      " [  4.10928909]\n",
      " [481.68392363]\n",
      " [105.18574767]\n",
      " [  4.37049142]\n",
      " [ 43.69638037]]\n"
     ]
    }
   ],
   "source": [
    "mean = np.sum(features, axis=1, keepdims=True) / m\n",
    "\n",
    "variance = np.sum((features - mean) ** 2, axis=1, keepdims=True) / m\n",
    "std = np.sqrt(variance)\n",
    "\n",
    "x_train = (features - mean) / std\n",
    "\n",
    "print(mean.shape)\n",
    "print(std.shape)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b018d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x, b):\n",
    "    z = np.dot(w.T, x) + b\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def train(x, y, alpha=0.1, iter=10000000, limit=0.0000001):\n",
    "    \n",
    "    m = x.shape[1]\n",
    "    n = x.shape[0]\n",
    "\n",
    "    w = np.zeros((n, 1))\n",
    "    b = 0\n",
    "\n",
    "    for i in range(iter):\n",
    "        p = predict(w, x, b)\n",
    "        loss = -(1/m) * np.sum(y*np.log(p) + (1-y)*np.log(1-p))\n",
    "        \n",
    "        if (i % 1000 == 0):\n",
    "            print(f\"Iteration: {i} | Loss: {loss}\")\n",
    "\n",
    "        step_w = alpha * (1/m) * np.dot(x, (p - y).T)\n",
    "        step_b = alpha * (1/m) * np.sum(p - y)\n",
    "\n",
    "        w = w - step_w\n",
    "        b = b - step_b\n",
    "\n",
    "        if (np.all(np.abs(step_w)) <= limit and np.abs(step_b) <= limit):\n",
    "            print(\"Converge\")\n",
    "            break\n",
    "\n",
    "    print(\"Didn't converge\")\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2809bd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for Gryffindor house\n",
      "Iteration: 0 | Loss: 0.6931471805599452\n",
      "Iteration: 1000 | Loss: 0.05017321837648034\n",
      "Iteration: 2000 | Loss: 0.0481850924282886\n",
      "Iteration: 3000 | Loss: 0.04750567113658663\n",
      "Iteration: 4000 | Loss: 0.047136617341936624\n",
      "Iteration: 5000 | Loss: 0.046908502349019714\n",
      "Iteration: 6000 | Loss: 0.04676116604839823\n",
      "Iteration: 7000 | Loss: 0.046664073094424253\n",
      "Iteration: 8000 | Loss: 0.04659925677085795\n",
      "Iteration: 9000 | Loss: 0.04655550864222947\n",
      "Iteration: 10000 | Loss: 0.04652566003898576\n",
      "Iteration: 11000 | Loss: 0.046505067127420724\n",
      "Iteration: 12000 | Loss: 0.046490695180440404\n",
      "Iteration: 13000 | Loss: 0.04648054539355112\n",
      "Iteration: 14000 | Loss: 0.04647329062969511\n",
      "Iteration: 15000 | Loss: 0.046468042130740565\n",
      "Iteration: 16000 | Loss: 0.04646419926653932\n",
      "Iteration: 17000 | Loss: 0.04646135223056141\n",
      "Iteration: 18000 | Loss: 0.04645921863840501\n",
      "Iteration: 19000 | Loss: 0.04645760193297889\n",
      "Iteration: 20000 | Loss: 0.04645636389064299\n",
      "Iteration: 21000 | Loss: 0.04645540630203447\n",
      "Iteration: 22000 | Loss: 0.046454658663775364\n",
      "Iteration: 23000 | Loss: 0.04645406983780009\n",
      "Iteration: 24000 | Loss: 0.046453602350220495\n",
      "Iteration: 25000 | Loss: 0.04645322846039569\n",
      "Iteration: 26000 | Loss: 0.04645292742689797\n",
      "Iteration: 27000 | Loss: 0.04645268358936531\n",
      "Iteration: 28000 | Loss: 0.04645248501104523\n",
      "Iteration: 29000 | Loss: 0.046452322509768655\n",
      "Iteration: 30000 | Loss: 0.046452188960171725\n",
      "Iteration: 31000 | Loss: 0.04645207878684657\n",
      "Iteration: 32000 | Loss: 0.046451987592952\n",
      "Iteration: 33000 | Loss: 0.04645191188569602\n",
      "Iteration: 34000 | Loss: 0.0464518488716491\n",
      "Iteration: 35000 | Loss: 0.0464517963027982\n",
      "Iteration: 36000 | Loss: 0.04645175235977183\n",
      "Iteration: 37000 | Loss: 0.04645171556251478\n",
      "Iteration: 38000 | Loss: 0.0464516847014014\n",
      "Iteration: 39000 | Loss: 0.04645165878369028\n",
      "Iteration: 40000 | Loss: 0.046451636991588836\n",
      "Iteration: 41000 | Loss: 0.0464516186491741\n",
      "Iteration: 42000 | Loss: 0.04645160319612237\n",
      "Iteration: 43000 | Loss: 0.046451590166714504\n",
      "Iteration: 44000 | Loss: 0.046451579172958085\n",
      "Iteration: 45000 | Loss: 0.046451569890946176\n",
      "Iteration: 46000 | Loss: 0.04645156204977681\n",
      "Iteration: 47000 | Loss: 0.046451555422512066\n",
      "Iteration: 48000 | Loss: 0.04645154981877049\n",
      "Iteration: 49000 | Loss: 0.046451545078636074\n",
      "Iteration: 50000 | Loss: 0.04645154106763189\n",
      "Iteration: 51000 | Loss: 0.046451537672561355\n",
      "Iteration: 52000 | Loss: 0.046451534798056304\n",
      "Iteration: 53000 | Loss: 0.046451532363706534\n",
      "Iteration: 54000 | Loss: 0.0464515303016667\n",
      "Iteration: 55000 | Loss: 0.04645152855465753\n",
      "Iteration: 56000 | Loss: 0.04645152707429389\n",
      "Iteration: 57000 | Loss: 0.0464515258196839\n",
      "Iteration: 58000 | Loss: 0.04645152475625343\n",
      "Iteration: 59000 | Loss: 0.04645152385475864\n",
      "Iteration: 60000 | Loss: 0.04645152309045577\n",
      "Iteration: 61000 | Loss: 0.04645152244240222\n",
      "Iteration: 62000 | Loss: 0.04645152189286767\n",
      "Iteration: 63000 | Loss: 0.04645152142683763\n",
      "Iteration: 64000 | Loss: 0.04645152103159493\n",
      "Iteration: 65000 | Loss: 0.04645152069636565\n",
      "Iteration: 66000 | Loss: 0.04645152041202101\n",
      "Iteration: 67000 | Loss: 0.046451520170824524\n",
      "Iteration: 68000 | Loss: 0.04645151996621918\n",
      "Iteration: 69000 | Loss: 0.0464515197926465\n",
      "Iteration: 70000 | Loss: 0.04645151964539413\n",
      "Iteration: 71000 | Loss: 0.046451519520466694\n",
      "Iteration: 72000 | Loss: 0.046451519414476186\n",
      "Iteration: 73000 | Loss: 0.04645151932454969\n",
      "Iteration: 74000 | Loss: 0.04645151924825054\n",
      "Iteration: 75000 | Loss: 0.04645151918351224\n",
      "Iteration: 76000 | Loss: 0.046451519128582\n",
      "Iteration: 77000 | Loss: 0.046451519081973036\n",
      "Iteration: 78000 | Loss: 0.046451519042424054\n",
      "Iteration: 79000 | Loss: 0.046451519008865266\n",
      "Iteration: 80000 | Loss: 0.04645151898038888\n",
      "Iteration: 81000 | Loss: 0.04645151895622502\n",
      "Iteration: 82000 | Loss: 0.046451518935720276\n",
      "Iteration: 83000 | Loss: 0.04645151891832038\n",
      "Iteration: 84000 | Loss: 0.04645151890355513\n",
      "Iteration: 85000 | Loss: 0.04645151889102546\n",
      "Iteration: 86000 | Loss: 0.0464515188803928\n",
      "Iteration: 87000 | Loss: 0.04645151887136985\n",
      "Iteration: 88000 | Loss: 0.046451518863712904\n",
      "Iteration: 89000 | Loss: 0.046451518857215136\n",
      "Iteration: 90000 | Loss: 0.04645151885170099\n",
      "Iteration: 91000 | Loss: 0.046451518847021644\n",
      "Iteration: 92000 | Loss: 0.04645151884305058\n",
      "Iteration: 93000 | Loss: 0.04645151883968062\n",
      "Iteration: 94000 | Loss: 0.046451518836820804\n",
      "Iteration: 95000 | Loss: 0.04645151883439386\n",
      "Iteration: 96000 | Loss: 0.046451518832334275\n",
      "Iteration: 97000 | Loss: 0.04645151883058645\n",
      "Iteration: 98000 | Loss: 0.046451518829103165\n",
      "Iteration: 99000 | Loss: 0.04645151882784438\n",
      "Iteration: 100000 | Loss: 0.04645151882677613\n",
      "Iteration: 101000 | Loss: 0.04645151882586958\n",
      "Iteration: 102000 | Loss: 0.04645151882510026\n",
      "Iteration: 103000 | Loss: 0.04645151882444733\n",
      "Iteration: 104000 | Loss: 0.046451518823893284\n",
      "Iteration: 105000 | Loss: 0.04645151882342306\n",
      "Iteration: 106000 | Loss: 0.046451518823023986\n",
      "Iteration: 107000 | Loss: 0.046451518822685334\n",
      "Iteration: 108000 | Loss: 0.04645151882239796\n",
      "Iteration: 109000 | Loss: 0.04645151882215404\n",
      "Iteration: 110000 | Loss: 0.046451518821947084\n",
      "Iteration: 111000 | Loss: 0.04645151882177139\n",
      "Iteration: 112000 | Loss: 0.04645151882162236\n",
      "Iteration: 113000 | Loss: 0.04645151882149582\n",
      "Iteration: 114000 | Loss: 0.04645151882138845\n",
      "Iteration: 115000 | Loss: 0.04645151882129734\n",
      "Iteration: 116000 | Loss: 0.04645151882122003\n",
      "Iteration: 117000 | Loss: 0.04645151882115438\n",
      "Iteration: 118000 | Loss: 0.046451518821098714\n",
      "Iteration: 119000 | Loss: 0.04645151882105143\n",
      "Iteration: 120000 | Loss: 0.046451518821011346\n",
      "Iteration: 121000 | Loss: 0.04645151882097734\n",
      "Iteration: 122000 | Loss: 0.04645151882094843\n",
      "Iteration: 123000 | Loss: 0.0464515188209239\n",
      "Iteration: 124000 | Loss: 0.04645151882090311\n",
      "Iteration: 125000 | Loss: 0.04645151882088544\n",
      "Iteration: 126000 | Loss: 0.04645151882087047\n",
      "Iteration: 127000 | Loss: 0.04645151882085773\n",
      "Iteration: 128000 | Loss: 0.04645151882084697\n",
      "Iteration: 129000 | Loss: 0.04645151882083779\n",
      "Iteration: 130000 | Loss: 0.04645151882083006\n",
      "Iteration: 131000 | Loss: 0.046451518820823434\n",
      "Iteration: 132000 | Loss: 0.046451518820817855\n",
      "Iteration: 133000 | Loss: 0.046451518820813095\n",
      "Iteration: 134000 | Loss: 0.046451518820809036\n",
      "Iteration: 135000 | Loss: 0.046451518820805615\n",
      "Iteration: 136000 | Loss: 0.04645151882080272\n",
      "Iteration: 137000 | Loss: 0.04645151882080027\n",
      "Iteration: 138000 | Loss: 0.046451518820798156\n",
      "Iteration: 139000 | Loss: 0.04645151882079641\n",
      "Iteration: 140000 | Loss: 0.046451518820794874\n",
      "Iteration: 141000 | Loss: 0.046451518820793625\n",
      "Iteration: 142000 | Loss: 0.04645151882079254\n",
      "Iteration: 143000 | Loss: 0.046451518820791626\n",
      "Iteration: 144000 | Loss: 0.0464515188207908\n",
      "Iteration: 145000 | Loss: 0.046451518820790176\n",
      "Iteration: 146000 | Loss: 0.046451518820789614\n",
      "Iteration: 147000 | Loss: 0.046451518820789135\n",
      "Iteration: 148000 | Loss: 0.04645151882078874\n",
      "Iteration: 149000 | Loss: 0.04645151882078834\n",
      "Iteration: 150000 | Loss: 0.04645151882078806\n",
      "Iteration: 151000 | Loss: 0.04645151882078784\n",
      "Iteration: 152000 | Loss: 0.04645151882078761\n",
      "Iteration: 153000 | Loss: 0.04645151882078746\n",
      "Iteration: 154000 | Loss: 0.04645151882078731\n",
      "Iteration: 155000 | Loss: 0.046451518820787144\n",
      "Iteration: 156000 | Loss: 0.04645151882078707\n",
      "Iteration: 157000 | Loss: 0.046451518820786984\n",
      "Iteration: 158000 | Loss: 0.046451518820786894\n",
      "Iteration: 159000 | Loss: 0.04645151882078679\n",
      "Iteration: 160000 | Loss: 0.046451518820786755\n",
      "Iteration: 161000 | Loss: 0.0464515188207867\n",
      "Iteration: 162000 | Loss: 0.046451518820786665\n",
      "Iteration: 163000 | Loss: 0.04645151882078664\n",
      "Iteration: 164000 | Loss: 0.04645151882078663\n",
      "Iteration: 165000 | Loss: 0.046451518820786575\n",
      "Iteration: 166000 | Loss: 0.04645151882078656\n",
      "Iteration: 167000 | Loss: 0.04645151882078656\n",
      "Iteration: 168000 | Loss: 0.04645151882078654\n",
      "Iteration: 169000 | Loss: 0.04645151882078653\n",
      "Iteration: 170000 | Loss: 0.046451518820786485\n",
      "Iteration: 171000 | Loss: 0.046451518820786485\n",
      "Iteration: 172000 | Loss: 0.046451518820786505\n",
      "Iteration: 173000 | Loss: 0.04645151882078648\n",
      "Iteration: 174000 | Loss: 0.04645151882078646\n",
      "Iteration: 175000 | Loss: 0.04645151882078647\n",
      "Iteration: 176000 | Loss: 0.046451518820786485\n",
      "Iteration: 177000 | Loss: 0.04645151882078647\n",
      "Iteration: 178000 | Loss: 0.04645151882078648\n",
      "Iteration: 179000 | Loss: 0.04645151882078645\n",
      "Iteration: 180000 | Loss: 0.04645151882078645\n",
      "Iteration: 181000 | Loss: 0.04645151882078645\n",
      "Iteration: 182000 | Loss: 0.04645151882078645\n",
      "Iteration: 183000 | Loss: 0.04645151882078646\n",
      "Iteration: 184000 | Loss: 0.04645151882078644\n",
      "Iteration: 185000 | Loss: 0.04645151882078647\n",
      "Iteration: 186000 | Loss: 0.04645151882078645\n",
      "Iteration: 187000 | Loss: 0.04645151882078647\n",
      "Iteration: 188000 | Loss: 0.04645151882078647\n",
      "Iteration: 189000 | Loss: 0.04645151882078646\n",
      "Iteration: 190000 | Loss: 0.04645151882078648\n",
      "Iteration: 191000 | Loss: 0.04645151882078646\n",
      "Iteration: 192000 | Loss: 0.04645151882078644\n",
      "Iteration: 193000 | Loss: 0.04645151882078642\n",
      "Iteration: 194000 | Loss: 0.04645151882078646\n",
      "Iteration: 195000 | Loss: 0.046451518820786415\n",
      "Iteration: 196000 | Loss: 0.04645151882078645\n",
      "Iteration: 197000 | Loss: 0.04645151882078645\n",
      "Iteration: 198000 | Loss: 0.046451518820786436\n",
      "Iteration: 199000 | Loss: 0.04645151882078646\n",
      "Iteration: 200000 | Loss: 0.046451518820786436\n",
      "Iteration: 201000 | Loss: 0.04645151882078644\n",
      "Iteration: 202000 | Loss: 0.04645151882078645\n",
      "Iteration: 203000 | Loss: 0.04645151882078642\n",
      "Iteration: 204000 | Loss: 0.04645151882078647\n",
      "Iteration: 205000 | Loss: 0.04645151882078645\n",
      "Iteration: 206000 | Loss: 0.04645151882078645\n",
      "Iteration: 207000 | Loss: 0.04645151882078645\n",
      "Iteration: 208000 | Loss: 0.046451518820786436\n",
      "Iteration: 209000 | Loss: 0.04645151882078645\n",
      "Iteration: 210000 | Loss: 0.046451518820786436\n",
      "Iteration: 211000 | Loss: 0.046451518820786485\n",
      "Iteration: 212000 | Loss: 0.04645151882078642\n",
      "Iteration: 213000 | Loss: 0.046451518820786436\n",
      "Iteration: 214000 | Loss: 0.04645151882078645\n",
      "Iteration: 215000 | Loss: 0.04645151882078645\n",
      "Iteration: 216000 | Loss: 0.04645151882078645\n",
      "Iteration: 217000 | Loss: 0.04645151882078644\n",
      "Iteration: 218000 | Loss: 0.04645151882078647\n",
      "Iteration: 219000 | Loss: 0.046451518820786436\n",
      "Iteration: 220000 | Loss: 0.046451518820786436\n",
      "Iteration: 221000 | Loss: 0.046451518820786415\n",
      "Iteration: 222000 | Loss: 0.04645151882078645\n",
      "Iteration: 223000 | Loss: 0.04645151882078645\n",
      "Iteration: 224000 | Loss: 0.046451518820786436\n",
      "Iteration: 225000 | Loss: 0.046451518820786415\n",
      "Iteration: 226000 | Loss: 0.04645151882078646\n",
      "Iteration: 227000 | Loss: 0.04645151882078646\n",
      "Iteration: 228000 | Loss: 0.04645151882078646\n",
      "Iteration: 229000 | Loss: 0.04645151882078647\n",
      "Iteration: 230000 | Loss: 0.046451518820786436\n",
      "Iteration: 231000 | Loss: 0.04645151882078645\n",
      "Iteration: 232000 | Loss: 0.046451518820786436\n",
      "Iteration: 233000 | Loss: 0.04645151882078647\n",
      "Iteration: 234000 | Loss: 0.046451518820786436\n",
      "Iteration: 235000 | Loss: 0.04645151882078644\n",
      "Iteration: 236000 | Loss: 0.04645151882078647\n",
      "Iteration: 237000 | Loss: 0.04645151882078646\n",
      "Iteration: 238000 | Loss: 0.04645151882078647\n",
      "Iteration: 239000 | Loss: 0.046451518820786436\n",
      "Iteration: 240000 | Loss: 0.046451518820786485\n",
      "Iteration: 241000 | Loss: 0.04645151882078648\n",
      "Iteration: 242000 | Loss: 0.04645151882078645\n",
      "Iteration: 243000 | Loss: 0.046451518820786436\n",
      "Iteration: 244000 | Loss: 0.04645151882078645\n",
      "Iteration: 245000 | Loss: 0.04645151882078646\n",
      "Iteration: 246000 | Loss: 0.04645151882078647\n",
      "Iteration: 247000 | Loss: 0.04645151882078644\n",
      "Iteration: 248000 | Loss: 0.04645151882078645\n",
      "Iteration: 249000 | Loss: 0.046451518820786436\n",
      "Iteration: 250000 | Loss: 0.04645151882078647\n",
      "Iteration: 251000 | Loss: 0.046451518820786436\n",
      "Iteration: 252000 | Loss: 0.04645151882078644\n",
      "Iteration: 253000 | Loss: 0.04645151882078645\n",
      "Iteration: 254000 | Loss: 0.04645151882078644\n",
      "Iteration: 255000 | Loss: 0.04645151882078646\n",
      "Iteration: 256000 | Loss: 0.046451518820786436\n",
      "Iteration: 257000 | Loss: 0.04645151882078647\n",
      "Iteration: 258000 | Loss: 0.046451518820786436\n",
      "Iteration: 259000 | Loss: 0.04645151882078645\n",
      "Iteration: 260000 | Loss: 0.04645151882078647\n",
      "Iteration: 261000 | Loss: 0.04645151882078645\n",
      "Iteration: 262000 | Loss: 0.046451518820786436\n",
      "Iteration: 263000 | Loss: 0.046451518820786436\n",
      "Iteration: 264000 | Loss: 0.046451518820786436\n",
      "Iteration: 265000 | Loss: 0.046451518820786436\n",
      "Iteration: 266000 | Loss: 0.046451518820786436\n",
      "Iteration: 267000 | Loss: 0.046451518820786436\n",
      "Iteration: 268000 | Loss: 0.04645151882078647\n",
      "Iteration: 269000 | Loss: 0.04645151882078644\n",
      "Iteration: 270000 | Loss: 0.04645151882078645\n",
      "Iteration: 271000 | Loss: 0.04645151882078646\n",
      "Iteration: 272000 | Loss: 0.046451518820786436\n",
      "Iteration: 273000 | Loss: 0.04645151882078645\n",
      "Iteration: 274000 | Loss: 0.04645151882078644\n",
      "Iteration: 275000 | Loss: 0.046451518820786415\n",
      "Iteration: 276000 | Loss: 0.046451518820786415\n",
      "Iteration: 277000 | Loss: 0.04645151882078644\n",
      "Iteration: 278000 | Loss: 0.04645151882078645\n",
      "Iteration: 279000 | Loss: 0.046451518820786436\n",
      "Iteration: 280000 | Loss: 0.04645151882078647\n",
      "Iteration: 281000 | Loss: 0.04645151882078648\n",
      "Iteration: 282000 | Loss: 0.04645151882078646\n",
      "Iteration: 283000 | Loss: 0.046451518820786436\n",
      "Iteration: 284000 | Loss: 0.04645151882078645\n",
      "Iteration: 285000 | Loss: 0.04645151882078645\n",
      "Iteration: 286000 | Loss: 0.04645151882078644\n",
      "Iteration: 287000 | Loss: 0.04645151882078646\n",
      "Iteration: 288000 | Loss: 0.04645151882078645\n",
      "Iteration: 289000 | Loss: 0.04645151882078645\n",
      "Iteration: 290000 | Loss: 0.04645151882078645\n",
      "Iteration: 291000 | Loss: 0.04645151882078642\n",
      "Iteration: 292000 | Loss: 0.04645151882078642\n",
      "Iteration: 293000 | Loss: 0.04645151882078645\n",
      "Iteration: 294000 | Loss: 0.04645151882078644\n",
      "Iteration: 295000 | Loss: 0.046451518820786436\n",
      "Iteration: 296000 | Loss: 0.04645151882078645\n",
      "Iteration: 297000 | Loss: 0.04645151882078642\n",
      "Iteration: 298000 | Loss: 0.046451518820786415\n",
      "Iteration: 299000 | Loss: 0.046451518820786415\n",
      "Iteration: 300000 | Loss: 0.04645151882078644\n",
      "Iteration: 301000 | Loss: 0.04645151882078645\n",
      "Iteration: 302000 | Loss: 0.04645151882078644\n",
      "Iteration: 303000 | Loss: 0.04645151882078644\n",
      "Iteration: 304000 | Loss: 0.046451518820786415\n",
      "Iteration: 305000 | Loss: 0.04645151882078646\n",
      "Iteration: 306000 | Loss: 0.04645151882078642\n",
      "Iteration: 307000 | Loss: 0.046451518820786436\n",
      "Iteration: 308000 | Loss: 0.04645151882078647\n",
      "Iteration: 309000 | Loss: 0.04645151882078645\n",
      "Iteration: 310000 | Loss: 0.04645151882078642\n",
      "Iteration: 311000 | Loss: 0.04645151882078645\n",
      "Iteration: 312000 | Loss: 0.04645151882078645\n",
      "Iteration: 313000 | Loss: 0.04645151882078642\n",
      "Iteration: 314000 | Loss: 0.04645151882078645\n",
      "Iteration: 315000 | Loss: 0.04645151882078645\n",
      "Converge\n",
      "Didn't converge\n",
      "[[ 0.80355618]\n",
      " [-1.79173037]\n",
      " [ 1.57605661]\n",
      " [-0.06219595]\n",
      " [ 1.0908252 ]\n",
      " [-0.77809016]\n",
      " [-1.24121391]]\n",
      "-3.618239838584519\n",
      "---------\n",
      "Train for Hufflepuff house\n",
      "Iteration: 0 | Loss: 0.6931471805599452\n",
      "Iteration: 1000 | Loss: 0.06309997861666297\n",
      "Iteration: 2000 | Loss: 0.06086024519727893\n",
      "Iteration: 3000 | Loss: 0.06038590269086781\n",
      "Iteration: 4000 | Loss: 0.060230753206139694\n",
      "Iteration: 5000 | Loss: 0.06016699366470772\n",
      "Iteration: 6000 | Loss: 0.06013615330896709\n",
      "Iteration: 7000 | Loss: 0.060119208654981764\n",
      "Iteration: 8000 | Loss: 0.06010894103842542\n",
      "Iteration: 9000 | Loss: 0.060102259237206815\n",
      "Iteration: 10000 | Loss: 0.0600976903328972\n",
      "Iteration: 11000 | Loss: 0.06009446051199893\n",
      "Iteration: 12000 | Loss: 0.06009212636283186\n",
      "Iteration: 13000 | Loss: 0.060090414609596174\n",
      "Iteration: 14000 | Loss: 0.060089146896516676\n",
      "Iteration: 15000 | Loss: 0.0600882017271503\n",
      "Iteration: 16000 | Loss: 0.06008749374692077\n",
      "Iteration: 17000 | Loss: 0.06008696167418052\n",
      "Iteration: 18000 | Loss: 0.0600865608368188\n",
      "Iteration: 19000 | Loss: 0.06008625832199295\n",
      "Iteration: 20000 | Loss: 0.06008602969781271\n",
      "Iteration: 21000 | Loss: 0.06008585673029521\n",
      "Iteration: 22000 | Loss: 0.0600857257578344\n",
      "Iteration: 23000 | Loss: 0.06008562651497029\n",
      "Iteration: 24000 | Loss: 0.06008555127124167\n",
      "Iteration: 25000 | Loss: 0.06008549419533127\n",
      "Iteration: 26000 | Loss: 0.060085450882632174\n",
      "Iteration: 27000 | Loss: 0.060085418002611864\n",
      "Iteration: 28000 | Loss: 0.060085393034682355\n",
      "Iteration: 29000 | Loss: 0.06008537406983621\n",
      "Iteration: 30000 | Loss: 0.06008535966136491\n",
      "Iteration: 31000 | Loss: 0.06008534871232869\n",
      "Iteration: 32000 | Loss: 0.06008534039061739\n",
      "Iteration: 33000 | Loss: 0.06008533406476636\n",
      "Iteration: 34000 | Loss: 0.060085329255411386\n",
      "Iteration: 35000 | Loss: 0.06008532559854358\n",
      "Iteration: 36000 | Loss: 0.06008532281767727\n",
      "Iteration: 37000 | Loss: 0.06008532070275711\n",
      "Iteration: 38000 | Loss: 0.06008531909416436\n",
      "Iteration: 39000 | Loss: 0.06008531787058467\n",
      "Iteration: 40000 | Loss: 0.06008531693980097\n",
      "Iteration: 41000 | Loss: 0.060085316231704725\n",
      "Iteration: 42000 | Loss: 0.06008531569298864\n",
      "Iteration: 43000 | Loss: 0.06008531528311593\n",
      "Iteration: 44000 | Loss: 0.06008531497125756\n",
      "Iteration: 45000 | Loss: 0.060085314733965695\n",
      "Iteration: 46000 | Loss: 0.06008531455340486\n",
      "Iteration: 47000 | Loss: 0.06008531441600755\n",
      "Iteration: 48000 | Loss: 0.060085314311452545\n",
      "Iteration: 49000 | Loss: 0.06008531423188741\n",
      "Iteration: 50000 | Loss: 0.06008531417133801\n",
      "Iteration: 51000 | Loss: 0.06008531412525867\n",
      "Iteration: 52000 | Loss: 0.06008531409019072\n",
      "Iteration: 53000 | Loss: 0.06008531406350237\n",
      "Iteration: 54000 | Loss: 0.06008531404319097\n",
      "Iteration: 55000 | Loss: 0.06008531402773268\n",
      "Iteration: 56000 | Loss: 0.0600853140159677\n",
      "Iteration: 57000 | Loss: 0.0600853140070136\n",
      "Iteration: 58000 | Loss: 0.06008531400019864\n",
      "Iteration: 59000 | Loss: 0.060085313995011845\n",
      "Iteration: 60000 | Loss: 0.060085313991064156\n",
      "Iteration: 61000 | Loss: 0.06008531398805948\n",
      "Iteration: 62000 | Loss: 0.06008531398577269\n",
      "Iteration: 63000 | Loss: 0.06008531398403207\n",
      "Iteration: 64000 | Loss: 0.060085313982707264\n",
      "Iteration: 65000 | Loss: 0.06008531398169893\n",
      "Iteration: 66000 | Loss: 0.060085313980931476\n",
      "Iteration: 67000 | Loss: 0.06008531398034732\n",
      "Iteration: 68000 | Loss: 0.06008531397990274\n",
      "Iteration: 69000 | Loss: 0.06008531397956434\n",
      "Iteration: 70000 | Loss: 0.06008531397930674\n",
      "Iteration: 71000 | Loss: 0.06008531397911068\n",
      "Iteration: 72000 | Loss: 0.06008531397896146\n",
      "Iteration: 73000 | Loss: 0.060085313978847935\n",
      "Iteration: 74000 | Loss: 0.06008531397876146\n",
      "Iteration: 75000 | Loss: 0.06008531397869565\n",
      "Iteration: 76000 | Loss: 0.06008531397864557\n",
      "Iteration: 77000 | Loss: 0.06008531397860746\n",
      "Iteration: 78000 | Loss: 0.06008531397857844\n",
      "Iteration: 79000 | Loss: 0.060085313978556334\n",
      "Iteration: 80000 | Loss: 0.06008531397853954\n",
      "Iteration: 81000 | Loss: 0.06008531397852675\n",
      "Iteration: 82000 | Loss: 0.06008531397851698\n",
      "Iteration: 83000 | Loss: 0.06008531397850957\n",
      "Iteration: 84000 | Loss: 0.06008531397850395\n",
      "Iteration: 85000 | Loss: 0.06008531397849966\n",
      "Iteration: 86000 | Loss: 0.06008531397849638\n",
      "Iteration: 87000 | Loss: 0.060085313978493864\n",
      "Iteration: 88000 | Loss: 0.060085313978492\n",
      "Iteration: 89000 | Loss: 0.060085313978490554\n",
      "Iteration: 90000 | Loss: 0.06008531397848947\n",
      "Iteration: 91000 | Loss: 0.06008531397848861\n",
      "Iteration: 92000 | Loss: 0.06008531397848801\n",
      "Iteration: 93000 | Loss: 0.06008531397848751\n",
      "Iteration: 94000 | Loss: 0.060085313978487126\n",
      "Iteration: 95000 | Loss: 0.06008531397848682\n",
      "Iteration: 96000 | Loss: 0.06008531397848664\n",
      "Iteration: 97000 | Loss: 0.060085313978486446\n",
      "Iteration: 98000 | Loss: 0.06008531397848636\n",
      "Iteration: 99000 | Loss: 0.06008531397848624\n",
      "Iteration: 100000 | Loss: 0.06008531397848617\n",
      "Iteration: 101000 | Loss: 0.06008531397848614\n",
      "Iteration: 102000 | Loss: 0.06008531397848607\n",
      "Iteration: 103000 | Loss: 0.06008531397848603\n",
      "Iteration: 104000 | Loss: 0.06008531397848601\n",
      "Iteration: 105000 | Loss: 0.060085313978486016\n",
      "Iteration: 106000 | Loss: 0.06008531397848601\n",
      "Iteration: 107000 | Loss: 0.060085313978485995\n",
      "Iteration: 108000 | Loss: 0.06008531397848597\n",
      "Iteration: 109000 | Loss: 0.060085313978485995\n",
      "Iteration: 110000 | Loss: 0.06008531397848597\n",
      "Iteration: 111000 | Loss: 0.06008531397848598\n",
      "Iteration: 112000 | Loss: 0.06008531397848597\n",
      "Iteration: 113000 | Loss: 0.06008531397848594\n",
      "Iteration: 114000 | Loss: 0.060085313978485946\n",
      "Iteration: 115000 | Loss: 0.06008531397848595\n",
      "Iteration: 116000 | Loss: 0.06008531397848595\n",
      "Iteration: 117000 | Loss: 0.06008531397848597\n",
      "Iteration: 118000 | Loss: 0.060085313978485995\n",
      "Iteration: 119000 | Loss: 0.06008531397848595\n",
      "Iteration: 120000 | Loss: 0.06008531397848595\n",
      "Iteration: 121000 | Loss: 0.06008531397848594\n",
      "Iteration: 122000 | Loss: 0.060085313978485974\n",
      "Iteration: 123000 | Loss: 0.060085313978485974\n",
      "Iteration: 124000 | Loss: 0.060085313978485974\n",
      "Iteration: 125000 | Loss: 0.06008531397848593\n",
      "Iteration: 126000 | Loss: 0.06008531397848598\n",
      "Iteration: 127000 | Loss: 0.06008531397848598\n",
      "Iteration: 128000 | Loss: 0.06008531397848597\n",
      "Iteration: 129000 | Loss: 0.06008531397848597\n",
      "Iteration: 130000 | Loss: 0.060085313978485946\n",
      "Iteration: 131000 | Loss: 0.06008531397848595\n",
      "Iteration: 132000 | Loss: 0.06008531397848595\n",
      "Iteration: 133000 | Loss: 0.06008531397848597\n",
      "Iteration: 134000 | Loss: 0.060085313978485946\n",
      "Iteration: 135000 | Loss: 0.06008531397848593\n",
      "Iteration: 136000 | Loss: 0.06008531397848593\n",
      "Iteration: 137000 | Loss: 0.06008531397848594\n",
      "Iteration: 138000 | Loss: 0.06008531397848597\n",
      "Iteration: 139000 | Loss: 0.060085313978485946\n",
      "Iteration: 140000 | Loss: 0.06008531397848598\n",
      "Iteration: 141000 | Loss: 0.060085313978485946\n",
      "Iteration: 142000 | Loss: 0.06008531397848597\n",
      "Iteration: 143000 | Loss: 0.06008531397848592\n",
      "Iteration: 144000 | Loss: 0.060085313978485946\n",
      "Iteration: 145000 | Loss: 0.06008531397848597\n",
      "Iteration: 146000 | Loss: 0.06008531397848595\n",
      "Iteration: 147000 | Loss: 0.06008531397848594\n",
      "Iteration: 148000 | Loss: 0.060085313978485974\n",
      "Iteration: 149000 | Loss: 0.06008531397848593\n",
      "Iteration: 150000 | Loss: 0.06008531397848598\n",
      "Iteration: 151000 | Loss: 0.06008531397848594\n",
      "Iteration: 152000 | Loss: 0.06008531397848593\n",
      "Iteration: 153000 | Loss: 0.06008531397848593\n",
      "Iteration: 154000 | Loss: 0.06008531397848595\n",
      "Iteration: 155000 | Loss: 0.06008531397848593\n",
      "Iteration: 156000 | Loss: 0.06008531397848597\n",
      "Iteration: 157000 | Loss: 0.06008531397848595\n",
      "Iteration: 158000 | Loss: 0.06008531397848591\n",
      "Iteration: 159000 | Loss: 0.06008531397848593\n",
      "Iteration: 160000 | Loss: 0.060085313978485974\n",
      "Iteration: 161000 | Loss: 0.060085313978485946\n",
      "Iteration: 162000 | Loss: 0.06008531397848594\n",
      "Iteration: 163000 | Loss: 0.06008531397848595\n",
      "Iteration: 164000 | Loss: 0.06008531397848597\n",
      "Iteration: 165000 | Loss: 0.06008531397848598\n",
      "Iteration: 166000 | Loss: 0.06008531397848598\n",
      "Iteration: 167000 | Loss: 0.06008531397848595\n",
      "Iteration: 168000 | Loss: 0.06008531397848597\n",
      "Iteration: 169000 | Loss: 0.06008531397848597\n",
      "Iteration: 170000 | Loss: 0.06008531397848597\n",
      "Iteration: 171000 | Loss: 0.06008531397848594\n",
      "Iteration: 172000 | Loss: 0.06008531397848595\n",
      "Iteration: 173000 | Loss: 0.06008531397848598\n",
      "Iteration: 174000 | Loss: 0.06008531397848597\n",
      "Iteration: 175000 | Loss: 0.06008531397848597\n",
      "Iteration: 176000 | Loss: 0.060085313978485946\n",
      "Iteration: 177000 | Loss: 0.060085313978485946\n",
      "Iteration: 178000 | Loss: 0.06008531397848597\n",
      "Iteration: 179000 | Loss: 0.060085313978485946\n",
      "Iteration: 180000 | Loss: 0.06008531397848595\n",
      "Iteration: 181000 | Loss: 0.06008531397848593\n",
      "Iteration: 182000 | Loss: 0.060085313978485946\n",
      "Iteration: 183000 | Loss: 0.06008531397848595\n",
      "Iteration: 184000 | Loss: 0.060085313978485946\n",
      "Iteration: 185000 | Loss: 0.06008531397848597\n",
      "Iteration: 186000 | Loss: 0.06008531397848595\n",
      "Iteration: 187000 | Loss: 0.06008531397848595\n",
      "Iteration: 188000 | Loss: 0.06008531397848593\n",
      "Iteration: 189000 | Loss: 0.060085313978485974\n",
      "Iteration: 190000 | Loss: 0.06008531397848597\n",
      "Iteration: 191000 | Loss: 0.060085313978485946\n",
      "Iteration: 192000 | Loss: 0.060085313978485974\n",
      "Iteration: 193000 | Loss: 0.060085313978485946\n",
      "Iteration: 194000 | Loss: 0.06008531397848595\n",
      "Iteration: 195000 | Loss: 0.06008531397848595\n",
      "Iteration: 196000 | Loss: 0.060085313978485946\n",
      "Iteration: 197000 | Loss: 0.060085313978485946\n",
      "Iteration: 198000 | Loss: 0.060085313978485946\n",
      "Iteration: 199000 | Loss: 0.060085313978485946\n",
      "Iteration: 200000 | Loss: 0.060085313978485946\n",
      "Iteration: 201000 | Loss: 0.060085313978485946\n",
      "Iteration: 202000 | Loss: 0.060085313978485946\n",
      "Iteration: 203000 | Loss: 0.060085313978485946\n",
      "Iteration: 204000 | Loss: 0.060085313978485946\n",
      "Iteration: 205000 | Loss: 0.060085313978485946\n",
      "Iteration: 206000 | Loss: 0.060085313978485946\n",
      "Iteration: 207000 | Loss: 0.060085313978485946\n",
      "Iteration: 208000 | Loss: 0.060085313978485946\n",
      "Iteration: 209000 | Loss: 0.060085313978485946\n",
      "Iteration: 210000 | Loss: 0.060085313978485946\n",
      "Iteration: 211000 | Loss: 0.060085313978485946\n",
      "Iteration: 212000 | Loss: 0.060085313978485946\n",
      "Iteration: 213000 | Loss: 0.060085313978485946\n",
      "Iteration: 214000 | Loss: 0.060085313978485946\n",
      "Iteration: 215000 | Loss: 0.060085313978485946\n",
      "Iteration: 216000 | Loss: 0.060085313978485946\n",
      "Iteration: 217000 | Loss: 0.060085313978485946\n",
      "Iteration: 218000 | Loss: 0.060085313978485946\n",
      "Iteration: 219000 | Loss: 0.060085313978485946\n",
      "Iteration: 220000 | Loss: 0.060085313978485946\n",
      "Iteration: 221000 | Loss: 0.060085313978485946\n",
      "Iteration: 222000 | Loss: 0.060085313978485946\n",
      "Iteration: 223000 | Loss: 0.060085313978485946\n",
      "Iteration: 224000 | Loss: 0.060085313978485946\n",
      "Iteration: 225000 | Loss: 0.060085313978485946\n",
      "Iteration: 226000 | Loss: 0.060085313978485946\n",
      "Iteration: 227000 | Loss: 0.060085313978485946\n",
      "Iteration: 228000 | Loss: 0.060085313978485946\n",
      "Iteration: 229000 | Loss: 0.060085313978485946\n",
      "Iteration: 230000 | Loss: 0.060085313978485946\n",
      "Iteration: 231000 | Loss: 0.060085313978485946\n",
      "Iteration: 232000 | Loss: 0.060085313978485946\n",
      "Iteration: 233000 | Loss: 0.060085313978485946\n",
      "Iteration: 234000 | Loss: 0.060085313978485946\n",
      "Iteration: 235000 | Loss: 0.060085313978485946\n",
      "Iteration: 236000 | Loss: 0.060085313978485946\n",
      "Iteration: 237000 | Loss: 0.060085313978485946\n",
      "Iteration: 238000 | Loss: 0.060085313978485946\n",
      "Iteration: 239000 | Loss: 0.060085313978485946\n",
      "Iteration: 240000 | Loss: 0.060085313978485946\n",
      "Iteration: 241000 | Loss: 0.060085313978485946\n",
      "Iteration: 242000 | Loss: 0.060085313978485946\n",
      "Iteration: 243000 | Loss: 0.060085313978485946\n",
      "Iteration: 244000 | Loss: 0.060085313978485946\n",
      "Iteration: 245000 | Loss: 0.060085313978485946\n",
      "Iteration: 246000 | Loss: 0.060085313978485946\n",
      "Iteration: 247000 | Loss: 0.060085313978485946\n",
      "Iteration: 248000 | Loss: 0.060085313978485946\n",
      "Iteration: 249000 | Loss: 0.060085313978485946\n",
      "Iteration: 250000 | Loss: 0.060085313978485946\n",
      "Iteration: 251000 | Loss: 0.060085313978485946\n",
      "Iteration: 252000 | Loss: 0.060085313978485946\n",
      "Iteration: 253000 | Loss: 0.060085313978485946\n",
      "Iteration: 254000 | Loss: 0.060085313978485946\n",
      "Iteration: 255000 | Loss: 0.060085313978485946\n",
      "Iteration: 256000 | Loss: 0.060085313978485946\n",
      "Iteration: 257000 | Loss: 0.060085313978485946\n",
      "Iteration: 258000 | Loss: 0.060085313978485946\n",
      "Iteration: 259000 | Loss: 0.060085313978485946\n",
      "Iteration: 260000 | Loss: 0.060085313978485946\n",
      "Iteration: 261000 | Loss: 0.060085313978485946\n",
      "Iteration: 262000 | Loss: 0.060085313978485946\n",
      "Iteration: 263000 | Loss: 0.060085313978485946\n",
      "Iteration: 264000 | Loss: 0.060085313978485946\n",
      "Iteration: 265000 | Loss: 0.060085313978485946\n",
      "Iteration: 266000 | Loss: 0.060085313978485946\n",
      "Iteration: 267000 | Loss: 0.060085313978485946\n",
      "Iteration: 268000 | Loss: 0.060085313978485946\n",
      "Iteration: 269000 | Loss: 0.060085313978485946\n",
      "Iteration: 270000 | Loss: 0.060085313978485946\n",
      "Iteration: 271000 | Loss: 0.060085313978485946\n",
      "Iteration: 272000 | Loss: 0.060085313978485946\n",
      "Iteration: 273000 | Loss: 0.060085313978485946\n",
      "Iteration: 274000 | Loss: 0.060085313978485946\n",
      "Iteration: 275000 | Loss: 0.060085313978485946\n",
      "Iteration: 276000 | Loss: 0.060085313978485946\n",
      "Iteration: 277000 | Loss: 0.060085313978485946\n",
      "Iteration: 278000 | Loss: 0.060085313978485946\n",
      "Iteration: 279000 | Loss: 0.060085313978485946\n",
      "Iteration: 280000 | Loss: 0.060085313978485946\n",
      "Iteration: 281000 | Loss: 0.060085313978485946\n",
      "Iteration: 282000 | Loss: 0.060085313978485946\n",
      "Iteration: 283000 | Loss: 0.060085313978485946\n",
      "Iteration: 284000 | Loss: 0.060085313978485946\n",
      "Iteration: 285000 | Loss: 0.060085313978485946\n",
      "Iteration: 286000 | Loss: 0.060085313978485946\n",
      "Iteration: 287000 | Loss: 0.060085313978485946\n",
      "Iteration: 288000 | Loss: 0.060085313978485946\n",
      "Iteration: 289000 | Loss: 0.060085313978485946\n",
      "Iteration: 290000 | Loss: 0.060085313978485946\n",
      "Iteration: 291000 | Loss: 0.060085313978485946\n",
      "Iteration: 292000 | Loss: 0.060085313978485946\n",
      "Iteration: 293000 | Loss: 0.060085313978485946\n",
      "Iteration: 294000 | Loss: 0.060085313978485946\n",
      "Iteration: 295000 | Loss: 0.060085313978485946\n",
      "Iteration: 296000 | Loss: 0.060085313978485946\n",
      "Iteration: 297000 | Loss: 0.060085313978485946\n",
      "Iteration: 298000 | Loss: 0.060085313978485946\n",
      "Iteration: 299000 | Loss: 0.060085313978485946\n",
      "Iteration: 300000 | Loss: 0.060085313978485946\n",
      "Iteration: 301000 | Loss: 0.060085313978485946\n",
      "Iteration: 302000 | Loss: 0.060085313978485946\n",
      "Iteration: 303000 | Loss: 0.060085313978485946\n",
      "Iteration: 304000 | Loss: 0.060085313978485946\n",
      "Iteration: 305000 | Loss: 0.060085313978485946\n",
      "Iteration: 306000 | Loss: 0.060085313978485946\n",
      "Iteration: 307000 | Loss: 0.060085313978485946\n",
      "Iteration: 308000 | Loss: 0.060085313978485946\n",
      "Iteration: 309000 | Loss: 0.060085313978485946\n",
      "Iteration: 310000 | Loss: 0.060085313978485946\n",
      "Iteration: 311000 | Loss: 0.060085313978485946\n",
      "Iteration: 312000 | Loss: 0.060085313978485946\n",
      "Iteration: 313000 | Loss: 0.060085313978485946\n",
      "Iteration: 314000 | Loss: 0.060085313978485946\n",
      "Iteration: 315000 | Loss: 0.060085313978485946\n",
      "Iteration: 316000 | Loss: 0.060085313978485946\n",
      "Iteration: 317000 | Loss: 0.060085313978485946\n",
      "Iteration: 318000 | Loss: 0.060085313978485946\n",
      "Iteration: 319000 | Loss: 0.060085313978485946\n",
      "Iteration: 320000 | Loss: 0.060085313978485946\n",
      "Iteration: 321000 | Loss: 0.060085313978485946\n",
      "Iteration: 322000 | Loss: 0.060085313978485946\n",
      "Iteration: 323000 | Loss: 0.060085313978485946\n",
      "Iteration: 324000 | Loss: 0.060085313978485946\n",
      "Iteration: 325000 | Loss: 0.060085313978485946\n",
      "Iteration: 326000 | Loss: 0.060085313978485946\n",
      "Iteration: 327000 | Loss: 0.060085313978485946\n",
      "Iteration: 328000 | Loss: 0.060085313978485946\n",
      "Iteration: 329000 | Loss: 0.060085313978485946\n",
      "Iteration: 330000 | Loss: 0.060085313978485946\n",
      "Iteration: 331000 | Loss: 0.060085313978485946\n",
      "Iteration: 332000 | Loss: 0.060085313978485946\n",
      "Iteration: 333000 | Loss: 0.060085313978485946\n",
      "Iteration: 334000 | Loss: 0.060085313978485946\n",
      "Iteration: 335000 | Loss: 0.060085313978485946\n",
      "Iteration: 336000 | Loss: 0.060085313978485946\n",
      "Iteration: 337000 | Loss: 0.060085313978485946\n",
      "Iteration: 338000 | Loss: 0.060085313978485946\n",
      "Iteration: 339000 | Loss: 0.060085313978485946\n",
      "Iteration: 340000 | Loss: 0.060085313978485946\n",
      "Iteration: 341000 | Loss: 0.060085313978485946\n",
      "Iteration: 342000 | Loss: 0.060085313978485946\n",
      "Iteration: 343000 | Loss: 0.060085313978485946\n",
      "Iteration: 344000 | Loss: 0.060085313978485946\n",
      "Iteration: 345000 | Loss: 0.060085313978485946\n",
      "Iteration: 346000 | Loss: 0.060085313978485946\n",
      "Iteration: 347000 | Loss: 0.060085313978485946\n",
      "Iteration: 348000 | Loss: 0.060085313978485946\n",
      "Iteration: 349000 | Loss: 0.060085313978485946\n",
      "Iteration: 350000 | Loss: 0.060085313978485946\n",
      "Iteration: 351000 | Loss: 0.060085313978485946\n",
      "Iteration: 352000 | Loss: 0.060085313978485946\n",
      "Iteration: 353000 | Loss: 0.060085313978485946\n",
      "Iteration: 354000 | Loss: 0.060085313978485946\n",
      "Iteration: 355000 | Loss: 0.060085313978485946\n",
      "Iteration: 356000 | Loss: 0.060085313978485946\n",
      "Iteration: 357000 | Loss: 0.060085313978485946\n",
      "Iteration: 358000 | Loss: 0.060085313978485946\n",
      "Iteration: 359000 | Loss: 0.060085313978485946\n",
      "Iteration: 360000 | Loss: 0.060085313978485946\n",
      "Iteration: 361000 | Loss: 0.060085313978485946\n",
      "Iteration: 362000 | Loss: 0.060085313978485946\n",
      "Iteration: 363000 | Loss: 0.060085313978485946\n",
      "Iteration: 364000 | Loss: 0.060085313978485946\n",
      "Iteration: 365000 | Loss: 0.060085313978485946\n",
      "Iteration: 366000 | Loss: 0.060085313978485946\n",
      "Iteration: 367000 | Loss: 0.060085313978485946\n",
      "Iteration: 368000 | Loss: 0.060085313978485946\n",
      "Iteration: 369000 | Loss: 0.060085313978485946\n",
      "Iteration: 370000 | Loss: 0.060085313978485946\n",
      "Iteration: 371000 | Loss: 0.060085313978485946\n",
      "Iteration: 372000 | Loss: 0.060085313978485946\n",
      "Iteration: 373000 | Loss: 0.060085313978485946\n",
      "Iteration: 374000 | Loss: 0.060085313978485946\n",
      "Iteration: 375000 | Loss: 0.060085313978485946\n",
      "Iteration: 376000 | Loss: 0.060085313978485946\n",
      "Iteration: 377000 | Loss: 0.060085313978485946\n",
      "Iteration: 378000 | Loss: 0.060085313978485946\n",
      "Iteration: 379000 | Loss: 0.060085313978485946\n",
      "Iteration: 380000 | Loss: 0.060085313978485946\n",
      "Iteration: 381000 | Loss: 0.060085313978485946\n",
      "Iteration: 382000 | Loss: 0.060085313978485946\n",
      "Iteration: 383000 | Loss: 0.060085313978485946\n",
      "Iteration: 384000 | Loss: 0.060085313978485946\n",
      "Iteration: 385000 | Loss: 0.060085313978485946\n",
      "Iteration: 386000 | Loss: 0.060085313978485946\n",
      "Iteration: 387000 | Loss: 0.060085313978485946\n",
      "Iteration: 388000 | Loss: 0.060085313978485946\n",
      "Iteration: 389000 | Loss: 0.060085313978485946\n",
      "Iteration: 390000 | Loss: 0.060085313978485946\n",
      "Iteration: 391000 | Loss: 0.060085313978485946\n",
      "Iteration: 392000 | Loss: 0.060085313978485946\n",
      "Iteration: 393000 | Loss: 0.060085313978485946\n",
      "Iteration: 394000 | Loss: 0.060085313978485946\n",
      "Iteration: 395000 | Loss: 0.060085313978485946\n",
      "Iteration: 396000 | Loss: 0.060085313978485946\n",
      "Iteration: 397000 | Loss: 0.060085313978485946\n",
      "Iteration: 398000 | Loss: 0.060085313978485946\n",
      "Iteration: 399000 | Loss: 0.060085313978485946\n",
      "Iteration: 400000 | Loss: 0.060085313978485946\n",
      "Iteration: 401000 | Loss: 0.060085313978485946\n",
      "Iteration: 402000 | Loss: 0.060085313978485946\n",
      "Iteration: 403000 | Loss: 0.060085313978485946\n",
      "Iteration: 404000 | Loss: 0.060085313978485946\n",
      "Iteration: 405000 | Loss: 0.060085313978485946\n",
      "Iteration: 406000 | Loss: 0.060085313978485946\n",
      "Iteration: 407000 | Loss: 0.060085313978485946\n",
      "Iteration: 408000 | Loss: 0.060085313978485946\n",
      "Iteration: 409000 | Loss: 0.060085313978485946\n",
      "Iteration: 410000 | Loss: 0.060085313978485946\n",
      "Iteration: 411000 | Loss: 0.060085313978485946\n",
      "Iteration: 412000 | Loss: 0.060085313978485946\n",
      "Iteration: 413000 | Loss: 0.060085313978485946\n",
      "Iteration: 414000 | Loss: 0.060085313978485946\n",
      "Iteration: 415000 | Loss: 0.060085313978485946\n",
      "Iteration: 416000 | Loss: 0.060085313978485946\n",
      "Iteration: 417000 | Loss: 0.060085313978485946\n",
      "Iteration: 418000 | Loss: 0.060085313978485946\n",
      "Iteration: 419000 | Loss: 0.060085313978485946\n",
      "Iteration: 420000 | Loss: 0.060085313978485946\n",
      "Iteration: 421000 | Loss: 0.060085313978485946\n",
      "Iteration: 422000 | Loss: 0.060085313978485946\n",
      "Iteration: 423000 | Loss: 0.060085313978485946\n",
      "Iteration: 424000 | Loss: 0.060085313978485946\n",
      "Iteration: 425000 | Loss: 0.060085313978485946\n",
      "Iteration: 426000 | Loss: 0.060085313978485946\n",
      "Iteration: 427000 | Loss: 0.060085313978485946\n",
      "Iteration: 428000 | Loss: 0.060085313978485946\n",
      "Iteration: 429000 | Loss: 0.060085313978485946\n",
      "Iteration: 430000 | Loss: 0.060085313978485946\n",
      "Iteration: 431000 | Loss: 0.060085313978485946\n",
      "Iteration: 432000 | Loss: 0.060085313978485946\n",
      "Iteration: 433000 | Loss: 0.060085313978485946\n",
      "Iteration: 434000 | Loss: 0.060085313978485946\n",
      "Iteration: 435000 | Loss: 0.060085313978485946\n",
      "Iteration: 436000 | Loss: 0.060085313978485946\n",
      "Iteration: 437000 | Loss: 0.060085313978485946\n",
      "Iteration: 438000 | Loss: 0.060085313978485946\n",
      "Iteration: 439000 | Loss: 0.060085313978485946\n",
      "Iteration: 440000 | Loss: 0.060085313978485946\n",
      "Iteration: 441000 | Loss: 0.060085313978485946\n",
      "Iteration: 442000 | Loss: 0.060085313978485946\n",
      "Iteration: 443000 | Loss: 0.060085313978485946\n",
      "Iteration: 444000 | Loss: 0.060085313978485946\n",
      "Iteration: 445000 | Loss: 0.060085313978485946\n",
      "Iteration: 446000 | Loss: 0.060085313978485946\n",
      "Iteration: 447000 | Loss: 0.060085313978485946\n",
      "Iteration: 448000 | Loss: 0.060085313978485946\n",
      "Iteration: 449000 | Loss: 0.060085313978485946\n",
      "Iteration: 450000 | Loss: 0.060085313978485946\n",
      "Iteration: 451000 | Loss: 0.060085313978485946\n",
      "Iteration: 452000 | Loss: 0.060085313978485946\n",
      "Iteration: 453000 | Loss: 0.060085313978485946\n",
      "Iteration: 454000 | Loss: 0.060085313978485946\n",
      "Iteration: 455000 | Loss: 0.060085313978485946\n",
      "Iteration: 456000 | Loss: 0.060085313978485946\n",
      "Iteration: 457000 | Loss: 0.060085313978485946\n",
      "Iteration: 458000 | Loss: 0.060085313978485946\n",
      "Iteration: 459000 | Loss: 0.060085313978485946\n",
      "Iteration: 460000 | Loss: 0.060085313978485946\n",
      "Iteration: 461000 | Loss: 0.060085313978485946\n",
      "Iteration: 462000 | Loss: 0.060085313978485946\n",
      "Iteration: 463000 | Loss: 0.060085313978485946\n",
      "Iteration: 464000 | Loss: 0.060085313978485946\n",
      "Iteration: 465000 | Loss: 0.060085313978485946\n",
      "Iteration: 466000 | Loss: 0.060085313978485946\n",
      "Iteration: 467000 | Loss: 0.060085313978485946\n",
      "Iteration: 468000 | Loss: 0.060085313978485946\n",
      "Iteration: 469000 | Loss: 0.060085313978485946\n",
      "Iteration: 470000 | Loss: 0.060085313978485946\n",
      "Iteration: 471000 | Loss: 0.060085313978485946\n",
      "Iteration: 472000 | Loss: 0.060085313978485946\n",
      "Iteration: 473000 | Loss: 0.060085313978485946\n",
      "Iteration: 474000 | Loss: 0.060085313978485946\n",
      "Iteration: 475000 | Loss: 0.060085313978485946\n",
      "Iteration: 476000 | Loss: 0.060085313978485946\n",
      "Iteration: 477000 | Loss: 0.060085313978485946\n",
      "Iteration: 478000 | Loss: 0.060085313978485946\n",
      "Iteration: 479000 | Loss: 0.060085313978485946\n",
      "Iteration: 480000 | Loss: 0.060085313978485946\n",
      "Iteration: 481000 | Loss: 0.060085313978485946\n",
      "Iteration: 482000 | Loss: 0.060085313978485946\n",
      "Iteration: 483000 | Loss: 0.060085313978485946\n",
      "Iteration: 484000 | Loss: 0.060085313978485946\n",
      "Iteration: 485000 | Loss: 0.060085313978485946\n",
      "Iteration: 486000 | Loss: 0.060085313978485946\n",
      "Iteration: 487000 | Loss: 0.060085313978485946\n",
      "Iteration: 488000 | Loss: 0.060085313978485946\n",
      "Iteration: 489000 | Loss: 0.060085313978485946\n",
      "Iteration: 490000 | Loss: 0.060085313978485946\n",
      "Iteration: 491000 | Loss: 0.060085313978485946\n",
      "Iteration: 492000 | Loss: 0.060085313978485946\n",
      "Iteration: 493000 | Loss: 0.060085313978485946\n",
      "Iteration: 494000 | Loss: 0.060085313978485946\n",
      "Iteration: 495000 | Loss: 0.060085313978485946\n",
      "Iteration: 496000 | Loss: 0.060085313978485946\n",
      "Iteration: 497000 | Loss: 0.060085313978485946\n",
      "Iteration: 498000 | Loss: 0.060085313978485946\n",
      "Iteration: 499000 | Loss: 0.060085313978485946\n",
      "Iteration: 500000 | Loss: 0.060085313978485946\n",
      "Iteration: 501000 | Loss: 0.060085313978485946\n",
      "Iteration: 502000 | Loss: 0.060085313978485946\n",
      "Iteration: 503000 | Loss: 0.060085313978485946\n",
      "Iteration: 504000 | Loss: 0.060085313978485946\n",
      "Iteration: 505000 | Loss: 0.060085313978485946\n",
      "Iteration: 506000 | Loss: 0.060085313978485946\n",
      "Iteration: 507000 | Loss: 0.060085313978485946\n",
      "Iteration: 508000 | Loss: 0.060085313978485946\n",
      "Iteration: 509000 | Loss: 0.060085313978485946\n",
      "Iteration: 510000 | Loss: 0.060085313978485946\n",
      "Iteration: 511000 | Loss: 0.060085313978485946\n",
      "Iteration: 512000 | Loss: 0.060085313978485946\n",
      "Iteration: 513000 | Loss: 0.060085313978485946\n",
      "Iteration: 514000 | Loss: 0.060085313978485946\n",
      "Iteration: 515000 | Loss: 0.060085313978485946\n",
      "Iteration: 516000 | Loss: 0.060085313978485946\n",
      "Iteration: 517000 | Loss: 0.060085313978485946\n",
      "Iteration: 518000 | Loss: 0.060085313978485946\n",
      "Iteration: 519000 | Loss: 0.060085313978485946\n",
      "Iteration: 520000 | Loss: 0.060085313978485946\n",
      "Iteration: 521000 | Loss: 0.060085313978485946\n",
      "Iteration: 522000 | Loss: 0.060085313978485946\n",
      "Iteration: 523000 | Loss: 0.060085313978485946\n",
      "Iteration: 524000 | Loss: 0.060085313978485946\n",
      "Iteration: 525000 | Loss: 0.060085313978485946\n",
      "Iteration: 526000 | Loss: 0.060085313978485946\n",
      "Iteration: 527000 | Loss: 0.060085313978485946\n",
      "Iteration: 528000 | Loss: 0.060085313978485946\n",
      "Iteration: 529000 | Loss: 0.060085313978485946\n",
      "Iteration: 530000 | Loss: 0.060085313978485946\n",
      "Iteration: 531000 | Loss: 0.060085313978485946\n",
      "Iteration: 532000 | Loss: 0.060085313978485946\n",
      "Iteration: 533000 | Loss: 0.060085313978485946\n",
      "Iteration: 534000 | Loss: 0.060085313978485946\n",
      "Iteration: 535000 | Loss: 0.060085313978485946\n",
      "Iteration: 536000 | Loss: 0.060085313978485946\n",
      "Iteration: 537000 | Loss: 0.060085313978485946\n",
      "Iteration: 538000 | Loss: 0.060085313978485946\n",
      "Iteration: 539000 | Loss: 0.060085313978485946\n",
      "Iteration: 540000 | Loss: 0.060085313978485946\n",
      "Iteration: 541000 | Loss: 0.060085313978485946\n",
      "Iteration: 542000 | Loss: 0.060085313978485946\n",
      "Iteration: 543000 | Loss: 0.060085313978485946\n",
      "Iteration: 544000 | Loss: 0.060085313978485946\n",
      "Iteration: 545000 | Loss: 0.060085313978485946\n",
      "Iteration: 546000 | Loss: 0.060085313978485946\n",
      "Iteration: 547000 | Loss: 0.060085313978485946\n",
      "Iteration: 548000 | Loss: 0.060085313978485946\n",
      "Iteration: 549000 | Loss: 0.060085313978485946\n",
      "Iteration: 550000 | Loss: 0.060085313978485946\n",
      "Iteration: 551000 | Loss: 0.060085313978485946\n",
      "Iteration: 552000 | Loss: 0.060085313978485946\n",
      "Iteration: 553000 | Loss: 0.060085313978485946\n",
      "Iteration: 554000 | Loss: 0.060085313978485946\n",
      "Iteration: 555000 | Loss: 0.060085313978485946\n",
      "Iteration: 556000 | Loss: 0.060085313978485946\n",
      "Iteration: 557000 | Loss: 0.060085313978485946\n",
      "Iteration: 558000 | Loss: 0.060085313978485946\n",
      "Iteration: 559000 | Loss: 0.060085313978485946\n",
      "Iteration: 560000 | Loss: 0.060085313978485946\n",
      "Iteration: 561000 | Loss: 0.060085313978485946\n",
      "Iteration: 562000 | Loss: 0.060085313978485946\n",
      "Iteration: 563000 | Loss: 0.060085313978485946\n",
      "Iteration: 564000 | Loss: 0.060085313978485946\n",
      "Iteration: 565000 | Loss: 0.060085313978485946\n",
      "Iteration: 566000 | Loss: 0.060085313978485946\n",
      "Iteration: 567000 | Loss: 0.060085313978485946\n",
      "Iteration: 568000 | Loss: 0.060085313978485946\n",
      "Iteration: 569000 | Loss: 0.060085313978485946\n",
      "Iteration: 570000 | Loss: 0.060085313978485946\n",
      "Iteration: 571000 | Loss: 0.060085313978485946\n",
      "Iteration: 572000 | Loss: 0.060085313978485946\n",
      "Iteration: 573000 | Loss: 0.060085313978485946\n",
      "Iteration: 574000 | Loss: 0.060085313978485946\n",
      "Iteration: 575000 | Loss: 0.060085313978485946\n",
      "Iteration: 576000 | Loss: 0.060085313978485946\n",
      "Iteration: 577000 | Loss: 0.060085313978485946\n",
      "Iteration: 578000 | Loss: 0.060085313978485946\n",
      "Iteration: 579000 | Loss: 0.060085313978485946\n",
      "Iteration: 580000 | Loss: 0.060085313978485946\n",
      "Iteration: 581000 | Loss: 0.060085313978485946\n",
      "Iteration: 582000 | Loss: 0.060085313978485946\n",
      "Iteration: 583000 | Loss: 0.060085313978485946\n",
      "Iteration: 584000 | Loss: 0.060085313978485946\n",
      "Iteration: 585000 | Loss: 0.060085313978485946\n",
      "Iteration: 586000 | Loss: 0.060085313978485946\n",
      "Iteration: 587000 | Loss: 0.060085313978485946\n",
      "Iteration: 588000 | Loss: 0.060085313978485946\n",
      "Iteration: 589000 | Loss: 0.060085313978485946\n",
      "Iteration: 590000 | Loss: 0.060085313978485946\n",
      "Iteration: 591000 | Loss: 0.060085313978485946\n",
      "Iteration: 592000 | Loss: 0.060085313978485946\n",
      "Iteration: 593000 | Loss: 0.060085313978485946\n",
      "Iteration: 594000 | Loss: 0.060085313978485946\n",
      "Iteration: 595000 | Loss: 0.060085313978485946\n",
      "Iteration: 596000 | Loss: 0.060085313978485946\n",
      "Iteration: 597000 | Loss: 0.060085313978485946\n",
      "Iteration: 598000 | Loss: 0.060085313978485946\n",
      "Iteration: 599000 | Loss: 0.060085313978485946\n",
      "Iteration: 600000 | Loss: 0.060085313978485946\n",
      "Iteration: 601000 | Loss: 0.060085313978485946\n",
      "Iteration: 602000 | Loss: 0.060085313978485946\n",
      "Iteration: 603000 | Loss: 0.060085313978485946\n",
      "Iteration: 604000 | Loss: 0.060085313978485946\n",
      "Iteration: 605000 | Loss: 0.060085313978485946\n",
      "Iteration: 606000 | Loss: 0.060085313978485946\n",
      "Iteration: 607000 | Loss: 0.060085313978485946\n",
      "Iteration: 608000 | Loss: 0.060085313978485946\n",
      "Iteration: 609000 | Loss: 0.060085313978485946\n",
      "Iteration: 610000 | Loss: 0.060085313978485946\n",
      "Iteration: 611000 | Loss: 0.060085313978485946\n",
      "Iteration: 612000 | Loss: 0.060085313978485946\n",
      "Iteration: 613000 | Loss: 0.060085313978485946\n",
      "Iteration: 614000 | Loss: 0.060085313978485946\n",
      "Iteration: 615000 | Loss: 0.060085313978485946\n",
      "Iteration: 616000 | Loss: 0.060085313978485946\n",
      "Iteration: 617000 | Loss: 0.060085313978485946\n",
      "Iteration: 618000 | Loss: 0.060085313978485946\n",
      "Iteration: 619000 | Loss: 0.060085313978485946\n",
      "Iteration: 620000 | Loss: 0.060085313978485946\n",
      "Iteration: 621000 | Loss: 0.060085313978485946\n",
      "Iteration: 622000 | Loss: 0.060085313978485946\n",
      "Iteration: 623000 | Loss: 0.060085313978485946\n",
      "Iteration: 624000 | Loss: 0.060085313978485946\n",
      "Iteration: 625000 | Loss: 0.060085313978485946\n",
      "Iteration: 626000 | Loss: 0.060085313978485946\n",
      "Iteration: 627000 | Loss: 0.060085313978485946\n",
      "Iteration: 628000 | Loss: 0.060085313978485946\n",
      "Iteration: 629000 | Loss: 0.060085313978485946\n",
      "Iteration: 630000 | Loss: 0.060085313978485946\n",
      "Iteration: 631000 | Loss: 0.060085313978485946\n",
      "Iteration: 632000 | Loss: 0.060085313978485946\n",
      "Iteration: 633000 | Loss: 0.060085313978485946\n",
      "Iteration: 634000 | Loss: 0.060085313978485946\n",
      "Iteration: 635000 | Loss: 0.060085313978485946\n",
      "Iteration: 636000 | Loss: 0.060085313978485946\n",
      "Iteration: 637000 | Loss: 0.060085313978485946\n",
      "Iteration: 638000 | Loss: 0.060085313978485946\n",
      "Iteration: 639000 | Loss: 0.060085313978485946\n",
      "Iteration: 640000 | Loss: 0.060085313978485946\n",
      "Iteration: 641000 | Loss: 0.060085313978485946\n",
      "Iteration: 642000 | Loss: 0.060085313978485946\n",
      "Iteration: 643000 | Loss: 0.060085313978485946\n",
      "Iteration: 644000 | Loss: 0.060085313978485946\n",
      "Iteration: 645000 | Loss: 0.060085313978485946\n",
      "Iteration: 646000 | Loss: 0.060085313978485946\n",
      "Iteration: 647000 | Loss: 0.060085313978485946\n",
      "Iteration: 648000 | Loss: 0.060085313978485946\n",
      "Iteration: 649000 | Loss: 0.060085313978485946\n",
      "Iteration: 650000 | Loss: 0.060085313978485946\n",
      "Iteration: 651000 | Loss: 0.060085313978485946\n",
      "Iteration: 652000 | Loss: 0.060085313978485946\n",
      "Iteration: 653000 | Loss: 0.060085313978485946\n",
      "Iteration: 654000 | Loss: 0.060085313978485946\n",
      "Iteration: 655000 | Loss: 0.060085313978485946\n",
      "Iteration: 656000 | Loss: 0.060085313978485946\n",
      "Iteration: 657000 | Loss: 0.060085313978485946\n",
      "Iteration: 658000 | Loss: 0.060085313978485946\n",
      "Iteration: 659000 | Loss: 0.060085313978485946\n",
      "Iteration: 660000 | Loss: 0.060085313978485946\n",
      "Iteration: 661000 | Loss: 0.060085313978485946\n",
      "Iteration: 662000 | Loss: 0.060085313978485946\n",
      "Iteration: 663000 | Loss: 0.060085313978485946\n",
      "Iteration: 664000 | Loss: 0.060085313978485946\n",
      "Iteration: 665000 | Loss: 0.060085313978485946\n",
      "Iteration: 666000 | Loss: 0.060085313978485946\n",
      "Iteration: 667000 | Loss: 0.060085313978485946\n",
      "Iteration: 668000 | Loss: 0.060085313978485946\n",
      "Iteration: 669000 | Loss: 0.060085313978485946\n",
      "Iteration: 670000 | Loss: 0.060085313978485946\n",
      "Iteration: 671000 | Loss: 0.060085313978485946\n",
      "Iteration: 672000 | Loss: 0.060085313978485946\n",
      "Iteration: 673000 | Loss: 0.060085313978485946\n",
      "Iteration: 674000 | Loss: 0.060085313978485946\n",
      "Iteration: 675000 | Loss: 0.060085313978485946\n",
      "Iteration: 676000 | Loss: 0.060085313978485946\n",
      "Iteration: 677000 | Loss: 0.060085313978485946\n",
      "Iteration: 678000 | Loss: 0.060085313978485946\n",
      "Iteration: 679000 | Loss: 0.060085313978485946\n",
      "Iteration: 680000 | Loss: 0.060085313978485946\n",
      "Iteration: 681000 | Loss: 0.060085313978485946\n",
      "Iteration: 682000 | Loss: 0.060085313978485946\n",
      "Iteration: 683000 | Loss: 0.060085313978485946\n",
      "Iteration: 684000 | Loss: 0.060085313978485946\n",
      "Iteration: 685000 | Loss: 0.060085313978485946\n",
      "Iteration: 686000 | Loss: 0.060085313978485946\n",
      "Iteration: 687000 | Loss: 0.060085313978485946\n",
      "Iteration: 688000 | Loss: 0.060085313978485946\n",
      "Iteration: 689000 | Loss: 0.060085313978485946\n",
      "Iteration: 690000 | Loss: 0.060085313978485946\n",
      "Iteration: 691000 | Loss: 0.060085313978485946\n",
      "Iteration: 692000 | Loss: 0.060085313978485946\n",
      "Iteration: 693000 | Loss: 0.060085313978485946\n",
      "Iteration: 694000 | Loss: 0.060085313978485946\n",
      "Iteration: 695000 | Loss: 0.060085313978485946\n",
      "Iteration: 696000 | Loss: 0.060085313978485946\n",
      "Iteration: 697000 | Loss: 0.060085313978485946\n",
      "Iteration: 698000 | Loss: 0.060085313978485946\n",
      "Iteration: 699000 | Loss: 0.060085313978485946\n",
      "Iteration: 700000 | Loss: 0.060085313978485946\n",
      "Iteration: 701000 | Loss: 0.060085313978485946\n",
      "Iteration: 702000 | Loss: 0.060085313978485946\n",
      "Iteration: 703000 | Loss: 0.060085313978485946\n",
      "Iteration: 704000 | Loss: 0.060085313978485946\n",
      "Iteration: 705000 | Loss: 0.060085313978485946\n",
      "Iteration: 706000 | Loss: 0.060085313978485946\n",
      "Iteration: 707000 | Loss: 0.060085313978485946\n",
      "Iteration: 708000 | Loss: 0.060085313978485946\n",
      "Iteration: 709000 | Loss: 0.060085313978485946\n",
      "Iteration: 710000 | Loss: 0.060085313978485946\n",
      "Iteration: 711000 | Loss: 0.060085313978485946\n",
      "Iteration: 712000 | Loss: 0.060085313978485946\n",
      "Iteration: 713000 | Loss: 0.060085313978485946\n",
      "Iteration: 714000 | Loss: 0.060085313978485946\n",
      "Iteration: 715000 | Loss: 0.060085313978485946\n",
      "Iteration: 716000 | Loss: 0.060085313978485946\n",
      "Iteration: 717000 | Loss: 0.060085313978485946\n",
      "Iteration: 718000 | Loss: 0.060085313978485946\n",
      "Iteration: 719000 | Loss: 0.060085313978485946\n",
      "Iteration: 720000 | Loss: 0.060085313978485946\n",
      "Iteration: 721000 | Loss: 0.060085313978485946\n",
      "Iteration: 722000 | Loss: 0.060085313978485946\n",
      "Iteration: 723000 | Loss: 0.060085313978485946\n",
      "Iteration: 724000 | Loss: 0.060085313978485946\n",
      "Iteration: 725000 | Loss: 0.060085313978485946\n",
      "Iteration: 726000 | Loss: 0.060085313978485946\n",
      "Iteration: 727000 | Loss: 0.060085313978485946\n",
      "Iteration: 728000 | Loss: 0.060085313978485946\n",
      "Iteration: 729000 | Loss: 0.060085313978485946\n",
      "Iteration: 730000 | Loss: 0.060085313978485946\n",
      "Iteration: 731000 | Loss: 0.060085313978485946\n",
      "Iteration: 732000 | Loss: 0.060085313978485946\n",
      "Iteration: 733000 | Loss: 0.060085313978485946\n",
      "Iteration: 734000 | Loss: 0.060085313978485946\n",
      "Iteration: 735000 | Loss: 0.060085313978485946\n",
      "Iteration: 736000 | Loss: 0.060085313978485946\n",
      "Iteration: 737000 | Loss: 0.060085313978485946\n",
      "Iteration: 738000 | Loss: 0.060085313978485946\n",
      "Iteration: 739000 | Loss: 0.060085313978485946\n",
      "Iteration: 740000 | Loss: 0.060085313978485946\n",
      "Iteration: 741000 | Loss: 0.060085313978485946\n",
      "Iteration: 742000 | Loss: 0.060085313978485946\n",
      "Iteration: 743000 | Loss: 0.060085313978485946\n",
      "Iteration: 744000 | Loss: 0.060085313978485946\n",
      "Iteration: 745000 | Loss: 0.060085313978485946\n",
      "Iteration: 746000 | Loss: 0.060085313978485946\n",
      "Iteration: 747000 | Loss: 0.060085313978485946\n",
      "Iteration: 748000 | Loss: 0.060085313978485946\n",
      "Iteration: 749000 | Loss: 0.060085313978485946\n",
      "Iteration: 750000 | Loss: 0.060085313978485946\n",
      "Iteration: 751000 | Loss: 0.060085313978485946\n",
      "Iteration: 752000 | Loss: 0.060085313978485946\n",
      "Iteration: 753000 | Loss: 0.060085313978485946\n",
      "Iteration: 754000 | Loss: 0.060085313978485946\n",
      "Iteration: 755000 | Loss: 0.060085313978485946\n",
      "Iteration: 756000 | Loss: 0.060085313978485946\n",
      "Iteration: 757000 | Loss: 0.060085313978485946\n",
      "Iteration: 758000 | Loss: 0.060085313978485946\n",
      "Iteration: 759000 | Loss: 0.060085313978485946\n",
      "Iteration: 760000 | Loss: 0.060085313978485946\n",
      "Iteration: 761000 | Loss: 0.060085313978485946\n",
      "Iteration: 762000 | Loss: 0.060085313978485946\n",
      "Iteration: 763000 | Loss: 0.060085313978485946\n",
      "Iteration: 764000 | Loss: 0.060085313978485946\n",
      "Iteration: 765000 | Loss: 0.060085313978485946\n",
      "Iteration: 766000 | Loss: 0.060085313978485946\n",
      "Iteration: 767000 | Loss: 0.060085313978485946\n",
      "Iteration: 768000 | Loss: 0.060085313978485946\n",
      "Iteration: 769000 | Loss: 0.060085313978485946\n",
      "Iteration: 770000 | Loss: 0.060085313978485946\n",
      "Iteration: 771000 | Loss: 0.060085313978485946\n",
      "Iteration: 772000 | Loss: 0.060085313978485946\n",
      "Iteration: 773000 | Loss: 0.060085313978485946\n",
      "Iteration: 774000 | Loss: 0.060085313978485946\n",
      "Iteration: 775000 | Loss: 0.060085313978485946\n",
      "Iteration: 776000 | Loss: 0.060085313978485946\n",
      "Iteration: 777000 | Loss: 0.060085313978485946\n",
      "Iteration: 778000 | Loss: 0.060085313978485946\n",
      "Iteration: 779000 | Loss: 0.060085313978485946\n",
      "Iteration: 780000 | Loss: 0.060085313978485946\n",
      "Iteration: 781000 | Loss: 0.060085313978485946\n",
      "Iteration: 782000 | Loss: 0.060085313978485946\n",
      "Iteration: 783000 | Loss: 0.060085313978485946\n",
      "Iteration: 784000 | Loss: 0.060085313978485946\n",
      "Iteration: 785000 | Loss: 0.060085313978485946\n",
      "Iteration: 786000 | Loss: 0.060085313978485946\n",
      "Iteration: 787000 | Loss: 0.060085313978485946\n",
      "Iteration: 788000 | Loss: 0.060085313978485946\n",
      "Iteration: 789000 | Loss: 0.060085313978485946\n",
      "Iteration: 790000 | Loss: 0.060085313978485946\n",
      "Iteration: 791000 | Loss: 0.060085313978485946\n",
      "Iteration: 792000 | Loss: 0.060085313978485946\n",
      "Iteration: 793000 | Loss: 0.060085313978485946\n",
      "Iteration: 794000 | Loss: 0.060085313978485946\n",
      "Iteration: 795000 | Loss: 0.060085313978485946\n",
      "Iteration: 796000 | Loss: 0.060085313978485946\n",
      "Iteration: 797000 | Loss: 0.060085313978485946\n",
      "Iteration: 798000 | Loss: 0.060085313978485946\n",
      "Iteration: 799000 | Loss: 0.060085313978485946\n",
      "Iteration: 800000 | Loss: 0.060085313978485946\n",
      "Iteration: 801000 | Loss: 0.060085313978485946\n",
      "Iteration: 802000 | Loss: 0.060085313978485946\n",
      "Iteration: 803000 | Loss: 0.060085313978485946\n",
      "Iteration: 804000 | Loss: 0.060085313978485946\n",
      "Iteration: 805000 | Loss: 0.060085313978485946\n",
      "Iteration: 806000 | Loss: 0.060085313978485946\n",
      "Iteration: 807000 | Loss: 0.060085313978485946\n",
      "Iteration: 808000 | Loss: 0.060085313978485946\n",
      "Iteration: 809000 | Loss: 0.060085313978485946\n",
      "Iteration: 810000 | Loss: 0.060085313978485946\n",
      "Iteration: 811000 | Loss: 0.060085313978485946\n",
      "Iteration: 812000 | Loss: 0.060085313978485946\n",
      "Iteration: 813000 | Loss: 0.060085313978485946\n",
      "Iteration: 814000 | Loss: 0.060085313978485946\n",
      "Iteration: 815000 | Loss: 0.060085313978485946\n",
      "Iteration: 816000 | Loss: 0.060085313978485946\n",
      "Iteration: 817000 | Loss: 0.060085313978485946\n",
      "Iteration: 818000 | Loss: 0.060085313978485946\n",
      "Iteration: 819000 | Loss: 0.060085313978485946\n",
      "Iteration: 820000 | Loss: 0.060085313978485946\n",
      "Iteration: 821000 | Loss: 0.060085313978485946\n",
      "Iteration: 822000 | Loss: 0.060085313978485946\n",
      "Iteration: 823000 | Loss: 0.060085313978485946\n",
      "Iteration: 824000 | Loss: 0.060085313978485946\n",
      "Iteration: 825000 | Loss: 0.060085313978485946\n",
      "Iteration: 826000 | Loss: 0.060085313978485946\n",
      "Iteration: 827000 | Loss: 0.060085313978485946\n",
      "Iteration: 828000 | Loss: 0.060085313978485946\n",
      "Iteration: 829000 | Loss: 0.060085313978485946\n",
      "Iteration: 830000 | Loss: 0.060085313978485946\n",
      "Iteration: 831000 | Loss: 0.060085313978485946\n",
      "Iteration: 832000 | Loss: 0.060085313978485946\n",
      "Iteration: 833000 | Loss: 0.060085313978485946\n",
      "Iteration: 834000 | Loss: 0.060085313978485946\n",
      "Iteration: 835000 | Loss: 0.060085313978485946\n",
      "Iteration: 836000 | Loss: 0.060085313978485946\n",
      "Iteration: 837000 | Loss: 0.060085313978485946\n",
      "Iteration: 838000 | Loss: 0.060085313978485946\n",
      "Iteration: 839000 | Loss: 0.060085313978485946\n",
      "Iteration: 840000 | Loss: 0.060085313978485946\n",
      "Iteration: 841000 | Loss: 0.060085313978485946\n",
      "Iteration: 842000 | Loss: 0.060085313978485946\n",
      "Iteration: 843000 | Loss: 0.060085313978485946\n",
      "Iteration: 844000 | Loss: 0.060085313978485946\n",
      "Iteration: 845000 | Loss: 0.060085313978485946\n",
      "Iteration: 846000 | Loss: 0.060085313978485946\n",
      "Iteration: 847000 | Loss: 0.060085313978485946\n",
      "Iteration: 848000 | Loss: 0.060085313978485946\n",
      "Iteration: 849000 | Loss: 0.060085313978485946\n",
      "Iteration: 850000 | Loss: 0.060085313978485946\n",
      "Iteration: 851000 | Loss: 0.060085313978485946\n",
      "Iteration: 852000 | Loss: 0.060085313978485946\n",
      "Iteration: 853000 | Loss: 0.060085313978485946\n",
      "Iteration: 854000 | Loss: 0.060085313978485946\n",
      "Iteration: 855000 | Loss: 0.060085313978485946\n",
      "Iteration: 856000 | Loss: 0.060085313978485946\n",
      "Iteration: 857000 | Loss: 0.060085313978485946\n",
      "Iteration: 858000 | Loss: 0.060085313978485946\n",
      "Iteration: 859000 | Loss: 0.060085313978485946\n",
      "Iteration: 860000 | Loss: 0.060085313978485946\n",
      "Iteration: 861000 | Loss: 0.060085313978485946\n",
      "Iteration: 862000 | Loss: 0.060085313978485946\n",
      "Iteration: 863000 | Loss: 0.060085313978485946\n",
      "Iteration: 864000 | Loss: 0.060085313978485946\n",
      "Iteration: 865000 | Loss: 0.060085313978485946\n",
      "Iteration: 866000 | Loss: 0.060085313978485946\n",
      "Iteration: 867000 | Loss: 0.060085313978485946\n",
      "Iteration: 868000 | Loss: 0.060085313978485946\n",
      "Iteration: 869000 | Loss: 0.060085313978485946\n",
      "Iteration: 870000 | Loss: 0.060085313978485946\n",
      "Iteration: 871000 | Loss: 0.060085313978485946\n",
      "Iteration: 872000 | Loss: 0.060085313978485946\n",
      "Iteration: 873000 | Loss: 0.060085313978485946\n",
      "Iteration: 874000 | Loss: 0.060085313978485946\n",
      "Iteration: 875000 | Loss: 0.060085313978485946\n",
      "Iteration: 876000 | Loss: 0.060085313978485946\n",
      "Iteration: 877000 | Loss: 0.060085313978485946\n",
      "Iteration: 878000 | Loss: 0.060085313978485946\n",
      "Iteration: 879000 | Loss: 0.060085313978485946\n",
      "Iteration: 880000 | Loss: 0.060085313978485946\n",
      "Iteration: 881000 | Loss: 0.060085313978485946\n",
      "Iteration: 882000 | Loss: 0.060085313978485946\n",
      "Iteration: 883000 | Loss: 0.060085313978485946\n",
      "Iteration: 884000 | Loss: 0.060085313978485946\n",
      "Iteration: 885000 | Loss: 0.060085313978485946\n",
      "Iteration: 886000 | Loss: 0.060085313978485946\n",
      "Iteration: 887000 | Loss: 0.060085313978485946\n",
      "Iteration: 888000 | Loss: 0.060085313978485946\n",
      "Iteration: 889000 | Loss: 0.060085313978485946\n",
      "Iteration: 890000 | Loss: 0.060085313978485946\n",
      "Iteration: 891000 | Loss: 0.060085313978485946\n",
      "Iteration: 892000 | Loss: 0.060085313978485946\n",
      "Iteration: 893000 | Loss: 0.060085313978485946\n",
      "Iteration: 894000 | Loss: 0.060085313978485946\n",
      "Iteration: 895000 | Loss: 0.060085313978485946\n",
      "Iteration: 896000 | Loss: 0.060085313978485946\n",
      "Iteration: 897000 | Loss: 0.060085313978485946\n",
      "Iteration: 898000 | Loss: 0.060085313978485946\n",
      "Iteration: 899000 | Loss: 0.060085313978485946\n",
      "Iteration: 900000 | Loss: 0.060085313978485946\n",
      "Iteration: 901000 | Loss: 0.060085313978485946\n",
      "Iteration: 902000 | Loss: 0.060085313978485946\n",
      "Iteration: 903000 | Loss: 0.060085313978485946\n",
      "Iteration: 904000 | Loss: 0.060085313978485946\n",
      "Iteration: 905000 | Loss: 0.060085313978485946\n",
      "Iteration: 906000 | Loss: 0.060085313978485946\n",
      "Iteration: 907000 | Loss: 0.060085313978485946\n",
      "Iteration: 908000 | Loss: 0.060085313978485946\n",
      "Iteration: 909000 | Loss: 0.060085313978485946\n",
      "Iteration: 910000 | Loss: 0.060085313978485946\n",
      "Iteration: 911000 | Loss: 0.060085313978485946\n",
      "Iteration: 912000 | Loss: 0.060085313978485946\n",
      "Iteration: 913000 | Loss: 0.060085313978485946\n",
      "Iteration: 914000 | Loss: 0.060085313978485946\n",
      "Iteration: 915000 | Loss: 0.060085313978485946\n",
      "Iteration: 916000 | Loss: 0.060085313978485946\n",
      "Iteration: 917000 | Loss: 0.060085313978485946\n",
      "Iteration: 918000 | Loss: 0.060085313978485946\n",
      "Iteration: 919000 | Loss: 0.060085313978485946\n",
      "Iteration: 920000 | Loss: 0.060085313978485946\n",
      "Iteration: 921000 | Loss: 0.060085313978485946\n",
      "Iteration: 922000 | Loss: 0.060085313978485946\n",
      "Iteration: 923000 | Loss: 0.060085313978485946\n",
      "Iteration: 924000 | Loss: 0.060085313978485946\n",
      "Iteration: 925000 | Loss: 0.060085313978485946\n",
      "Iteration: 926000 | Loss: 0.060085313978485946\n",
      "Iteration: 927000 | Loss: 0.060085313978485946\n",
      "Iteration: 928000 | Loss: 0.060085313978485946\n",
      "Iteration: 929000 | Loss: 0.060085313978485946\n",
      "Iteration: 930000 | Loss: 0.060085313978485946\n",
      "Iteration: 931000 | Loss: 0.060085313978485946\n",
      "Iteration: 932000 | Loss: 0.060085313978485946\n",
      "Iteration: 933000 | Loss: 0.060085313978485946\n",
      "Iteration: 934000 | Loss: 0.060085313978485946\n",
      "Iteration: 935000 | Loss: 0.060085313978485946\n",
      "Iteration: 936000 | Loss: 0.060085313978485946\n",
      "Iteration: 937000 | Loss: 0.060085313978485946\n",
      "Iteration: 938000 | Loss: 0.060085313978485946\n",
      "Iteration: 939000 | Loss: 0.060085313978485946\n",
      "Iteration: 940000 | Loss: 0.060085313978485946\n",
      "Iteration: 941000 | Loss: 0.060085313978485946\n",
      "Iteration: 942000 | Loss: 0.060085313978485946\n",
      "Iteration: 943000 | Loss: 0.060085313978485946\n",
      "Iteration: 944000 | Loss: 0.060085313978485946\n",
      "Iteration: 945000 | Loss: 0.060085313978485946\n",
      "Iteration: 946000 | Loss: 0.060085313978485946\n",
      "Iteration: 947000 | Loss: 0.060085313978485946\n",
      "Iteration: 948000 | Loss: 0.060085313978485946\n",
      "Iteration: 949000 | Loss: 0.060085313978485946\n",
      "Iteration: 950000 | Loss: 0.060085313978485946\n",
      "Iteration: 951000 | Loss: 0.060085313978485946\n",
      "Iteration: 952000 | Loss: 0.060085313978485946\n",
      "Iteration: 953000 | Loss: 0.060085313978485946\n",
      "Iteration: 954000 | Loss: 0.060085313978485946\n",
      "Iteration: 955000 | Loss: 0.060085313978485946\n",
      "Iteration: 956000 | Loss: 0.060085313978485946\n",
      "Iteration: 957000 | Loss: 0.060085313978485946\n",
      "Iteration: 958000 | Loss: 0.060085313978485946\n",
      "Iteration: 959000 | Loss: 0.060085313978485946\n",
      "Iteration: 960000 | Loss: 0.060085313978485946\n",
      "Iteration: 961000 | Loss: 0.060085313978485946\n",
      "Iteration: 962000 | Loss: 0.060085313978485946\n",
      "Iteration: 963000 | Loss: 0.060085313978485946\n",
      "Iteration: 964000 | Loss: 0.060085313978485946\n",
      "Iteration: 965000 | Loss: 0.060085313978485946\n",
      "Iteration: 966000 | Loss: 0.060085313978485946\n",
      "Iteration: 967000 | Loss: 0.060085313978485946\n",
      "Iteration: 968000 | Loss: 0.060085313978485946\n",
      "Iteration: 969000 | Loss: 0.060085313978485946\n",
      "Iteration: 970000 | Loss: 0.060085313978485946\n",
      "Iteration: 971000 | Loss: 0.060085313978485946\n",
      "Iteration: 972000 | Loss: 0.060085313978485946\n",
      "Iteration: 973000 | Loss: 0.060085313978485946\n",
      "Iteration: 974000 | Loss: 0.060085313978485946\n",
      "Iteration: 975000 | Loss: 0.060085313978485946\n",
      "Iteration: 976000 | Loss: 0.060085313978485946\n",
      "Iteration: 977000 | Loss: 0.060085313978485946\n",
      "Iteration: 978000 | Loss: 0.060085313978485946\n",
      "Iteration: 979000 | Loss: 0.060085313978485946\n",
      "Iteration: 980000 | Loss: 0.060085313978485946\n",
      "Iteration: 981000 | Loss: 0.060085313978485946\n",
      "Iteration: 982000 | Loss: 0.060085313978485946\n",
      "Iteration: 983000 | Loss: 0.060085313978485946\n",
      "Iteration: 984000 | Loss: 0.060085313978485946\n",
      "Iteration: 985000 | Loss: 0.060085313978485946\n",
      "Iteration: 986000 | Loss: 0.060085313978485946\n",
      "Iteration: 987000 | Loss: 0.060085313978485946\n",
      "Iteration: 988000 | Loss: 0.060085313978485946\n",
      "Iteration: 989000 | Loss: 0.060085313978485946\n",
      "Iteration: 990000 | Loss: 0.060085313978485946\n",
      "Iteration: 991000 | Loss: 0.060085313978485946\n",
      "Iteration: 992000 | Loss: 0.060085313978485946\n",
      "Iteration: 993000 | Loss: 0.060085313978485946\n",
      "Iteration: 994000 | Loss: 0.060085313978485946\n",
      "Iteration: 995000 | Loss: 0.060085313978485946\n",
      "Iteration: 996000 | Loss: 0.060085313978485946\n",
      "Iteration: 997000 | Loss: 0.060085313978485946\n",
      "Iteration: 998000 | Loss: 0.060085313978485946\n",
      "Iteration: 999000 | Loss: 0.060085313978485946\n",
      "Iteration: 1000000 | Loss: 0.060085313978485946\n",
      "Iteration: 1001000 | Loss: 0.060085313978485946\n",
      "Iteration: 1002000 | Loss: 0.060085313978485946\n",
      "Iteration: 1003000 | Loss: 0.060085313978485946\n",
      "Iteration: 1004000 | Loss: 0.060085313978485946\n",
      "Iteration: 1005000 | Loss: 0.060085313978485946\n",
      "Iteration: 1006000 | Loss: 0.060085313978485946\n",
      "Iteration: 1007000 | Loss: 0.060085313978485946\n",
      "Iteration: 1008000 | Loss: 0.060085313978485946\n",
      "Iteration: 1009000 | Loss: 0.060085313978485946\n",
      "Iteration: 1010000 | Loss: 0.060085313978485946\n",
      "Iteration: 1011000 | Loss: 0.060085313978485946\n",
      "Iteration: 1012000 | Loss: 0.060085313978485946\n",
      "Iteration: 1013000 | Loss: 0.060085313978485946\n",
      "Iteration: 1014000 | Loss: 0.060085313978485946\n",
      "Iteration: 1015000 | Loss: 0.060085313978485946\n",
      "Iteration: 1016000 | Loss: 0.060085313978485946\n",
      "Iteration: 1017000 | Loss: 0.060085313978485946\n",
      "Iteration: 1018000 | Loss: 0.060085313978485946\n",
      "Iteration: 1019000 | Loss: 0.060085313978485946\n",
      "Iteration: 1020000 | Loss: 0.060085313978485946\n",
      "Iteration: 1021000 | Loss: 0.060085313978485946\n",
      "Iteration: 1022000 | Loss: 0.060085313978485946\n",
      "Iteration: 1023000 | Loss: 0.060085313978485946\n",
      "Iteration: 1024000 | Loss: 0.060085313978485946\n",
      "Iteration: 1025000 | Loss: 0.060085313978485946\n",
      "Iteration: 1026000 | Loss: 0.060085313978485946\n",
      "Iteration: 1027000 | Loss: 0.060085313978485946\n",
      "Iteration: 1028000 | Loss: 0.060085313978485946\n",
      "Iteration: 1029000 | Loss: 0.060085313978485946\n",
      "Iteration: 1030000 | Loss: 0.060085313978485946\n",
      "Iteration: 1031000 | Loss: 0.060085313978485946\n",
      "Iteration: 1032000 | Loss: 0.060085313978485946\n",
      "Iteration: 1033000 | Loss: 0.060085313978485946\n",
      "Iteration: 1034000 | Loss: 0.060085313978485946\n",
      "Iteration: 1035000 | Loss: 0.060085313978485946\n",
      "Iteration: 1036000 | Loss: 0.060085313978485946\n",
      "Iteration: 1037000 | Loss: 0.060085313978485946\n",
      "Iteration: 1038000 | Loss: 0.060085313978485946\n",
      "Iteration: 1039000 | Loss: 0.060085313978485946\n",
      "Iteration: 1040000 | Loss: 0.060085313978485946\n",
      "Iteration: 1041000 | Loss: 0.060085313978485946\n",
      "Iteration: 1042000 | Loss: 0.060085313978485946\n",
      "Iteration: 1043000 | Loss: 0.060085313978485946\n",
      "Iteration: 1044000 | Loss: 0.060085313978485946\n",
      "Iteration: 1045000 | Loss: 0.060085313978485946\n",
      "Iteration: 1046000 | Loss: 0.060085313978485946\n",
      "Iteration: 1047000 | Loss: 0.060085313978485946\n",
      "Iteration: 1048000 | Loss: 0.060085313978485946\n",
      "Iteration: 1049000 | Loss: 0.060085313978485946\n",
      "Iteration: 1050000 | Loss: 0.060085313978485946\n",
      "Iteration: 1051000 | Loss: 0.060085313978485946\n",
      "Iteration: 1052000 | Loss: 0.060085313978485946\n",
      "Iteration: 1053000 | Loss: 0.060085313978485946\n",
      "Iteration: 1054000 | Loss: 0.060085313978485946\n",
      "Iteration: 1055000 | Loss: 0.060085313978485946\n",
      "Iteration: 1056000 | Loss: 0.060085313978485946\n",
      "Iteration: 1057000 | Loss: 0.060085313978485946\n",
      "Iteration: 1058000 | Loss: 0.060085313978485946\n",
      "Iteration: 1059000 | Loss: 0.060085313978485946\n",
      "Iteration: 1060000 | Loss: 0.060085313978485946\n",
      "Iteration: 1061000 | Loss: 0.060085313978485946\n",
      "Iteration: 1062000 | Loss: 0.060085313978485946\n",
      "Iteration: 1063000 | Loss: 0.060085313978485946\n",
      "Iteration: 1064000 | Loss: 0.060085313978485946\n",
      "Iteration: 1065000 | Loss: 0.060085313978485946\n",
      "Iteration: 1066000 | Loss: 0.060085313978485946\n",
      "Iteration: 1067000 | Loss: 0.060085313978485946\n",
      "Iteration: 1068000 | Loss: 0.060085313978485946\n",
      "Iteration: 1069000 | Loss: 0.060085313978485946\n",
      "Iteration: 1070000 | Loss: 0.060085313978485946\n",
      "Iteration: 1071000 | Loss: 0.060085313978485946\n",
      "Iteration: 1072000 | Loss: 0.060085313978485946\n",
      "Iteration: 1073000 | Loss: 0.060085313978485946\n",
      "Iteration: 1074000 | Loss: 0.060085313978485946\n",
      "Iteration: 1075000 | Loss: 0.060085313978485946\n",
      "Iteration: 1076000 | Loss: 0.060085313978485946\n",
      "Iteration: 1077000 | Loss: 0.060085313978485946\n",
      "Iteration: 1078000 | Loss: 0.060085313978485946\n",
      "Iteration: 1079000 | Loss: 0.060085313978485946\n",
      "Iteration: 1080000 | Loss: 0.060085313978485946\n",
      "Iteration: 1081000 | Loss: 0.060085313978485946\n",
      "Iteration: 1082000 | Loss: 0.060085313978485946\n",
      "Iteration: 1083000 | Loss: 0.060085313978485946\n",
      "Iteration: 1084000 | Loss: 0.060085313978485946\n",
      "Iteration: 1085000 | Loss: 0.060085313978485946\n",
      "Iteration: 1086000 | Loss: 0.060085313978485946\n",
      "Iteration: 1087000 | Loss: 0.060085313978485946\n",
      "Iteration: 1088000 | Loss: 0.060085313978485946\n",
      "Iteration: 1089000 | Loss: 0.060085313978485946\n",
      "Iteration: 1090000 | Loss: 0.060085313978485946\n",
      "Iteration: 1091000 | Loss: 0.060085313978485946\n",
      "Iteration: 1092000 | Loss: 0.060085313978485946\n",
      "Iteration: 1093000 | Loss: 0.060085313978485946\n",
      "Iteration: 1094000 | Loss: 0.060085313978485946\n",
      "Iteration: 1095000 | Loss: 0.060085313978485946\n",
      "Iteration: 1096000 | Loss: 0.060085313978485946\n",
      "Iteration: 1097000 | Loss: 0.060085313978485946\n",
      "Iteration: 1098000 | Loss: 0.060085313978485946\n",
      "Iteration: 1099000 | Loss: 0.060085313978485946\n",
      "Iteration: 1100000 | Loss: 0.060085313978485946\n",
      "Iteration: 1101000 | Loss: 0.060085313978485946\n",
      "Iteration: 1102000 | Loss: 0.060085313978485946\n",
      "Iteration: 1103000 | Loss: 0.060085313978485946\n",
      "Iteration: 1104000 | Loss: 0.060085313978485946\n",
      "Iteration: 1105000 | Loss: 0.060085313978485946\n",
      "Iteration: 1106000 | Loss: 0.060085313978485946\n",
      "Iteration: 1107000 | Loss: 0.060085313978485946\n",
      "Iteration: 1108000 | Loss: 0.060085313978485946\n",
      "Iteration: 1109000 | Loss: 0.060085313978485946\n",
      "Iteration: 1110000 | Loss: 0.060085313978485946\n",
      "Iteration: 1111000 | Loss: 0.060085313978485946\n",
      "Iteration: 1112000 | Loss: 0.060085313978485946\n",
      "Iteration: 1113000 | Loss: 0.060085313978485946\n",
      "Iteration: 1114000 | Loss: 0.060085313978485946\n",
      "Iteration: 1115000 | Loss: 0.060085313978485946\n",
      "Iteration: 1116000 | Loss: 0.060085313978485946\n",
      "Iteration: 1117000 | Loss: 0.060085313978485946\n",
      "Iteration: 1118000 | Loss: 0.060085313978485946\n",
      "Iteration: 1119000 | Loss: 0.060085313978485946\n",
      "Iteration: 1120000 | Loss: 0.060085313978485946\n",
      "Iteration: 1121000 | Loss: 0.060085313978485946\n",
      "Iteration: 1122000 | Loss: 0.060085313978485946\n",
      "Iteration: 1123000 | Loss: 0.060085313978485946\n",
      "Iteration: 1124000 | Loss: 0.060085313978485946\n",
      "Iteration: 1125000 | Loss: 0.060085313978485946\n",
      "Iteration: 1126000 | Loss: 0.060085313978485946\n",
      "Iteration: 1127000 | Loss: 0.060085313978485946\n",
      "Iteration: 1128000 | Loss: 0.060085313978485946\n",
      "Iteration: 1129000 | Loss: 0.060085313978485946\n",
      "Iteration: 1130000 | Loss: 0.060085313978485946\n",
      "Iteration: 1131000 | Loss: 0.060085313978485946\n",
      "Iteration: 1132000 | Loss: 0.060085313978485946\n",
      "Iteration: 1133000 | Loss: 0.060085313978485946\n",
      "Iteration: 1134000 | Loss: 0.060085313978485946\n",
      "Iteration: 1135000 | Loss: 0.060085313978485946\n",
      "Iteration: 1136000 | Loss: 0.060085313978485946\n",
      "Iteration: 1137000 | Loss: 0.060085313978485946\n",
      "Iteration: 1138000 | Loss: 0.060085313978485946\n",
      "Iteration: 1139000 | Loss: 0.060085313978485946\n",
      "Iteration: 1140000 | Loss: 0.060085313978485946\n",
      "Iteration: 1141000 | Loss: 0.060085313978485946\n",
      "Iteration: 1142000 | Loss: 0.060085313978485946\n",
      "Iteration: 1143000 | Loss: 0.060085313978485946\n",
      "Iteration: 1144000 | Loss: 0.060085313978485946\n",
      "Iteration: 1145000 | Loss: 0.060085313978485946\n",
      "Iteration: 1146000 | Loss: 0.060085313978485946\n",
      "Iteration: 1147000 | Loss: 0.060085313978485946\n",
      "Iteration: 1148000 | Loss: 0.060085313978485946\n",
      "Iteration: 1149000 | Loss: 0.060085313978485946\n",
      "Iteration: 1150000 | Loss: 0.060085313978485946\n",
      "Iteration: 1151000 | Loss: 0.060085313978485946\n",
      "Iteration: 1152000 | Loss: 0.060085313978485946\n",
      "Iteration: 1153000 | Loss: 0.060085313978485946\n",
      "Iteration: 1154000 | Loss: 0.060085313978485946\n",
      "Iteration: 1155000 | Loss: 0.060085313978485946\n",
      "Iteration: 1156000 | Loss: 0.060085313978485946\n",
      "Iteration: 1157000 | Loss: 0.060085313978485946\n",
      "Iteration: 1158000 | Loss: 0.060085313978485946\n",
      "Iteration: 1159000 | Loss: 0.060085313978485946\n",
      "Iteration: 1160000 | Loss: 0.060085313978485946\n",
      "Iteration: 1161000 | Loss: 0.060085313978485946\n",
      "Iteration: 1162000 | Loss: 0.060085313978485946\n",
      "Iteration: 1163000 | Loss: 0.060085313978485946\n",
      "Iteration: 1164000 | Loss: 0.060085313978485946\n",
      "Iteration: 1165000 | Loss: 0.060085313978485946\n",
      "Iteration: 1166000 | Loss: 0.060085313978485946\n",
      "Iteration: 1167000 | Loss: 0.060085313978485946\n",
      "Iteration: 1168000 | Loss: 0.060085313978485946\n",
      "Iteration: 1169000 | Loss: 0.060085313978485946\n",
      "Iteration: 1170000 | Loss: 0.060085313978485946\n",
      "Iteration: 1171000 | Loss: 0.060085313978485946\n",
      "Iteration: 1172000 | Loss: 0.060085313978485946\n",
      "Iteration: 1173000 | Loss: 0.060085313978485946\n",
      "Iteration: 1174000 | Loss: 0.060085313978485946\n",
      "Iteration: 1175000 | Loss: 0.060085313978485946\n",
      "Iteration: 1176000 | Loss: 0.060085313978485946\n",
      "Iteration: 1177000 | Loss: 0.060085313978485946\n",
      "Iteration: 1178000 | Loss: 0.060085313978485946\n",
      "Iteration: 1179000 | Loss: 0.060085313978485946\n",
      "Iteration: 1180000 | Loss: 0.060085313978485946\n",
      "Iteration: 1181000 | Loss: 0.060085313978485946\n",
      "Iteration: 1182000 | Loss: 0.060085313978485946\n",
      "Iteration: 1183000 | Loss: 0.060085313978485946\n",
      "Iteration: 1184000 | Loss: 0.060085313978485946\n",
      "Iteration: 1185000 | Loss: 0.060085313978485946\n",
      "Iteration: 1186000 | Loss: 0.060085313978485946\n",
      "Iteration: 1187000 | Loss: 0.060085313978485946\n",
      "Iteration: 1188000 | Loss: 0.060085313978485946\n",
      "Iteration: 1189000 | Loss: 0.060085313978485946\n",
      "Iteration: 1190000 | Loss: 0.060085313978485946\n",
      "Iteration: 1191000 | Loss: 0.060085313978485946\n",
      "Iteration: 1192000 | Loss: 0.060085313978485946\n",
      "Iteration: 1193000 | Loss: 0.060085313978485946\n",
      "Iteration: 1194000 | Loss: 0.060085313978485946\n",
      "Iteration: 1195000 | Loss: 0.060085313978485946\n",
      "Iteration: 1196000 | Loss: 0.060085313978485946\n",
      "Iteration: 1197000 | Loss: 0.060085313978485946\n",
      "Iteration: 1198000 | Loss: 0.060085313978485946\n",
      "Iteration: 1199000 | Loss: 0.060085313978485946\n",
      "Iteration: 1200000 | Loss: 0.060085313978485946\n",
      "Iteration: 1201000 | Loss: 0.060085313978485946\n",
      "Iteration: 1202000 | Loss: 0.060085313978485946\n",
      "Iteration: 1203000 | Loss: 0.060085313978485946\n",
      "Iteration: 1204000 | Loss: 0.060085313978485946\n",
      "Iteration: 1205000 | Loss: 0.060085313978485946\n",
      "Iteration: 1206000 | Loss: 0.060085313978485946\n",
      "Iteration: 1207000 | Loss: 0.060085313978485946\n",
      "Iteration: 1208000 | Loss: 0.060085313978485946\n",
      "Iteration: 1209000 | Loss: 0.060085313978485946\n",
      "Iteration: 1210000 | Loss: 0.060085313978485946\n",
      "Iteration: 1211000 | Loss: 0.060085313978485946\n",
      "Iteration: 1212000 | Loss: 0.060085313978485946\n",
      "Iteration: 1213000 | Loss: 0.060085313978485946\n",
      "Iteration: 1214000 | Loss: 0.060085313978485946\n",
      "Iteration: 1215000 | Loss: 0.060085313978485946\n",
      "Iteration: 1216000 | Loss: 0.060085313978485946\n",
      "Iteration: 1217000 | Loss: 0.060085313978485946\n",
      "Iteration: 1218000 | Loss: 0.060085313978485946\n",
      "Iteration: 1219000 | Loss: 0.060085313978485946\n",
      "Iteration: 1220000 | Loss: 0.060085313978485946\n",
      "Iteration: 1221000 | Loss: 0.060085313978485946\n",
      "Iteration: 1222000 | Loss: 0.060085313978485946\n",
      "Iteration: 1223000 | Loss: 0.060085313978485946\n",
      "Iteration: 1224000 | Loss: 0.060085313978485946\n",
      "Iteration: 1225000 | Loss: 0.060085313978485946\n",
      "Iteration: 1226000 | Loss: 0.060085313978485946\n",
      "Iteration: 1227000 | Loss: 0.060085313978485946\n",
      "Iteration: 1228000 | Loss: 0.060085313978485946\n",
      "Iteration: 1229000 | Loss: 0.060085313978485946\n",
      "Iteration: 1230000 | Loss: 0.060085313978485946\n",
      "Iteration: 1231000 | Loss: 0.060085313978485946\n",
      "Iteration: 1232000 | Loss: 0.060085313978485946\n",
      "Iteration: 1233000 | Loss: 0.060085313978485946\n",
      "Iteration: 1234000 | Loss: 0.060085313978485946\n",
      "Iteration: 1235000 | Loss: 0.060085313978485946\n",
      "Iteration: 1236000 | Loss: 0.060085313978485946\n",
      "Iteration: 1237000 | Loss: 0.060085313978485946\n",
      "Iteration: 1238000 | Loss: 0.060085313978485946\n",
      "Iteration: 1239000 | Loss: 0.060085313978485946\n",
      "Iteration: 1240000 | Loss: 0.060085313978485946\n",
      "Iteration: 1241000 | Loss: 0.060085313978485946\n",
      "Iteration: 1242000 | Loss: 0.060085313978485946\n",
      "Iteration: 1243000 | Loss: 0.060085313978485946\n",
      "Iteration: 1244000 | Loss: 0.060085313978485946\n",
      "Iteration: 1245000 | Loss: 0.060085313978485946\n",
      "Iteration: 1246000 | Loss: 0.060085313978485946\n",
      "Iteration: 1247000 | Loss: 0.060085313978485946\n",
      "Iteration: 1248000 | Loss: 0.060085313978485946\n",
      "Iteration: 1249000 | Loss: 0.060085313978485946\n",
      "Iteration: 1250000 | Loss: 0.060085313978485946\n",
      "Iteration: 1251000 | Loss: 0.060085313978485946\n",
      "Iteration: 1252000 | Loss: 0.060085313978485946\n",
      "Iteration: 1253000 | Loss: 0.060085313978485946\n",
      "Iteration: 1254000 | Loss: 0.060085313978485946\n",
      "Iteration: 1255000 | Loss: 0.060085313978485946\n",
      "Iteration: 1256000 | Loss: 0.060085313978485946\n",
      "Iteration: 1257000 | Loss: 0.060085313978485946\n",
      "Iteration: 1258000 | Loss: 0.060085313978485946\n",
      "Iteration: 1259000 | Loss: 0.060085313978485946\n",
      "Iteration: 1260000 | Loss: 0.060085313978485946\n",
      "Iteration: 1261000 | Loss: 0.060085313978485946\n",
      "Iteration: 1262000 | Loss: 0.060085313978485946\n",
      "Iteration: 1263000 | Loss: 0.060085313978485946\n",
      "Iteration: 1264000 | Loss: 0.060085313978485946\n",
      "Iteration: 1265000 | Loss: 0.060085313978485946\n",
      "Iteration: 1266000 | Loss: 0.060085313978485946\n",
      "Iteration: 1267000 | Loss: 0.060085313978485946\n",
      "Iteration: 1268000 | Loss: 0.060085313978485946\n",
      "Iteration: 1269000 | Loss: 0.060085313978485946\n",
      "Iteration: 1270000 | Loss: 0.060085313978485946\n",
      "Iteration: 1271000 | Loss: 0.060085313978485946\n",
      "Iteration: 1272000 | Loss: 0.060085313978485946\n",
      "Iteration: 1273000 | Loss: 0.060085313978485946\n",
      "Iteration: 1274000 | Loss: 0.060085313978485946\n",
      "Iteration: 1275000 | Loss: 0.060085313978485946\n",
      "Iteration: 1276000 | Loss: 0.060085313978485946\n",
      "Iteration: 1277000 | Loss: 0.060085313978485946\n",
      "Iteration: 1278000 | Loss: 0.060085313978485946\n",
      "Iteration: 1279000 | Loss: 0.060085313978485946\n",
      "Iteration: 1280000 | Loss: 0.060085313978485946\n",
      "Iteration: 1281000 | Loss: 0.060085313978485946\n",
      "Iteration: 1282000 | Loss: 0.060085313978485946\n",
      "Iteration: 1283000 | Loss: 0.060085313978485946\n",
      "Iteration: 1284000 | Loss: 0.060085313978485946\n",
      "Iteration: 1285000 | Loss: 0.060085313978485946\n",
      "Iteration: 1286000 | Loss: 0.060085313978485946\n",
      "Iteration: 1287000 | Loss: 0.060085313978485946\n",
      "Iteration: 1288000 | Loss: 0.060085313978485946\n",
      "Iteration: 1289000 | Loss: 0.060085313978485946\n",
      "Iteration: 1290000 | Loss: 0.060085313978485946\n",
      "Iteration: 1291000 | Loss: 0.060085313978485946\n",
      "Iteration: 1292000 | Loss: 0.060085313978485946\n",
      "Iteration: 1293000 | Loss: 0.060085313978485946\n",
      "Iteration: 1294000 | Loss: 0.060085313978485946\n",
      "Iteration: 1295000 | Loss: 0.060085313978485946\n",
      "Iteration: 1296000 | Loss: 0.060085313978485946\n",
      "Iteration: 1297000 | Loss: 0.060085313978485946\n",
      "Iteration: 1298000 | Loss: 0.060085313978485946\n",
      "Iteration: 1299000 | Loss: 0.060085313978485946\n",
      "Iteration: 1300000 | Loss: 0.060085313978485946\n",
      "Iteration: 1301000 | Loss: 0.060085313978485946\n",
      "Iteration: 1302000 | Loss: 0.060085313978485946\n",
      "Iteration: 1303000 | Loss: 0.060085313978485946\n",
      "Iteration: 1304000 | Loss: 0.060085313978485946\n",
      "Iteration: 1305000 | Loss: 0.060085313978485946\n",
      "Iteration: 1306000 | Loss: 0.060085313978485946\n",
      "Iteration: 1307000 | Loss: 0.060085313978485946\n",
      "Iteration: 1308000 | Loss: 0.060085313978485946\n",
      "Iteration: 1309000 | Loss: 0.060085313978485946\n",
      "Iteration: 1310000 | Loss: 0.060085313978485946\n",
      "Iteration: 1311000 | Loss: 0.060085313978485946\n",
      "Iteration: 1312000 | Loss: 0.060085313978485946\n",
      "Iteration: 1313000 | Loss: 0.060085313978485946\n",
      "Iteration: 1314000 | Loss: 0.060085313978485946\n",
      "Iteration: 1315000 | Loss: 0.060085313978485946\n",
      "Iteration: 1316000 | Loss: 0.060085313978485946\n",
      "Iteration: 1317000 | Loss: 0.060085313978485946\n",
      "Iteration: 1318000 | Loss: 0.060085313978485946\n",
      "Iteration: 1319000 | Loss: 0.060085313978485946\n",
      "Iteration: 1320000 | Loss: 0.060085313978485946\n",
      "Iteration: 1321000 | Loss: 0.060085313978485946\n",
      "Iteration: 1322000 | Loss: 0.060085313978485946\n",
      "Iteration: 1323000 | Loss: 0.060085313978485946\n",
      "Iteration: 1324000 | Loss: 0.060085313978485946\n",
      "Iteration: 1325000 | Loss: 0.060085313978485946\n",
      "Iteration: 1326000 | Loss: 0.060085313978485946\n",
      "Iteration: 1327000 | Loss: 0.060085313978485946\n",
      "Iteration: 1328000 | Loss: 0.060085313978485946\n",
      "Iteration: 1329000 | Loss: 0.060085313978485946\n",
      "Iteration: 1330000 | Loss: 0.060085313978485946\n",
      "Iteration: 1331000 | Loss: 0.060085313978485946\n",
      "Iteration: 1332000 | Loss: 0.060085313978485946\n",
      "Iteration: 1333000 | Loss: 0.060085313978485946\n",
      "Iteration: 1334000 | Loss: 0.060085313978485946\n",
      "Iteration: 1335000 | Loss: 0.060085313978485946\n",
      "Iteration: 1336000 | Loss: 0.060085313978485946\n",
      "Iteration: 1337000 | Loss: 0.060085313978485946\n",
      "Iteration: 1338000 | Loss: 0.060085313978485946\n",
      "Iteration: 1339000 | Loss: 0.060085313978485946\n",
      "Iteration: 1340000 | Loss: 0.060085313978485946\n",
      "Iteration: 1341000 | Loss: 0.060085313978485946\n",
      "Iteration: 1342000 | Loss: 0.060085313978485946\n",
      "Iteration: 1343000 | Loss: 0.060085313978485946\n",
      "Iteration: 1344000 | Loss: 0.060085313978485946\n",
      "Iteration: 1345000 | Loss: 0.060085313978485946\n",
      "Iteration: 1346000 | Loss: 0.060085313978485946\n",
      "Iteration: 1347000 | Loss: 0.060085313978485946\n",
      "Iteration: 1348000 | Loss: 0.060085313978485946\n",
      "Iteration: 1349000 | Loss: 0.060085313978485946\n",
      "Iteration: 1350000 | Loss: 0.060085313978485946\n",
      "Iteration: 1351000 | Loss: 0.060085313978485946\n",
      "Iteration: 1352000 | Loss: 0.060085313978485946\n",
      "Iteration: 1353000 | Loss: 0.060085313978485946\n",
      "Iteration: 1354000 | Loss: 0.060085313978485946\n",
      "Iteration: 1355000 | Loss: 0.060085313978485946\n",
      "Iteration: 1356000 | Loss: 0.060085313978485946\n",
      "Iteration: 1357000 | Loss: 0.060085313978485946\n",
      "Iteration: 1358000 | Loss: 0.060085313978485946\n",
      "Iteration: 1359000 | Loss: 0.060085313978485946\n",
      "Iteration: 1360000 | Loss: 0.060085313978485946\n",
      "Iteration: 1361000 | Loss: 0.060085313978485946\n",
      "Iteration: 1362000 | Loss: 0.060085313978485946\n",
      "Iteration: 1363000 | Loss: 0.060085313978485946\n",
      "Iteration: 1364000 | Loss: 0.060085313978485946\n",
      "Iteration: 1365000 | Loss: 0.060085313978485946\n",
      "Iteration: 1366000 | Loss: 0.060085313978485946\n",
      "Iteration: 1367000 | Loss: 0.060085313978485946\n",
      "Iteration: 1368000 | Loss: 0.060085313978485946\n",
      "Iteration: 1369000 | Loss: 0.060085313978485946\n",
      "Iteration: 1370000 | Loss: 0.060085313978485946\n",
      "Iteration: 1371000 | Loss: 0.060085313978485946\n",
      "Iteration: 1372000 | Loss: 0.060085313978485946\n",
      "Iteration: 1373000 | Loss: 0.060085313978485946\n",
      "Iteration: 1374000 | Loss: 0.060085313978485946\n",
      "Iteration: 1375000 | Loss: 0.060085313978485946\n",
      "Iteration: 1376000 | Loss: 0.060085313978485946\n",
      "Iteration: 1377000 | Loss: 0.060085313978485946\n",
      "Iteration: 1378000 | Loss: 0.060085313978485946\n",
      "Iteration: 1379000 | Loss: 0.060085313978485946\n",
      "Iteration: 1380000 | Loss: 0.060085313978485946\n",
      "Iteration: 1381000 | Loss: 0.060085313978485946\n",
      "Iteration: 1382000 | Loss: 0.060085313978485946\n",
      "Iteration: 1383000 | Loss: 0.060085313978485946\n",
      "Iteration: 1384000 | Loss: 0.060085313978485946\n",
      "Iteration: 1385000 | Loss: 0.060085313978485946\n",
      "Iteration: 1386000 | Loss: 0.060085313978485946\n",
      "Iteration: 1387000 | Loss: 0.060085313978485946\n",
      "Iteration: 1388000 | Loss: 0.060085313978485946\n",
      "Iteration: 1389000 | Loss: 0.060085313978485946\n",
      "Iteration: 1390000 | Loss: 0.060085313978485946\n",
      "Iteration: 1391000 | Loss: 0.060085313978485946\n",
      "Iteration: 1392000 | Loss: 0.060085313978485946\n",
      "Iteration: 1393000 | Loss: 0.060085313978485946\n",
      "Iteration: 1394000 | Loss: 0.060085313978485946\n",
      "Iteration: 1395000 | Loss: 0.060085313978485946\n",
      "Iteration: 1396000 | Loss: 0.060085313978485946\n",
      "Iteration: 1397000 | Loss: 0.060085313978485946\n",
      "Iteration: 1398000 | Loss: 0.060085313978485946\n",
      "Iteration: 1399000 | Loss: 0.060085313978485946\n",
      "Iteration: 1400000 | Loss: 0.060085313978485946\n",
      "Iteration: 1401000 | Loss: 0.060085313978485946\n",
      "Iteration: 1402000 | Loss: 0.060085313978485946\n",
      "Iteration: 1403000 | Loss: 0.060085313978485946\n",
      "Iteration: 1404000 | Loss: 0.060085313978485946\n",
      "Iteration: 1405000 | Loss: 0.060085313978485946\n",
      "Iteration: 1406000 | Loss: 0.060085313978485946\n",
      "Iteration: 1407000 | Loss: 0.060085313978485946\n",
      "Iteration: 1408000 | Loss: 0.060085313978485946\n",
      "Iteration: 1409000 | Loss: 0.060085313978485946\n",
      "Iteration: 1410000 | Loss: 0.060085313978485946\n",
      "Iteration: 1411000 | Loss: 0.060085313978485946\n",
      "Iteration: 1412000 | Loss: 0.060085313978485946\n",
      "Iteration: 1413000 | Loss: 0.060085313978485946\n",
      "Iteration: 1414000 | Loss: 0.060085313978485946\n",
      "Iteration: 1415000 | Loss: 0.060085313978485946\n",
      "Iteration: 1416000 | Loss: 0.060085313978485946\n",
      "Iteration: 1417000 | Loss: 0.060085313978485946\n",
      "Iteration: 1418000 | Loss: 0.060085313978485946\n",
      "Iteration: 1419000 | Loss: 0.060085313978485946\n",
      "Iteration: 1420000 | Loss: 0.060085313978485946\n",
      "Iteration: 1421000 | Loss: 0.060085313978485946\n",
      "Iteration: 1422000 | Loss: 0.060085313978485946\n",
      "Iteration: 1423000 | Loss: 0.060085313978485946\n",
      "Iteration: 1424000 | Loss: 0.060085313978485946\n",
      "Iteration: 1425000 | Loss: 0.060085313978485946\n",
      "Iteration: 1426000 | Loss: 0.060085313978485946\n",
      "Iteration: 1427000 | Loss: 0.060085313978485946\n",
      "Iteration: 1428000 | Loss: 0.060085313978485946\n",
      "Iteration: 1429000 | Loss: 0.060085313978485946\n",
      "Iteration: 1430000 | Loss: 0.060085313978485946\n",
      "Iteration: 1431000 | Loss: 0.060085313978485946\n",
      "Iteration: 1432000 | Loss: 0.060085313978485946\n",
      "Iteration: 1433000 | Loss: 0.060085313978485946\n",
      "Iteration: 1434000 | Loss: 0.060085313978485946\n",
      "Iteration: 1435000 | Loss: 0.060085313978485946\n",
      "Iteration: 1436000 | Loss: 0.060085313978485946\n",
      "Iteration: 1437000 | Loss: 0.060085313978485946\n",
      "Iteration: 1438000 | Loss: 0.060085313978485946\n",
      "Iteration: 1439000 | Loss: 0.060085313978485946\n",
      "Iteration: 1440000 | Loss: 0.060085313978485946\n",
      "Iteration: 1441000 | Loss: 0.060085313978485946\n",
      "Iteration: 1442000 | Loss: 0.060085313978485946\n",
      "Iteration: 1443000 | Loss: 0.060085313978485946\n",
      "Iteration: 1444000 | Loss: 0.060085313978485946\n",
      "Iteration: 1445000 | Loss: 0.060085313978485946\n",
      "Iteration: 1446000 | Loss: 0.060085313978485946\n",
      "Iteration: 1447000 | Loss: 0.060085313978485946\n",
      "Iteration: 1448000 | Loss: 0.060085313978485946\n",
      "Iteration: 1449000 | Loss: 0.060085313978485946\n",
      "Iteration: 1450000 | Loss: 0.060085313978485946\n",
      "Iteration: 1451000 | Loss: 0.060085313978485946\n",
      "Iteration: 1452000 | Loss: 0.060085313978485946\n",
      "Iteration: 1453000 | Loss: 0.060085313978485946\n",
      "Iteration: 1454000 | Loss: 0.060085313978485946\n",
      "Iteration: 1455000 | Loss: 0.060085313978485946\n",
      "Iteration: 1456000 | Loss: 0.060085313978485946\n",
      "Iteration: 1457000 | Loss: 0.060085313978485946\n",
      "Iteration: 1458000 | Loss: 0.060085313978485946\n",
      "Iteration: 1459000 | Loss: 0.060085313978485946\n",
      "Iteration: 1460000 | Loss: 0.060085313978485946\n",
      "Iteration: 1461000 | Loss: 0.060085313978485946\n",
      "Iteration: 1462000 | Loss: 0.060085313978485946\n",
      "Iteration: 1463000 | Loss: 0.060085313978485946\n",
      "Iteration: 1464000 | Loss: 0.060085313978485946\n",
      "Iteration: 1465000 | Loss: 0.060085313978485946\n",
      "Iteration: 1466000 | Loss: 0.060085313978485946\n",
      "Iteration: 1467000 | Loss: 0.060085313978485946\n",
      "Iteration: 1468000 | Loss: 0.060085313978485946\n",
      "Iteration: 1469000 | Loss: 0.060085313978485946\n",
      "Iteration: 1470000 | Loss: 0.060085313978485946\n",
      "Iteration: 1471000 | Loss: 0.060085313978485946\n",
      "Iteration: 1472000 | Loss: 0.060085313978485946\n",
      "Iteration: 1473000 | Loss: 0.060085313978485946\n",
      "Iteration: 1474000 | Loss: 0.060085313978485946\n",
      "Iteration: 1475000 | Loss: 0.060085313978485946\n",
      "Iteration: 1476000 | Loss: 0.060085313978485946\n",
      "Iteration: 1477000 | Loss: 0.060085313978485946\n",
      "Iteration: 1478000 | Loss: 0.060085313978485946\n",
      "Iteration: 1479000 | Loss: 0.060085313978485946\n",
      "Iteration: 1480000 | Loss: 0.060085313978485946\n",
      "Iteration: 1481000 | Loss: 0.060085313978485946\n",
      "Iteration: 1482000 | Loss: 0.060085313978485946\n",
      "Iteration: 1483000 | Loss: 0.060085313978485946\n",
      "Iteration: 1484000 | Loss: 0.060085313978485946\n",
      "Iteration: 1485000 | Loss: 0.060085313978485946\n",
      "Iteration: 1486000 | Loss: 0.060085313978485946\n",
      "Iteration: 1487000 | Loss: 0.060085313978485946\n",
      "Iteration: 1488000 | Loss: 0.060085313978485946\n",
      "Iteration: 1489000 | Loss: 0.060085313978485946\n",
      "Iteration: 1490000 | Loss: 0.060085313978485946\n",
      "Iteration: 1491000 | Loss: 0.060085313978485946\n",
      "Iteration: 1492000 | Loss: 0.060085313978485946\n",
      "Iteration: 1493000 | Loss: 0.060085313978485946\n",
      "Iteration: 1494000 | Loss: 0.060085313978485946\n",
      "Iteration: 1495000 | Loss: 0.060085313978485946\n",
      "Iteration: 1496000 | Loss: 0.060085313978485946\n",
      "Iteration: 1497000 | Loss: 0.060085313978485946\n",
      "Iteration: 1498000 | Loss: 0.060085313978485946\n",
      "Iteration: 1499000 | Loss: 0.060085313978485946\n",
      "Iteration: 1500000 | Loss: 0.060085313978485946\n",
      "Iteration: 1501000 | Loss: 0.060085313978485946\n",
      "Iteration: 1502000 | Loss: 0.060085313978485946\n",
      "Iteration: 1503000 | Loss: 0.060085313978485946\n",
      "Iteration: 1504000 | Loss: 0.060085313978485946\n",
      "Iteration: 1505000 | Loss: 0.060085313978485946\n",
      "Iteration: 1506000 | Loss: 0.060085313978485946\n",
      "Iteration: 1507000 | Loss: 0.060085313978485946\n",
      "Iteration: 1508000 | Loss: 0.060085313978485946\n",
      "Iteration: 1509000 | Loss: 0.060085313978485946\n",
      "Iteration: 1510000 | Loss: 0.060085313978485946\n",
      "Iteration: 1511000 | Loss: 0.060085313978485946\n",
      "Iteration: 1512000 | Loss: 0.060085313978485946\n",
      "Iteration: 1513000 | Loss: 0.060085313978485946\n",
      "Iteration: 1514000 | Loss: 0.060085313978485946\n",
      "Iteration: 1515000 | Loss: 0.060085313978485946\n",
      "Iteration: 1516000 | Loss: 0.060085313978485946\n",
      "Iteration: 1517000 | Loss: 0.060085313978485946\n",
      "Iteration: 1518000 | Loss: 0.060085313978485946\n",
      "Iteration: 1519000 | Loss: 0.060085313978485946\n",
      "Iteration: 1520000 | Loss: 0.060085313978485946\n",
      "Iteration: 1521000 | Loss: 0.060085313978485946\n",
      "Iteration: 1522000 | Loss: 0.060085313978485946\n",
      "Iteration: 1523000 | Loss: 0.060085313978485946\n",
      "Iteration: 1524000 | Loss: 0.060085313978485946\n",
      "Iteration: 1525000 | Loss: 0.060085313978485946\n",
      "Iteration: 1526000 | Loss: 0.060085313978485946\n",
      "Iteration: 1527000 | Loss: 0.060085313978485946\n",
      "Iteration: 1528000 | Loss: 0.060085313978485946\n",
      "Iteration: 1529000 | Loss: 0.060085313978485946\n",
      "Iteration: 1530000 | Loss: 0.060085313978485946\n",
      "Iteration: 1531000 | Loss: 0.060085313978485946\n",
      "Iteration: 1532000 | Loss: 0.060085313978485946\n",
      "Iteration: 1533000 | Loss: 0.060085313978485946\n",
      "Iteration: 1534000 | Loss: 0.060085313978485946\n",
      "Iteration: 1535000 | Loss: 0.060085313978485946\n",
      "Iteration: 1536000 | Loss: 0.060085313978485946\n",
      "Iteration: 1537000 | Loss: 0.060085313978485946\n",
      "Iteration: 1538000 | Loss: 0.060085313978485946\n",
      "Iteration: 1539000 | Loss: 0.060085313978485946\n",
      "Iteration: 1540000 | Loss: 0.060085313978485946\n",
      "Iteration: 1541000 | Loss: 0.060085313978485946\n",
      "Iteration: 1542000 | Loss: 0.060085313978485946\n",
      "Iteration: 1543000 | Loss: 0.060085313978485946\n",
      "Iteration: 1544000 | Loss: 0.060085313978485946\n",
      "Iteration: 1545000 | Loss: 0.060085313978485946\n",
      "Iteration: 1546000 | Loss: 0.060085313978485946\n",
      "Iteration: 1547000 | Loss: 0.060085313978485946\n",
      "Iteration: 1548000 | Loss: 0.060085313978485946\n",
      "Iteration: 1549000 | Loss: 0.060085313978485946\n",
      "Iteration: 1550000 | Loss: 0.060085313978485946\n",
      "Iteration: 1551000 | Loss: 0.060085313978485946\n",
      "Iteration: 1552000 | Loss: 0.060085313978485946\n",
      "Iteration: 1553000 | Loss: 0.060085313978485946\n",
      "Iteration: 1554000 | Loss: 0.060085313978485946\n",
      "Iteration: 1555000 | Loss: 0.060085313978485946\n",
      "Iteration: 1556000 | Loss: 0.060085313978485946\n",
      "Iteration: 1557000 | Loss: 0.060085313978485946\n",
      "Iteration: 1558000 | Loss: 0.060085313978485946\n",
      "Iteration: 1559000 | Loss: 0.060085313978485946\n",
      "Iteration: 1560000 | Loss: 0.060085313978485946\n",
      "Iteration: 1561000 | Loss: 0.060085313978485946\n",
      "Iteration: 1562000 | Loss: 0.060085313978485946\n",
      "Iteration: 1563000 | Loss: 0.060085313978485946\n",
      "Iteration: 1564000 | Loss: 0.060085313978485946\n",
      "Iteration: 1565000 | Loss: 0.060085313978485946\n",
      "Iteration: 1566000 | Loss: 0.060085313978485946\n",
      "Iteration: 1567000 | Loss: 0.060085313978485946\n",
      "Iteration: 1568000 | Loss: 0.060085313978485946\n",
      "Iteration: 1569000 | Loss: 0.060085313978485946\n",
      "Iteration: 1570000 | Loss: 0.060085313978485946\n",
      "Iteration: 1571000 | Loss: 0.060085313978485946\n",
      "Iteration: 1572000 | Loss: 0.060085313978485946\n",
      "Iteration: 1573000 | Loss: 0.060085313978485946\n",
      "Iteration: 1574000 | Loss: 0.060085313978485946\n",
      "Iteration: 1575000 | Loss: 0.060085313978485946\n",
      "Iteration: 1576000 | Loss: 0.060085313978485946\n",
      "Iteration: 1577000 | Loss: 0.060085313978485946\n",
      "Iteration: 1578000 | Loss: 0.060085313978485946\n",
      "Iteration: 1579000 | Loss: 0.060085313978485946\n",
      "Iteration: 1580000 | Loss: 0.060085313978485946\n",
      "Iteration: 1581000 | Loss: 0.060085313978485946\n",
      "Iteration: 1582000 | Loss: 0.060085313978485946\n",
      "Iteration: 1583000 | Loss: 0.060085313978485946\n",
      "Iteration: 1584000 | Loss: 0.060085313978485946\n",
      "Iteration: 1585000 | Loss: 0.060085313978485946\n",
      "Iteration: 1586000 | Loss: 0.060085313978485946\n",
      "Iteration: 1587000 | Loss: 0.060085313978485946\n",
      "Iteration: 1588000 | Loss: 0.060085313978485946\n",
      "Iteration: 1589000 | Loss: 0.060085313978485946\n",
      "Iteration: 1590000 | Loss: 0.060085313978485946\n",
      "Iteration: 1591000 | Loss: 0.060085313978485946\n",
      "Iteration: 1592000 | Loss: 0.060085313978485946\n",
      "Iteration: 1593000 | Loss: 0.060085313978485946\n",
      "Iteration: 1594000 | Loss: 0.060085313978485946\n",
      "Iteration: 1595000 | Loss: 0.060085313978485946\n",
      "Iteration: 1596000 | Loss: 0.060085313978485946\n",
      "Iteration: 1597000 | Loss: 0.060085313978485946\n",
      "Iteration: 1598000 | Loss: 0.060085313978485946\n",
      "Iteration: 1599000 | Loss: 0.060085313978485946\n",
      "Iteration: 1600000 | Loss: 0.060085313978485946\n",
      "Iteration: 1601000 | Loss: 0.060085313978485946\n",
      "Iteration: 1602000 | Loss: 0.060085313978485946\n",
      "Iteration: 1603000 | Loss: 0.060085313978485946\n",
      "Iteration: 1604000 | Loss: 0.060085313978485946\n",
      "Iteration: 1605000 | Loss: 0.060085313978485946\n",
      "Iteration: 1606000 | Loss: 0.060085313978485946\n",
      "Iteration: 1607000 | Loss: 0.060085313978485946\n",
      "Iteration: 1608000 | Loss: 0.060085313978485946\n",
      "Iteration: 1609000 | Loss: 0.060085313978485946\n",
      "Iteration: 1610000 | Loss: 0.060085313978485946\n",
      "Iteration: 1611000 | Loss: 0.060085313978485946\n",
      "Iteration: 1612000 | Loss: 0.060085313978485946\n",
      "Iteration: 1613000 | Loss: 0.060085313978485946\n",
      "Iteration: 1614000 | Loss: 0.060085313978485946\n",
      "Iteration: 1615000 | Loss: 0.060085313978485946\n",
      "Iteration: 1616000 | Loss: 0.060085313978485946\n",
      "Iteration: 1617000 | Loss: 0.060085313978485946\n",
      "Iteration: 1618000 | Loss: 0.060085313978485946\n",
      "Iteration: 1619000 | Loss: 0.060085313978485946\n",
      "Iteration: 1620000 | Loss: 0.060085313978485946\n",
      "Iteration: 1621000 | Loss: 0.060085313978485946\n",
      "Iteration: 1622000 | Loss: 0.060085313978485946\n",
      "Iteration: 1623000 | Loss: 0.060085313978485946\n",
      "Iteration: 1624000 | Loss: 0.060085313978485946\n",
      "Iteration: 1625000 | Loss: 0.060085313978485946\n",
      "Iteration: 1626000 | Loss: 0.060085313978485946\n",
      "Iteration: 1627000 | Loss: 0.060085313978485946\n",
      "Iteration: 1628000 | Loss: 0.060085313978485946\n",
      "Iteration: 1629000 | Loss: 0.060085313978485946\n",
      "Iteration: 1630000 | Loss: 0.060085313978485946\n",
      "Iteration: 1631000 | Loss: 0.060085313978485946\n",
      "Iteration: 1632000 | Loss: 0.060085313978485946\n",
      "Iteration: 1633000 | Loss: 0.060085313978485946\n",
      "Iteration: 1634000 | Loss: 0.060085313978485946\n",
      "Iteration: 1635000 | Loss: 0.060085313978485946\n",
      "Iteration: 1636000 | Loss: 0.060085313978485946\n",
      "Iteration: 1637000 | Loss: 0.060085313978485946\n",
      "Iteration: 1638000 | Loss: 0.060085313978485946\n",
      "Iteration: 1639000 | Loss: 0.060085313978485946\n",
      "Iteration: 1640000 | Loss: 0.060085313978485946\n",
      "Iteration: 1641000 | Loss: 0.060085313978485946\n",
      "Iteration: 1642000 | Loss: 0.060085313978485946\n",
      "Iteration: 1643000 | Loss: 0.060085313978485946\n",
      "Iteration: 1644000 | Loss: 0.060085313978485946\n",
      "Iteration: 1645000 | Loss: 0.060085313978485946\n",
      "Iteration: 1646000 | Loss: 0.060085313978485946\n",
      "Iteration: 1647000 | Loss: 0.060085313978485946\n",
      "Iteration: 1648000 | Loss: 0.060085313978485946\n",
      "Iteration: 1649000 | Loss: 0.060085313978485946\n",
      "Iteration: 1650000 | Loss: 0.060085313978485946\n",
      "Iteration: 1651000 | Loss: 0.060085313978485946\n",
      "Iteration: 1652000 | Loss: 0.060085313978485946\n",
      "Iteration: 1653000 | Loss: 0.060085313978485946\n",
      "Iteration: 1654000 | Loss: 0.060085313978485946\n",
      "Iteration: 1655000 | Loss: 0.060085313978485946\n",
      "Iteration: 1656000 | Loss: 0.060085313978485946\n",
      "Iteration: 1657000 | Loss: 0.060085313978485946\n",
      "Iteration: 1658000 | Loss: 0.060085313978485946\n",
      "Iteration: 1659000 | Loss: 0.060085313978485946\n",
      "Iteration: 1660000 | Loss: 0.060085313978485946\n",
      "Iteration: 1661000 | Loss: 0.060085313978485946\n",
      "Iteration: 1662000 | Loss: 0.060085313978485946\n",
      "Iteration: 1663000 | Loss: 0.060085313978485946\n",
      "Iteration: 1664000 | Loss: 0.060085313978485946\n",
      "Iteration: 1665000 | Loss: 0.060085313978485946\n",
      "Iteration: 1666000 | Loss: 0.060085313978485946\n",
      "Iteration: 1667000 | Loss: 0.060085313978485946\n",
      "Iteration: 1668000 | Loss: 0.060085313978485946\n",
      "Iteration: 1669000 | Loss: 0.060085313978485946\n",
      "Iteration: 1670000 | Loss: 0.060085313978485946\n",
      "Iteration: 1671000 | Loss: 0.060085313978485946\n",
      "Iteration: 1672000 | Loss: 0.060085313978485946\n",
      "Iteration: 1673000 | Loss: 0.060085313978485946\n",
      "Iteration: 1674000 | Loss: 0.060085313978485946\n",
      "Iteration: 1675000 | Loss: 0.060085313978485946\n",
      "Iteration: 1676000 | Loss: 0.060085313978485946\n",
      "Iteration: 1677000 | Loss: 0.060085313978485946\n",
      "Iteration: 1678000 | Loss: 0.060085313978485946\n",
      "Iteration: 1679000 | Loss: 0.060085313978485946\n",
      "Iteration: 1680000 | Loss: 0.060085313978485946\n",
      "Iteration: 1681000 | Loss: 0.060085313978485946\n",
      "Iteration: 1682000 | Loss: 0.060085313978485946\n",
      "Iteration: 1683000 | Loss: 0.060085313978485946\n",
      "Iteration: 1684000 | Loss: 0.060085313978485946\n",
      "Iteration: 1685000 | Loss: 0.060085313978485946\n",
      "Iteration: 1686000 | Loss: 0.060085313978485946\n",
      "Iteration: 1687000 | Loss: 0.060085313978485946\n",
      "Iteration: 1688000 | Loss: 0.060085313978485946\n",
      "Iteration: 1689000 | Loss: 0.060085313978485946\n",
      "Iteration: 1690000 | Loss: 0.060085313978485946\n",
      "Iteration: 1691000 | Loss: 0.060085313978485946\n",
      "Iteration: 1692000 | Loss: 0.060085313978485946\n",
      "Iteration: 1693000 | Loss: 0.060085313978485946\n",
      "Iteration: 1694000 | Loss: 0.060085313978485946\n",
      "Iteration: 1695000 | Loss: 0.060085313978485946\n",
      "Iteration: 1696000 | Loss: 0.060085313978485946\n",
      "Iteration: 1697000 | Loss: 0.060085313978485946\n",
      "Iteration: 1698000 | Loss: 0.060085313978485946\n",
      "Iteration: 1699000 | Loss: 0.060085313978485946\n",
      "Iteration: 1700000 | Loss: 0.060085313978485946\n",
      "Iteration: 1701000 | Loss: 0.060085313978485946\n",
      "Iteration: 1702000 | Loss: 0.060085313978485946\n",
      "Iteration: 1703000 | Loss: 0.060085313978485946\n",
      "Iteration: 1704000 | Loss: 0.060085313978485946\n",
      "Iteration: 1705000 | Loss: 0.060085313978485946\n",
      "Iteration: 1706000 | Loss: 0.060085313978485946\n",
      "Iteration: 1707000 | Loss: 0.060085313978485946\n",
      "Iteration: 1708000 | Loss: 0.060085313978485946\n",
      "Iteration: 1709000 | Loss: 0.060085313978485946\n",
      "Iteration: 1710000 | Loss: 0.060085313978485946\n",
      "Iteration: 1711000 | Loss: 0.060085313978485946\n",
      "Iteration: 1712000 | Loss: 0.060085313978485946\n",
      "Iteration: 1713000 | Loss: 0.060085313978485946\n",
      "Iteration: 1714000 | Loss: 0.060085313978485946\n",
      "Iteration: 1715000 | Loss: 0.060085313978485946\n",
      "Iteration: 1716000 | Loss: 0.060085313978485946\n",
      "Iteration: 1717000 | Loss: 0.060085313978485946\n",
      "Iteration: 1718000 | Loss: 0.060085313978485946\n",
      "Iteration: 1719000 | Loss: 0.060085313978485946\n",
      "Iteration: 1720000 | Loss: 0.060085313978485946\n",
      "Iteration: 1721000 | Loss: 0.060085313978485946\n",
      "Iteration: 1722000 | Loss: 0.060085313978485946\n",
      "Iteration: 1723000 | Loss: 0.060085313978485946\n",
      "Iteration: 1724000 | Loss: 0.060085313978485946\n",
      "Iteration: 1725000 | Loss: 0.060085313978485946\n",
      "Iteration: 1726000 | Loss: 0.060085313978485946\n",
      "Iteration: 1727000 | Loss: 0.060085313978485946\n",
      "Iteration: 1728000 | Loss: 0.060085313978485946\n",
      "Iteration: 1729000 | Loss: 0.060085313978485946\n",
      "Iteration: 1730000 | Loss: 0.060085313978485946\n",
      "Iteration: 1731000 | Loss: 0.060085313978485946\n",
      "Iteration: 1732000 | Loss: 0.060085313978485946\n",
      "Iteration: 1733000 | Loss: 0.060085313978485946\n",
      "Iteration: 1734000 | Loss: 0.060085313978485946\n",
      "Iteration: 1735000 | Loss: 0.060085313978485946\n",
      "Iteration: 1736000 | Loss: 0.060085313978485946\n",
      "Iteration: 1737000 | Loss: 0.060085313978485946\n",
      "Iteration: 1738000 | Loss: 0.060085313978485946\n",
      "Iteration: 1739000 | Loss: 0.060085313978485946\n",
      "Iteration: 1740000 | Loss: 0.060085313978485946\n",
      "Iteration: 1741000 | Loss: 0.060085313978485946\n",
      "Iteration: 1742000 | Loss: 0.060085313978485946\n",
      "Iteration: 1743000 | Loss: 0.060085313978485946\n",
      "Iteration: 1744000 | Loss: 0.060085313978485946\n",
      "Iteration: 1745000 | Loss: 0.060085313978485946\n",
      "Iteration: 1746000 | Loss: 0.060085313978485946\n",
      "Iteration: 1747000 | Loss: 0.060085313978485946\n",
      "Iteration: 1748000 | Loss: 0.060085313978485946\n",
      "Iteration: 1749000 | Loss: 0.060085313978485946\n",
      "Iteration: 1750000 | Loss: 0.060085313978485946\n",
      "Iteration: 1751000 | Loss: 0.060085313978485946\n",
      "Iteration: 1752000 | Loss: 0.060085313978485946\n",
      "Iteration: 1753000 | Loss: 0.060085313978485946\n",
      "Iteration: 1754000 | Loss: 0.060085313978485946\n",
      "Iteration: 1755000 | Loss: 0.060085313978485946\n",
      "Iteration: 1756000 | Loss: 0.060085313978485946\n",
      "Iteration: 1757000 | Loss: 0.060085313978485946\n",
      "Iteration: 1758000 | Loss: 0.060085313978485946\n",
      "Iteration: 1759000 | Loss: 0.060085313978485946\n",
      "Iteration: 1760000 | Loss: 0.060085313978485946\n",
      "Iteration: 1761000 | Loss: 0.060085313978485946\n",
      "Iteration: 1762000 | Loss: 0.060085313978485946\n",
      "Iteration: 1763000 | Loss: 0.060085313978485946\n",
      "Iteration: 1764000 | Loss: 0.060085313978485946\n",
      "Iteration: 1765000 | Loss: 0.060085313978485946\n",
      "Iteration: 1766000 | Loss: 0.060085313978485946\n",
      "Iteration: 1767000 | Loss: 0.060085313978485946\n",
      "Iteration: 1768000 | Loss: 0.060085313978485946\n",
      "Iteration: 1769000 | Loss: 0.060085313978485946\n",
      "Iteration: 1770000 | Loss: 0.060085313978485946\n",
      "Iteration: 1771000 | Loss: 0.060085313978485946\n",
      "Iteration: 1772000 | Loss: 0.060085313978485946\n",
      "Iteration: 1773000 | Loss: 0.060085313978485946\n",
      "Iteration: 1774000 | Loss: 0.060085313978485946\n",
      "Iteration: 1775000 | Loss: 0.060085313978485946\n",
      "Iteration: 1776000 | Loss: 0.060085313978485946\n",
      "Iteration: 1777000 | Loss: 0.060085313978485946\n",
      "Iteration: 1778000 | Loss: 0.060085313978485946\n",
      "Iteration: 1779000 | Loss: 0.060085313978485946\n",
      "Iteration: 1780000 | Loss: 0.060085313978485946\n",
      "Iteration: 1781000 | Loss: 0.060085313978485946\n",
      "Iteration: 1782000 | Loss: 0.060085313978485946\n",
      "Iteration: 1783000 | Loss: 0.060085313978485946\n",
      "Iteration: 1784000 | Loss: 0.060085313978485946\n",
      "Iteration: 1785000 | Loss: 0.060085313978485946\n",
      "Iteration: 1786000 | Loss: 0.060085313978485946\n",
      "Iteration: 1787000 | Loss: 0.060085313978485946\n",
      "Iteration: 1788000 | Loss: 0.060085313978485946\n",
      "Iteration: 1789000 | Loss: 0.060085313978485946\n",
      "Iteration: 1790000 | Loss: 0.060085313978485946\n",
      "Iteration: 1791000 | Loss: 0.060085313978485946\n",
      "Iteration: 1792000 | Loss: 0.060085313978485946\n",
      "Iteration: 1793000 | Loss: 0.060085313978485946\n",
      "Iteration: 1794000 | Loss: 0.060085313978485946\n",
      "Iteration: 1795000 | Loss: 0.060085313978485946\n",
      "Iteration: 1796000 | Loss: 0.060085313978485946\n",
      "Iteration: 1797000 | Loss: 0.060085313978485946\n",
      "Iteration: 1798000 | Loss: 0.060085313978485946\n",
      "Iteration: 1799000 | Loss: 0.060085313978485946\n",
      "Iteration: 1800000 | Loss: 0.060085313978485946\n",
      "Iteration: 1801000 | Loss: 0.060085313978485946\n",
      "Iteration: 1802000 | Loss: 0.060085313978485946\n",
      "Iteration: 1803000 | Loss: 0.060085313978485946\n",
      "Iteration: 1804000 | Loss: 0.060085313978485946\n",
      "Iteration: 1805000 | Loss: 0.060085313978485946\n",
      "Iteration: 1806000 | Loss: 0.060085313978485946\n",
      "Iteration: 1807000 | Loss: 0.060085313978485946\n",
      "Iteration: 1808000 | Loss: 0.060085313978485946\n",
      "Iteration: 1809000 | Loss: 0.060085313978485946\n",
      "Iteration: 1810000 | Loss: 0.060085313978485946\n",
      "Iteration: 1811000 | Loss: 0.060085313978485946\n",
      "Iteration: 1812000 | Loss: 0.060085313978485946\n",
      "Iteration: 1813000 | Loss: 0.060085313978485946\n",
      "Iteration: 1814000 | Loss: 0.060085313978485946\n",
      "Iteration: 1815000 | Loss: 0.060085313978485946\n",
      "Iteration: 1816000 | Loss: 0.060085313978485946\n",
      "Iteration: 1817000 | Loss: 0.060085313978485946\n",
      "Iteration: 1818000 | Loss: 0.060085313978485946\n",
      "Iteration: 1819000 | Loss: 0.060085313978485946\n",
      "Iteration: 1820000 | Loss: 0.060085313978485946\n",
      "Iteration: 1821000 | Loss: 0.060085313978485946\n",
      "Iteration: 1822000 | Loss: 0.060085313978485946\n",
      "Iteration: 1823000 | Loss: 0.060085313978485946\n",
      "Iteration: 1824000 | Loss: 0.060085313978485946\n",
      "Iteration: 1825000 | Loss: 0.060085313978485946\n",
      "Iteration: 1826000 | Loss: 0.060085313978485946\n",
      "Iteration: 1827000 | Loss: 0.060085313978485946\n",
      "Iteration: 1828000 | Loss: 0.060085313978485946\n",
      "Iteration: 1829000 | Loss: 0.060085313978485946\n",
      "Iteration: 1830000 | Loss: 0.060085313978485946\n",
      "Iteration: 1831000 | Loss: 0.060085313978485946\n",
      "Iteration: 1832000 | Loss: 0.060085313978485946\n",
      "Iteration: 1833000 | Loss: 0.060085313978485946\n",
      "Iteration: 1834000 | Loss: 0.060085313978485946\n",
      "Iteration: 1835000 | Loss: 0.060085313978485946\n",
      "Iteration: 1836000 | Loss: 0.060085313978485946\n",
      "Iteration: 1837000 | Loss: 0.060085313978485946\n",
      "Iteration: 1838000 | Loss: 0.060085313978485946\n",
      "Iteration: 1839000 | Loss: 0.060085313978485946\n",
      "Iteration: 1840000 | Loss: 0.060085313978485946\n",
      "Iteration: 1841000 | Loss: 0.060085313978485946\n",
      "Iteration: 1842000 | Loss: 0.060085313978485946\n",
      "Iteration: 1843000 | Loss: 0.060085313978485946\n",
      "Iteration: 1844000 | Loss: 0.060085313978485946\n",
      "Iteration: 1845000 | Loss: 0.060085313978485946\n",
      "Iteration: 1846000 | Loss: 0.060085313978485946\n",
      "Iteration: 1847000 | Loss: 0.060085313978485946\n",
      "Iteration: 1848000 | Loss: 0.060085313978485946\n",
      "Iteration: 1849000 | Loss: 0.060085313978485946\n",
      "Iteration: 1850000 | Loss: 0.060085313978485946\n",
      "Iteration: 1851000 | Loss: 0.060085313978485946\n",
      "Iteration: 1852000 | Loss: 0.060085313978485946\n",
      "Iteration: 1853000 | Loss: 0.060085313978485946\n",
      "Iteration: 1854000 | Loss: 0.060085313978485946\n",
      "Iteration: 1855000 | Loss: 0.060085313978485946\n",
      "Iteration: 1856000 | Loss: 0.060085313978485946\n",
      "Iteration: 1857000 | Loss: 0.060085313978485946\n",
      "Iteration: 1858000 | Loss: 0.060085313978485946\n",
      "Iteration: 1859000 | Loss: 0.060085313978485946\n",
      "Iteration: 1860000 | Loss: 0.060085313978485946\n",
      "Iteration: 1861000 | Loss: 0.060085313978485946\n",
      "Iteration: 1862000 | Loss: 0.060085313978485946\n",
      "Iteration: 1863000 | Loss: 0.060085313978485946\n",
      "Iteration: 1864000 | Loss: 0.060085313978485946\n",
      "Iteration: 1865000 | Loss: 0.060085313978485946\n",
      "Iteration: 1866000 | Loss: 0.060085313978485946\n",
      "Iteration: 1867000 | Loss: 0.060085313978485946\n",
      "Iteration: 1868000 | Loss: 0.060085313978485946\n",
      "Iteration: 1869000 | Loss: 0.060085313978485946\n",
      "Iteration: 1870000 | Loss: 0.060085313978485946\n",
      "Iteration: 1871000 | Loss: 0.060085313978485946\n",
      "Iteration: 1872000 | Loss: 0.060085313978485946\n",
      "Iteration: 1873000 | Loss: 0.060085313978485946\n",
      "Iteration: 1874000 | Loss: 0.060085313978485946\n",
      "Iteration: 1875000 | Loss: 0.060085313978485946\n",
      "Iteration: 1876000 | Loss: 0.060085313978485946\n",
      "Iteration: 1877000 | Loss: 0.060085313978485946\n",
      "Iteration: 1878000 | Loss: 0.060085313978485946\n",
      "Iteration: 1879000 | Loss: 0.060085313978485946\n",
      "Iteration: 1880000 | Loss: 0.060085313978485946\n",
      "Iteration: 1881000 | Loss: 0.060085313978485946\n",
      "Iteration: 1882000 | Loss: 0.060085313978485946\n",
      "Iteration: 1883000 | Loss: 0.060085313978485946\n",
      "Iteration: 1884000 | Loss: 0.060085313978485946\n",
      "Iteration: 1885000 | Loss: 0.060085313978485946\n",
      "Iteration: 1886000 | Loss: 0.060085313978485946\n",
      "Iteration: 1887000 | Loss: 0.060085313978485946\n",
      "Iteration: 1888000 | Loss: 0.060085313978485946\n",
      "Iteration: 1889000 | Loss: 0.060085313978485946\n",
      "Iteration: 1890000 | Loss: 0.060085313978485946\n",
      "Iteration: 1891000 | Loss: 0.060085313978485946\n",
      "Iteration: 1892000 | Loss: 0.060085313978485946\n",
      "Iteration: 1893000 | Loss: 0.060085313978485946\n",
      "Iteration: 1894000 | Loss: 0.060085313978485946\n",
      "Iteration: 1895000 | Loss: 0.060085313978485946\n",
      "Iteration: 1896000 | Loss: 0.060085313978485946\n",
      "Iteration: 1897000 | Loss: 0.060085313978485946\n",
      "Iteration: 1898000 | Loss: 0.060085313978485946\n",
      "Iteration: 1899000 | Loss: 0.060085313978485946\n",
      "Iteration: 1900000 | Loss: 0.060085313978485946\n",
      "Iteration: 1901000 | Loss: 0.060085313978485946\n",
      "Iteration: 1902000 | Loss: 0.060085313978485946\n",
      "Iteration: 1903000 | Loss: 0.060085313978485946\n",
      "Iteration: 1904000 | Loss: 0.060085313978485946\n",
      "Iteration: 1905000 | Loss: 0.060085313978485946\n",
      "Iteration: 1906000 | Loss: 0.060085313978485946\n",
      "Iteration: 1907000 | Loss: 0.060085313978485946\n",
      "Iteration: 1908000 | Loss: 0.060085313978485946\n",
      "Iteration: 1909000 | Loss: 0.060085313978485946\n",
      "Iteration: 1910000 | Loss: 0.060085313978485946\n",
      "Iteration: 1911000 | Loss: 0.060085313978485946\n",
      "Iteration: 1912000 | Loss: 0.060085313978485946\n",
      "Iteration: 1913000 | Loss: 0.060085313978485946\n",
      "Iteration: 1914000 | Loss: 0.060085313978485946\n",
      "Iteration: 1915000 | Loss: 0.060085313978485946\n",
      "Iteration: 1916000 | Loss: 0.060085313978485946\n",
      "Iteration: 1917000 | Loss: 0.060085313978485946\n",
      "Iteration: 1918000 | Loss: 0.060085313978485946\n",
      "Iteration: 1919000 | Loss: 0.060085313978485946\n",
      "Iteration: 1920000 | Loss: 0.060085313978485946\n",
      "Iteration: 1921000 | Loss: 0.060085313978485946\n",
      "Iteration: 1922000 | Loss: 0.060085313978485946\n",
      "Iteration: 1923000 | Loss: 0.060085313978485946\n",
      "Iteration: 1924000 | Loss: 0.060085313978485946\n",
      "Iteration: 1925000 | Loss: 0.060085313978485946\n",
      "Iteration: 1926000 | Loss: 0.060085313978485946\n",
      "Iteration: 1927000 | Loss: 0.060085313978485946\n",
      "Iteration: 1928000 | Loss: 0.060085313978485946\n",
      "Iteration: 1929000 | Loss: 0.060085313978485946\n",
      "Iteration: 1930000 | Loss: 0.060085313978485946\n",
      "Iteration: 1931000 | Loss: 0.060085313978485946\n",
      "Iteration: 1932000 | Loss: 0.060085313978485946\n",
      "Iteration: 1933000 | Loss: 0.060085313978485946\n",
      "Iteration: 1934000 | Loss: 0.060085313978485946\n",
      "Iteration: 1935000 | Loss: 0.060085313978485946\n",
      "Iteration: 1936000 | Loss: 0.060085313978485946\n",
      "Iteration: 1937000 | Loss: 0.060085313978485946\n",
      "Iteration: 1938000 | Loss: 0.060085313978485946\n",
      "Iteration: 1939000 | Loss: 0.060085313978485946\n",
      "Iteration: 1940000 | Loss: 0.060085313978485946\n",
      "Iteration: 1941000 | Loss: 0.060085313978485946\n",
      "Iteration: 1942000 | Loss: 0.060085313978485946\n",
      "Iteration: 1943000 | Loss: 0.060085313978485946\n",
      "Iteration: 1944000 | Loss: 0.060085313978485946\n",
      "Iteration: 1945000 | Loss: 0.060085313978485946\n",
      "Iteration: 1946000 | Loss: 0.060085313978485946\n",
      "Iteration: 1947000 | Loss: 0.060085313978485946\n",
      "Iteration: 1948000 | Loss: 0.060085313978485946\n",
      "Iteration: 1949000 | Loss: 0.060085313978485946\n",
      "Iteration: 1950000 | Loss: 0.060085313978485946\n",
      "Iteration: 1951000 | Loss: 0.060085313978485946\n",
      "Iteration: 1952000 | Loss: 0.060085313978485946\n",
      "Iteration: 1953000 | Loss: 0.060085313978485946\n",
      "Iteration: 1954000 | Loss: 0.060085313978485946\n",
      "Iteration: 1955000 | Loss: 0.060085313978485946\n",
      "Iteration: 1956000 | Loss: 0.060085313978485946\n",
      "Iteration: 1957000 | Loss: 0.060085313978485946\n",
      "Iteration: 1958000 | Loss: 0.060085313978485946\n",
      "Iteration: 1959000 | Loss: 0.060085313978485946\n",
      "Iteration: 1960000 | Loss: 0.060085313978485946\n",
      "Iteration: 1961000 | Loss: 0.060085313978485946\n",
      "Iteration: 1962000 | Loss: 0.060085313978485946\n",
      "Iteration: 1963000 | Loss: 0.060085313978485946\n",
      "Iteration: 1964000 | Loss: 0.060085313978485946\n",
      "Iteration: 1965000 | Loss: 0.060085313978485946\n",
      "Iteration: 1966000 | Loss: 0.060085313978485946\n",
      "Iteration: 1967000 | Loss: 0.060085313978485946\n",
      "Iteration: 1968000 | Loss: 0.060085313978485946\n",
      "Iteration: 1969000 | Loss: 0.060085313978485946\n",
      "Iteration: 1970000 | Loss: 0.060085313978485946\n",
      "Iteration: 1971000 | Loss: 0.060085313978485946\n",
      "Iteration: 1972000 | Loss: 0.060085313978485946\n",
      "Iteration: 1973000 | Loss: 0.060085313978485946\n",
      "Iteration: 1974000 | Loss: 0.060085313978485946\n",
      "Iteration: 1975000 | Loss: 0.060085313978485946\n",
      "Iteration: 1976000 | Loss: 0.060085313978485946\n",
      "Iteration: 1977000 | Loss: 0.060085313978485946\n",
      "Iteration: 1978000 | Loss: 0.060085313978485946\n",
      "Iteration: 1979000 | Loss: 0.060085313978485946\n",
      "Iteration: 1980000 | Loss: 0.060085313978485946\n",
      "Iteration: 1981000 | Loss: 0.060085313978485946\n",
      "Iteration: 1982000 | Loss: 0.060085313978485946\n",
      "Iteration: 1983000 | Loss: 0.060085313978485946\n",
      "Iteration: 1984000 | Loss: 0.060085313978485946\n",
      "Iteration: 1985000 | Loss: 0.060085313978485946\n",
      "Iteration: 1986000 | Loss: 0.060085313978485946\n",
      "Iteration: 1987000 | Loss: 0.060085313978485946\n",
      "Iteration: 1988000 | Loss: 0.060085313978485946\n",
      "Iteration: 1989000 | Loss: 0.060085313978485946\n",
      "Iteration: 1990000 | Loss: 0.060085313978485946\n",
      "Iteration: 1991000 | Loss: 0.060085313978485946\n",
      "Iteration: 1992000 | Loss: 0.060085313978485946\n",
      "Iteration: 1993000 | Loss: 0.060085313978485946\n",
      "Iteration: 1994000 | Loss: 0.060085313978485946\n",
      "Iteration: 1995000 | Loss: 0.060085313978485946\n",
      "Iteration: 1996000 | Loss: 0.060085313978485946\n",
      "Iteration: 1997000 | Loss: 0.060085313978485946\n",
      "Iteration: 1998000 | Loss: 0.060085313978485946\n",
      "Iteration: 1999000 | Loss: 0.060085313978485946\n",
      "Iteration: 2000000 | Loss: 0.060085313978485946\n",
      "Iteration: 2001000 | Loss: 0.060085313978485946\n",
      "Iteration: 2002000 | Loss: 0.060085313978485946\n",
      "Iteration: 2003000 | Loss: 0.060085313978485946\n",
      "Iteration: 2004000 | Loss: 0.060085313978485946\n",
      "Iteration: 2005000 | Loss: 0.060085313978485946\n",
      "Iteration: 2006000 | Loss: 0.060085313978485946\n",
      "Iteration: 2007000 | Loss: 0.060085313978485946\n",
      "Iteration: 2008000 | Loss: 0.060085313978485946\n",
      "Iteration: 2009000 | Loss: 0.060085313978485946\n",
      "Iteration: 2010000 | Loss: 0.060085313978485946\n",
      "Iteration: 2011000 | Loss: 0.060085313978485946\n",
      "Iteration: 2012000 | Loss: 0.060085313978485946\n",
      "Iteration: 2013000 | Loss: 0.060085313978485946\n",
      "Iteration: 2014000 | Loss: 0.060085313978485946\n",
      "Iteration: 2015000 | Loss: 0.060085313978485946\n",
      "Iteration: 2016000 | Loss: 0.060085313978485946\n",
      "Iteration: 2017000 | Loss: 0.060085313978485946\n",
      "Iteration: 2018000 | Loss: 0.060085313978485946\n",
      "Iteration: 2019000 | Loss: 0.060085313978485946\n",
      "Iteration: 2020000 | Loss: 0.060085313978485946\n",
      "Iteration: 2021000 | Loss: 0.060085313978485946\n",
      "Iteration: 2022000 | Loss: 0.060085313978485946\n",
      "Iteration: 2023000 | Loss: 0.060085313978485946\n",
      "Iteration: 2024000 | Loss: 0.060085313978485946\n",
      "Iteration: 2025000 | Loss: 0.060085313978485946\n",
      "Iteration: 2026000 | Loss: 0.060085313978485946\n",
      "Iteration: 2027000 | Loss: 0.060085313978485946\n",
      "Iteration: 2028000 | Loss: 0.060085313978485946\n",
      "Iteration: 2029000 | Loss: 0.060085313978485946\n",
      "Iteration: 2030000 | Loss: 0.060085313978485946\n",
      "Iteration: 2031000 | Loss: 0.060085313978485946\n",
      "Iteration: 2032000 | Loss: 0.060085313978485946\n",
      "Iteration: 2033000 | Loss: 0.060085313978485946\n",
      "Iteration: 2034000 | Loss: 0.060085313978485946\n",
      "Iteration: 2035000 | Loss: 0.060085313978485946\n",
      "Iteration: 2036000 | Loss: 0.060085313978485946\n",
      "Iteration: 2037000 | Loss: 0.060085313978485946\n",
      "Iteration: 2038000 | Loss: 0.060085313978485946\n",
      "Iteration: 2039000 | Loss: 0.060085313978485946\n",
      "Iteration: 2040000 | Loss: 0.060085313978485946\n",
      "Iteration: 2041000 | Loss: 0.060085313978485946\n",
      "Iteration: 2042000 | Loss: 0.060085313978485946\n",
      "Iteration: 2043000 | Loss: 0.060085313978485946\n",
      "Iteration: 2044000 | Loss: 0.060085313978485946\n",
      "Iteration: 2045000 | Loss: 0.060085313978485946\n",
      "Iteration: 2046000 | Loss: 0.060085313978485946\n",
      "Iteration: 2047000 | Loss: 0.060085313978485946\n",
      "Iteration: 2048000 | Loss: 0.060085313978485946\n",
      "Iteration: 2049000 | Loss: 0.060085313978485946\n",
      "Iteration: 2050000 | Loss: 0.060085313978485946\n",
      "Iteration: 2051000 | Loss: 0.060085313978485946\n",
      "Iteration: 2052000 | Loss: 0.060085313978485946\n",
      "Iteration: 2053000 | Loss: 0.060085313978485946\n",
      "Iteration: 2054000 | Loss: 0.060085313978485946\n",
      "Iteration: 2055000 | Loss: 0.060085313978485946\n",
      "Iteration: 2056000 | Loss: 0.060085313978485946\n",
      "Iteration: 2057000 | Loss: 0.060085313978485946\n",
      "Iteration: 2058000 | Loss: 0.060085313978485946\n",
      "Iteration: 2059000 | Loss: 0.060085313978485946\n",
      "Iteration: 2060000 | Loss: 0.060085313978485946\n",
      "Iteration: 2061000 | Loss: 0.060085313978485946\n",
      "Iteration: 2062000 | Loss: 0.060085313978485946\n",
      "Iteration: 2063000 | Loss: 0.060085313978485946\n",
      "Iteration: 2064000 | Loss: 0.060085313978485946\n",
      "Iteration: 2065000 | Loss: 0.060085313978485946\n",
      "Iteration: 2066000 | Loss: 0.060085313978485946\n",
      "Iteration: 2067000 | Loss: 0.060085313978485946\n",
      "Iteration: 2068000 | Loss: 0.060085313978485946\n",
      "Iteration: 2069000 | Loss: 0.060085313978485946\n",
      "Iteration: 2070000 | Loss: 0.060085313978485946\n",
      "Iteration: 2071000 | Loss: 0.060085313978485946\n",
      "Iteration: 2072000 | Loss: 0.060085313978485946\n",
      "Iteration: 2073000 | Loss: 0.060085313978485946\n",
      "Iteration: 2074000 | Loss: 0.060085313978485946\n",
      "Iteration: 2075000 | Loss: 0.060085313978485946\n",
      "Iteration: 2076000 | Loss: 0.060085313978485946\n",
      "Iteration: 2077000 | Loss: 0.060085313978485946\n",
      "Iteration: 2078000 | Loss: 0.060085313978485946\n",
      "Iteration: 2079000 | Loss: 0.060085313978485946\n",
      "Iteration: 2080000 | Loss: 0.060085313978485946\n",
      "Iteration: 2081000 | Loss: 0.060085313978485946\n",
      "Iteration: 2082000 | Loss: 0.060085313978485946\n",
      "Iteration: 2083000 | Loss: 0.060085313978485946\n",
      "Iteration: 2084000 | Loss: 0.060085313978485946\n",
      "Iteration: 2085000 | Loss: 0.060085313978485946\n",
      "Iteration: 2086000 | Loss: 0.060085313978485946\n",
      "Iteration: 2087000 | Loss: 0.060085313978485946\n",
      "Iteration: 2088000 | Loss: 0.060085313978485946\n",
      "Iteration: 2089000 | Loss: 0.060085313978485946\n",
      "Iteration: 2090000 | Loss: 0.060085313978485946\n",
      "Iteration: 2091000 | Loss: 0.060085313978485946\n",
      "Iteration: 2092000 | Loss: 0.060085313978485946\n",
      "Iteration: 2093000 | Loss: 0.060085313978485946\n",
      "Iteration: 2094000 | Loss: 0.060085313978485946\n",
      "Iteration: 2095000 | Loss: 0.060085313978485946\n",
      "Iteration: 2096000 | Loss: 0.060085313978485946\n",
      "Iteration: 2097000 | Loss: 0.060085313978485946\n",
      "Iteration: 2098000 | Loss: 0.060085313978485946\n",
      "Iteration: 2099000 | Loss: 0.060085313978485946\n",
      "Iteration: 2100000 | Loss: 0.060085313978485946\n",
      "Iteration: 2101000 | Loss: 0.060085313978485946\n",
      "Iteration: 2102000 | Loss: 0.060085313978485946\n",
      "Iteration: 2103000 | Loss: 0.060085313978485946\n",
      "Iteration: 2104000 | Loss: 0.060085313978485946\n",
      "Iteration: 2105000 | Loss: 0.060085313978485946\n",
      "Iteration: 2106000 | Loss: 0.060085313978485946\n",
      "Iteration: 2107000 | Loss: 0.060085313978485946\n",
      "Iteration: 2108000 | Loss: 0.060085313978485946\n",
      "Iteration: 2109000 | Loss: 0.060085313978485946\n",
      "Iteration: 2110000 | Loss: 0.060085313978485946\n",
      "Iteration: 2111000 | Loss: 0.060085313978485946\n",
      "Iteration: 2112000 | Loss: 0.060085313978485946\n",
      "Iteration: 2113000 | Loss: 0.060085313978485946\n",
      "Iteration: 2114000 | Loss: 0.060085313978485946\n",
      "Iteration: 2115000 | Loss: 0.060085313978485946\n",
      "Iteration: 2116000 | Loss: 0.060085313978485946\n",
      "Iteration: 2117000 | Loss: 0.060085313978485946\n",
      "Iteration: 2118000 | Loss: 0.060085313978485946\n",
      "Iteration: 2119000 | Loss: 0.060085313978485946\n",
      "Iteration: 2120000 | Loss: 0.060085313978485946\n",
      "Iteration: 2121000 | Loss: 0.060085313978485946\n",
      "Iteration: 2122000 | Loss: 0.060085313978485946\n",
      "Iteration: 2123000 | Loss: 0.060085313978485946\n",
      "Iteration: 2124000 | Loss: 0.060085313978485946\n",
      "Iteration: 2125000 | Loss: 0.060085313978485946\n",
      "Iteration: 2126000 | Loss: 0.060085313978485946\n",
      "Iteration: 2127000 | Loss: 0.060085313978485946\n",
      "Iteration: 2128000 | Loss: 0.060085313978485946\n",
      "Iteration: 2129000 | Loss: 0.060085313978485946\n",
      "Iteration: 2130000 | Loss: 0.060085313978485946\n",
      "Iteration: 2131000 | Loss: 0.060085313978485946\n",
      "Iteration: 2132000 | Loss: 0.060085313978485946\n",
      "Iteration: 2133000 | Loss: 0.060085313978485946\n",
      "Iteration: 2134000 | Loss: 0.060085313978485946\n",
      "Iteration: 2135000 | Loss: 0.060085313978485946\n",
      "Iteration: 2136000 | Loss: 0.060085313978485946\n",
      "Iteration: 2137000 | Loss: 0.060085313978485946\n",
      "Iteration: 2138000 | Loss: 0.060085313978485946\n",
      "Iteration: 2139000 | Loss: 0.060085313978485946\n",
      "Iteration: 2140000 | Loss: 0.060085313978485946\n",
      "Iteration: 2141000 | Loss: 0.060085313978485946\n",
      "Iteration: 2142000 | Loss: 0.060085313978485946\n",
      "Iteration: 2143000 | Loss: 0.060085313978485946\n",
      "Iteration: 2144000 | Loss: 0.060085313978485946\n",
      "Iteration: 2145000 | Loss: 0.060085313978485946\n",
      "Iteration: 2146000 | Loss: 0.060085313978485946\n",
      "Iteration: 2147000 | Loss: 0.060085313978485946\n",
      "Iteration: 2148000 | Loss: 0.060085313978485946\n",
      "Iteration: 2149000 | Loss: 0.060085313978485946\n",
      "Iteration: 2150000 | Loss: 0.060085313978485946\n",
      "Iteration: 2151000 | Loss: 0.060085313978485946\n",
      "Iteration: 2152000 | Loss: 0.060085313978485946\n",
      "Iteration: 2153000 | Loss: 0.060085313978485946\n",
      "Iteration: 2154000 | Loss: 0.060085313978485946\n",
      "Iteration: 2155000 | Loss: 0.060085313978485946\n",
      "Iteration: 2156000 | Loss: 0.060085313978485946\n",
      "Iteration: 2157000 | Loss: 0.060085313978485946\n",
      "Iteration: 2158000 | Loss: 0.060085313978485946\n",
      "Iteration: 2159000 | Loss: 0.060085313978485946\n",
      "Iteration: 2160000 | Loss: 0.060085313978485946\n",
      "Iteration: 2161000 | Loss: 0.060085313978485946\n",
      "Iteration: 2162000 | Loss: 0.060085313978485946\n",
      "Iteration: 2163000 | Loss: 0.060085313978485946\n",
      "Iteration: 2164000 | Loss: 0.060085313978485946\n",
      "Iteration: 2165000 | Loss: 0.060085313978485946\n",
      "Iteration: 2166000 | Loss: 0.060085313978485946\n",
      "Iteration: 2167000 | Loss: 0.060085313978485946\n",
      "Iteration: 2168000 | Loss: 0.060085313978485946\n",
      "Iteration: 2169000 | Loss: 0.060085313978485946\n",
      "Iteration: 2170000 | Loss: 0.060085313978485946\n",
      "Iteration: 2171000 | Loss: 0.060085313978485946\n",
      "Iteration: 2172000 | Loss: 0.060085313978485946\n",
      "Iteration: 2173000 | Loss: 0.060085313978485946\n",
      "Iteration: 2174000 | Loss: 0.060085313978485946\n",
      "Iteration: 2175000 | Loss: 0.060085313978485946\n",
      "Iteration: 2176000 | Loss: 0.060085313978485946\n",
      "Iteration: 2177000 | Loss: 0.060085313978485946\n",
      "Iteration: 2178000 | Loss: 0.060085313978485946\n",
      "Iteration: 2179000 | Loss: 0.060085313978485946\n",
      "Iteration: 2180000 | Loss: 0.060085313978485946\n",
      "Iteration: 2181000 | Loss: 0.060085313978485946\n",
      "Iteration: 2182000 | Loss: 0.060085313978485946\n",
      "Iteration: 2183000 | Loss: 0.060085313978485946\n",
      "Iteration: 2184000 | Loss: 0.060085313978485946\n",
      "Iteration: 2185000 | Loss: 0.060085313978485946\n",
      "Iteration: 2186000 | Loss: 0.060085313978485946\n",
      "Iteration: 2187000 | Loss: 0.060085313978485946\n",
      "Iteration: 2188000 | Loss: 0.060085313978485946\n",
      "Iteration: 2189000 | Loss: 0.060085313978485946\n",
      "Iteration: 2190000 | Loss: 0.060085313978485946\n",
      "Iteration: 2191000 | Loss: 0.060085313978485946\n",
      "Iteration: 2192000 | Loss: 0.060085313978485946\n",
      "Iteration: 2193000 | Loss: 0.060085313978485946\n",
      "Iteration: 2194000 | Loss: 0.060085313978485946\n",
      "Iteration: 2195000 | Loss: 0.060085313978485946\n",
      "Iteration: 2196000 | Loss: 0.060085313978485946\n",
      "Iteration: 2197000 | Loss: 0.060085313978485946\n",
      "Iteration: 2198000 | Loss: 0.060085313978485946\n",
      "Iteration: 2199000 | Loss: 0.060085313978485946\n",
      "Iteration: 2200000 | Loss: 0.060085313978485946\n",
      "Iteration: 2201000 | Loss: 0.060085313978485946\n",
      "Iteration: 2202000 | Loss: 0.060085313978485946\n",
      "Iteration: 2203000 | Loss: 0.060085313978485946\n",
      "Iteration: 2204000 | Loss: 0.060085313978485946\n",
      "Iteration: 2205000 | Loss: 0.060085313978485946\n",
      "Iteration: 2206000 | Loss: 0.060085313978485946\n",
      "Iteration: 2207000 | Loss: 0.060085313978485946\n",
      "Iteration: 2208000 | Loss: 0.060085313978485946\n",
      "Iteration: 2209000 | Loss: 0.060085313978485946\n",
      "Iteration: 2210000 | Loss: 0.060085313978485946\n",
      "Iteration: 2211000 | Loss: 0.060085313978485946\n",
      "Iteration: 2212000 | Loss: 0.060085313978485946\n",
      "Iteration: 2213000 | Loss: 0.060085313978485946\n",
      "Iteration: 2214000 | Loss: 0.060085313978485946\n",
      "Iteration: 2215000 | Loss: 0.060085313978485946\n",
      "Iteration: 2216000 | Loss: 0.060085313978485946\n",
      "Iteration: 2217000 | Loss: 0.060085313978485946\n",
      "Iteration: 2218000 | Loss: 0.060085313978485946\n",
      "Iteration: 2219000 | Loss: 0.060085313978485946\n",
      "Iteration: 2220000 | Loss: 0.060085313978485946\n",
      "Iteration: 2221000 | Loss: 0.060085313978485946\n",
      "Iteration: 2222000 | Loss: 0.060085313978485946\n",
      "Iteration: 2223000 | Loss: 0.060085313978485946\n",
      "Iteration: 2224000 | Loss: 0.060085313978485946\n",
      "Iteration: 2225000 | Loss: 0.060085313978485946\n",
      "Iteration: 2226000 | Loss: 0.060085313978485946\n",
      "Iteration: 2227000 | Loss: 0.060085313978485946\n",
      "Iteration: 2228000 | Loss: 0.060085313978485946\n",
      "Iteration: 2229000 | Loss: 0.060085313978485946\n",
      "Iteration: 2230000 | Loss: 0.060085313978485946\n",
      "Iteration: 2231000 | Loss: 0.060085313978485946\n",
      "Iteration: 2232000 | Loss: 0.060085313978485946\n",
      "Iteration: 2233000 | Loss: 0.060085313978485946\n",
      "Iteration: 2234000 | Loss: 0.060085313978485946\n",
      "Iteration: 2235000 | Loss: 0.060085313978485946\n",
      "Iteration: 2236000 | Loss: 0.060085313978485946\n",
      "Iteration: 2237000 | Loss: 0.060085313978485946\n",
      "Iteration: 2238000 | Loss: 0.060085313978485946\n",
      "Iteration: 2239000 | Loss: 0.060085313978485946\n",
      "Iteration: 2240000 | Loss: 0.060085313978485946\n",
      "Iteration: 2241000 | Loss: 0.060085313978485946\n",
      "Iteration: 2242000 | Loss: 0.060085313978485946\n",
      "Iteration: 2243000 | Loss: 0.060085313978485946\n",
      "Iteration: 2244000 | Loss: 0.060085313978485946\n",
      "Iteration: 2245000 | Loss: 0.060085313978485946\n",
      "Iteration: 2246000 | Loss: 0.060085313978485946\n",
      "Iteration: 2247000 | Loss: 0.060085313978485946\n",
      "Iteration: 2248000 | Loss: 0.060085313978485946\n",
      "Iteration: 2249000 | Loss: 0.060085313978485946\n",
      "Iteration: 2250000 | Loss: 0.060085313978485946\n",
      "Iteration: 2251000 | Loss: 0.060085313978485946\n",
      "Iteration: 2252000 | Loss: 0.060085313978485946\n",
      "Iteration: 2253000 | Loss: 0.060085313978485946\n",
      "Iteration: 2254000 | Loss: 0.060085313978485946\n",
      "Iteration: 2255000 | Loss: 0.060085313978485946\n",
      "Iteration: 2256000 | Loss: 0.060085313978485946\n",
      "Iteration: 2257000 | Loss: 0.060085313978485946\n",
      "Iteration: 2258000 | Loss: 0.060085313978485946\n",
      "Iteration: 2259000 | Loss: 0.060085313978485946\n",
      "Iteration: 2260000 | Loss: 0.060085313978485946\n",
      "Iteration: 2261000 | Loss: 0.060085313978485946\n",
      "Iteration: 2262000 | Loss: 0.060085313978485946\n",
      "Iteration: 2263000 | Loss: 0.060085313978485946\n",
      "Iteration: 2264000 | Loss: 0.060085313978485946\n",
      "Iteration: 2265000 | Loss: 0.060085313978485946\n",
      "Iteration: 2266000 | Loss: 0.060085313978485946\n",
      "Iteration: 2267000 | Loss: 0.060085313978485946\n",
      "Iteration: 2268000 | Loss: 0.060085313978485946\n",
      "Iteration: 2269000 | Loss: 0.060085313978485946\n",
      "Iteration: 2270000 | Loss: 0.060085313978485946\n",
      "Iteration: 2271000 | Loss: 0.060085313978485946\n",
      "Iteration: 2272000 | Loss: 0.060085313978485946\n",
      "Iteration: 2273000 | Loss: 0.060085313978485946\n",
      "Iteration: 2274000 | Loss: 0.060085313978485946\n",
      "Iteration: 2275000 | Loss: 0.060085313978485946\n",
      "Iteration: 2276000 | Loss: 0.060085313978485946\n",
      "Iteration: 2277000 | Loss: 0.060085313978485946\n",
      "Iteration: 2278000 | Loss: 0.060085313978485946\n",
      "Iteration: 2279000 | Loss: 0.060085313978485946\n",
      "Iteration: 2280000 | Loss: 0.060085313978485946\n",
      "Iteration: 2281000 | Loss: 0.060085313978485946\n",
      "Iteration: 2282000 | Loss: 0.060085313978485946\n",
      "Iteration: 2283000 | Loss: 0.060085313978485946\n",
      "Iteration: 2284000 | Loss: 0.060085313978485946\n",
      "Iteration: 2285000 | Loss: 0.060085313978485946\n",
      "Iteration: 2286000 | Loss: 0.060085313978485946\n",
      "Iteration: 2287000 | Loss: 0.060085313978485946\n",
      "Iteration: 2288000 | Loss: 0.060085313978485946\n",
      "Iteration: 2289000 | Loss: 0.060085313978485946\n",
      "Iteration: 2290000 | Loss: 0.060085313978485946\n",
      "Iteration: 2291000 | Loss: 0.060085313978485946\n",
      "Iteration: 2292000 | Loss: 0.060085313978485946\n",
      "Iteration: 2293000 | Loss: 0.060085313978485946\n",
      "Iteration: 2294000 | Loss: 0.060085313978485946\n",
      "Iteration: 2295000 | Loss: 0.060085313978485946\n",
      "Iteration: 2296000 | Loss: 0.060085313978485946\n",
      "Iteration: 2297000 | Loss: 0.060085313978485946\n",
      "Iteration: 2298000 | Loss: 0.060085313978485946\n",
      "Iteration: 2299000 | Loss: 0.060085313978485946\n",
      "Iteration: 2300000 | Loss: 0.060085313978485946\n",
      "Iteration: 2301000 | Loss: 0.060085313978485946\n",
      "Iteration: 2302000 | Loss: 0.060085313978485946\n",
      "Iteration: 2303000 | Loss: 0.060085313978485946\n",
      "Iteration: 2304000 | Loss: 0.060085313978485946\n",
      "Iteration: 2305000 | Loss: 0.060085313978485946\n",
      "Iteration: 2306000 | Loss: 0.060085313978485946\n",
      "Iteration: 2307000 | Loss: 0.060085313978485946\n",
      "Iteration: 2308000 | Loss: 0.060085313978485946\n",
      "Iteration: 2309000 | Loss: 0.060085313978485946\n",
      "Iteration: 2310000 | Loss: 0.060085313978485946\n",
      "Iteration: 2311000 | Loss: 0.060085313978485946\n",
      "Iteration: 2312000 | Loss: 0.060085313978485946\n",
      "Iteration: 2313000 | Loss: 0.060085313978485946\n",
      "Iteration: 2314000 | Loss: 0.060085313978485946\n",
      "Iteration: 2315000 | Loss: 0.060085313978485946\n",
      "Iteration: 2316000 | Loss: 0.060085313978485946\n",
      "Iteration: 2317000 | Loss: 0.060085313978485946\n",
      "Iteration: 2318000 | Loss: 0.060085313978485946\n",
      "Iteration: 2319000 | Loss: 0.060085313978485946\n",
      "Iteration: 2320000 | Loss: 0.060085313978485946\n",
      "Iteration: 2321000 | Loss: 0.060085313978485946\n",
      "Iteration: 2322000 | Loss: 0.060085313978485946\n",
      "Iteration: 2323000 | Loss: 0.060085313978485946\n",
      "Iteration: 2324000 | Loss: 0.060085313978485946\n",
      "Iteration: 2325000 | Loss: 0.060085313978485946\n",
      "Iteration: 2326000 | Loss: 0.060085313978485946\n",
      "Iteration: 2327000 | Loss: 0.060085313978485946\n",
      "Iteration: 2328000 | Loss: 0.060085313978485946\n",
      "Iteration: 2329000 | Loss: 0.060085313978485946\n",
      "Iteration: 2330000 | Loss: 0.060085313978485946\n",
      "Iteration: 2331000 | Loss: 0.060085313978485946\n",
      "Iteration: 2332000 | Loss: 0.060085313978485946\n",
      "Iteration: 2333000 | Loss: 0.060085313978485946\n",
      "Iteration: 2334000 | Loss: 0.060085313978485946\n",
      "Iteration: 2335000 | Loss: 0.060085313978485946\n",
      "Iteration: 2336000 | Loss: 0.060085313978485946\n",
      "Iteration: 2337000 | Loss: 0.060085313978485946\n",
      "Iteration: 2338000 | Loss: 0.060085313978485946\n",
      "Iteration: 2339000 | Loss: 0.060085313978485946\n",
      "Iteration: 2340000 | Loss: 0.060085313978485946\n",
      "Iteration: 2341000 | Loss: 0.060085313978485946\n",
      "Iteration: 2342000 | Loss: 0.060085313978485946\n",
      "Iteration: 2343000 | Loss: 0.060085313978485946\n",
      "Iteration: 2344000 | Loss: 0.060085313978485946\n",
      "Iteration: 2345000 | Loss: 0.060085313978485946\n",
      "Iteration: 2346000 | Loss: 0.060085313978485946\n",
      "Iteration: 2347000 | Loss: 0.060085313978485946\n",
      "Iteration: 2348000 | Loss: 0.060085313978485946\n",
      "Iteration: 2349000 | Loss: 0.060085313978485946\n",
      "Iteration: 2350000 | Loss: 0.060085313978485946\n",
      "Iteration: 2351000 | Loss: 0.060085313978485946\n",
      "Iteration: 2352000 | Loss: 0.060085313978485946\n",
      "Iteration: 2353000 | Loss: 0.060085313978485946\n",
      "Iteration: 2354000 | Loss: 0.060085313978485946\n",
      "Iteration: 2355000 | Loss: 0.060085313978485946\n",
      "Iteration: 2356000 | Loss: 0.060085313978485946\n",
      "Iteration: 2357000 | Loss: 0.060085313978485946\n",
      "Iteration: 2358000 | Loss: 0.060085313978485946\n",
      "Iteration: 2359000 | Loss: 0.060085313978485946\n",
      "Iteration: 2360000 | Loss: 0.060085313978485946\n",
      "Iteration: 2361000 | Loss: 0.060085313978485946\n",
      "Iteration: 2362000 | Loss: 0.060085313978485946\n",
      "Iteration: 2363000 | Loss: 0.060085313978485946\n",
      "Iteration: 2364000 | Loss: 0.060085313978485946\n",
      "Iteration: 2365000 | Loss: 0.060085313978485946\n",
      "Iteration: 2366000 | Loss: 0.060085313978485946\n",
      "Iteration: 2367000 | Loss: 0.060085313978485946\n",
      "Iteration: 2368000 | Loss: 0.060085313978485946\n",
      "Iteration: 2369000 | Loss: 0.060085313978485946\n",
      "Iteration: 2370000 | Loss: 0.060085313978485946\n",
      "Iteration: 2371000 | Loss: 0.060085313978485946\n",
      "Iteration: 2372000 | Loss: 0.060085313978485946\n",
      "Iteration: 2373000 | Loss: 0.060085313978485946\n",
      "Iteration: 2374000 | Loss: 0.060085313978485946\n",
      "Iteration: 2375000 | Loss: 0.060085313978485946\n",
      "Iteration: 2376000 | Loss: 0.060085313978485946\n",
      "Iteration: 2377000 | Loss: 0.060085313978485946\n",
      "Iteration: 2378000 | Loss: 0.060085313978485946\n",
      "Iteration: 2379000 | Loss: 0.060085313978485946\n",
      "Iteration: 2380000 | Loss: 0.060085313978485946\n",
      "Iteration: 2381000 | Loss: 0.060085313978485946\n",
      "Iteration: 2382000 | Loss: 0.060085313978485946\n",
      "Iteration: 2383000 | Loss: 0.060085313978485946\n",
      "Iteration: 2384000 | Loss: 0.060085313978485946\n",
      "Iteration: 2385000 | Loss: 0.060085313978485946\n",
      "Iteration: 2386000 | Loss: 0.060085313978485946\n",
      "Iteration: 2387000 | Loss: 0.060085313978485946\n",
      "Iteration: 2388000 | Loss: 0.060085313978485946\n",
      "Iteration: 2389000 | Loss: 0.060085313978485946\n",
      "Iteration: 2390000 | Loss: 0.060085313978485946\n",
      "Iteration: 2391000 | Loss: 0.060085313978485946\n",
      "Iteration: 2392000 | Loss: 0.060085313978485946\n",
      "Iteration: 2393000 | Loss: 0.060085313978485946\n",
      "Iteration: 2394000 | Loss: 0.060085313978485946\n",
      "Iteration: 2395000 | Loss: 0.060085313978485946\n",
      "Iteration: 2396000 | Loss: 0.060085313978485946\n",
      "Iteration: 2397000 | Loss: 0.060085313978485946\n",
      "Iteration: 2398000 | Loss: 0.060085313978485946\n",
      "Iteration: 2399000 | Loss: 0.060085313978485946\n",
      "Iteration: 2400000 | Loss: 0.060085313978485946\n",
      "Iteration: 2401000 | Loss: 0.060085313978485946\n",
      "Iteration: 2402000 | Loss: 0.060085313978485946\n",
      "Iteration: 2403000 | Loss: 0.060085313978485946\n",
      "Iteration: 2404000 | Loss: 0.060085313978485946\n",
      "Iteration: 2405000 | Loss: 0.060085313978485946\n",
      "Iteration: 2406000 | Loss: 0.060085313978485946\n",
      "Iteration: 2407000 | Loss: 0.060085313978485946\n",
      "Iteration: 2408000 | Loss: 0.060085313978485946\n",
      "Iteration: 2409000 | Loss: 0.060085313978485946\n",
      "Iteration: 2410000 | Loss: 0.060085313978485946\n",
      "Iteration: 2411000 | Loss: 0.060085313978485946\n",
      "Iteration: 2412000 | Loss: 0.060085313978485946\n",
      "Iteration: 2413000 | Loss: 0.060085313978485946\n",
      "Iteration: 2414000 | Loss: 0.060085313978485946\n",
      "Iteration: 2415000 | Loss: 0.060085313978485946\n",
      "Iteration: 2416000 | Loss: 0.060085313978485946\n",
      "Iteration: 2417000 | Loss: 0.060085313978485946\n",
      "Iteration: 2418000 | Loss: 0.060085313978485946\n",
      "Iteration: 2419000 | Loss: 0.060085313978485946\n",
      "Iteration: 2420000 | Loss: 0.060085313978485946\n",
      "Iteration: 2421000 | Loss: 0.060085313978485946\n",
      "Iteration: 2422000 | Loss: 0.060085313978485946\n",
      "Iteration: 2423000 | Loss: 0.060085313978485946\n",
      "Iteration: 2424000 | Loss: 0.060085313978485946\n",
      "Iteration: 2425000 | Loss: 0.060085313978485946\n",
      "Iteration: 2426000 | Loss: 0.060085313978485946\n",
      "Iteration: 2427000 | Loss: 0.060085313978485946\n",
      "Iteration: 2428000 | Loss: 0.060085313978485946\n",
      "Iteration: 2429000 | Loss: 0.060085313978485946\n",
      "Iteration: 2430000 | Loss: 0.060085313978485946\n",
      "Iteration: 2431000 | Loss: 0.060085313978485946\n",
      "Iteration: 2432000 | Loss: 0.060085313978485946\n",
      "Iteration: 2433000 | Loss: 0.060085313978485946\n",
      "Iteration: 2434000 | Loss: 0.060085313978485946\n",
      "Iteration: 2435000 | Loss: 0.060085313978485946\n",
      "Iteration: 2436000 | Loss: 0.060085313978485946\n",
      "Iteration: 2437000 | Loss: 0.060085313978485946\n",
      "Iteration: 2438000 | Loss: 0.060085313978485946\n",
      "Iteration: 2439000 | Loss: 0.060085313978485946\n",
      "Iteration: 2440000 | Loss: 0.060085313978485946\n",
      "Iteration: 2441000 | Loss: 0.060085313978485946\n",
      "Iteration: 2442000 | Loss: 0.060085313978485946\n",
      "Iteration: 2443000 | Loss: 0.060085313978485946\n",
      "Iteration: 2444000 | Loss: 0.060085313978485946\n",
      "Iteration: 2445000 | Loss: 0.060085313978485946\n",
      "Iteration: 2446000 | Loss: 0.060085313978485946\n",
      "Iteration: 2447000 | Loss: 0.060085313978485946\n",
      "Iteration: 2448000 | Loss: 0.060085313978485946\n",
      "Iteration: 2449000 | Loss: 0.060085313978485946\n",
      "Iteration: 2450000 | Loss: 0.060085313978485946\n",
      "Iteration: 2451000 | Loss: 0.060085313978485946\n",
      "Iteration: 2452000 | Loss: 0.060085313978485946\n",
      "Iteration: 2453000 | Loss: 0.060085313978485946\n",
      "Iteration: 2454000 | Loss: 0.060085313978485946\n",
      "Iteration: 2455000 | Loss: 0.060085313978485946\n",
      "Iteration: 2456000 | Loss: 0.060085313978485946\n",
      "Iteration: 2457000 | Loss: 0.060085313978485946\n",
      "Iteration: 2458000 | Loss: 0.060085313978485946\n",
      "Iteration: 2459000 | Loss: 0.060085313978485946\n",
      "Iteration: 2460000 | Loss: 0.060085313978485946\n",
      "Iteration: 2461000 | Loss: 0.060085313978485946\n",
      "Iteration: 2462000 | Loss: 0.060085313978485946\n",
      "Iteration: 2463000 | Loss: 0.060085313978485946\n",
      "Iteration: 2464000 | Loss: 0.060085313978485946\n",
      "Iteration: 2465000 | Loss: 0.060085313978485946\n",
      "Iteration: 2466000 | Loss: 0.060085313978485946\n",
      "Iteration: 2467000 | Loss: 0.060085313978485946\n",
      "Iteration: 2468000 | Loss: 0.060085313978485946\n",
      "Iteration: 2469000 | Loss: 0.060085313978485946\n",
      "Iteration: 2470000 | Loss: 0.060085313978485946\n",
      "Iteration: 2471000 | Loss: 0.060085313978485946\n",
      "Iteration: 2472000 | Loss: 0.060085313978485946\n",
      "Iteration: 2473000 | Loss: 0.060085313978485946\n",
      "Iteration: 2474000 | Loss: 0.060085313978485946\n",
      "Iteration: 2475000 | Loss: 0.060085313978485946\n",
      "Iteration: 2476000 | Loss: 0.060085313978485946\n",
      "Iteration: 2477000 | Loss: 0.060085313978485946\n",
      "Iteration: 2478000 | Loss: 0.060085313978485946\n",
      "Iteration: 2479000 | Loss: 0.060085313978485946\n",
      "Iteration: 2480000 | Loss: 0.060085313978485946\n",
      "Iteration: 2481000 | Loss: 0.060085313978485946\n",
      "Iteration: 2482000 | Loss: 0.060085313978485946\n",
      "Iteration: 2483000 | Loss: 0.060085313978485946\n",
      "Iteration: 2484000 | Loss: 0.060085313978485946\n",
      "Iteration: 2485000 | Loss: 0.060085313978485946\n",
      "Iteration: 2486000 | Loss: 0.060085313978485946\n",
      "Iteration: 2487000 | Loss: 0.060085313978485946\n",
      "Iteration: 2488000 | Loss: 0.060085313978485946\n",
      "Iteration: 2489000 | Loss: 0.060085313978485946\n",
      "Iteration: 2490000 | Loss: 0.060085313978485946\n",
      "Iteration: 2491000 | Loss: 0.060085313978485946\n",
      "Iteration: 2492000 | Loss: 0.060085313978485946\n",
      "Iteration: 2493000 | Loss: 0.060085313978485946\n",
      "Iteration: 2494000 | Loss: 0.060085313978485946\n",
      "Iteration: 2495000 | Loss: 0.060085313978485946\n",
      "Iteration: 2496000 | Loss: 0.060085313978485946\n",
      "Iteration: 2497000 | Loss: 0.060085313978485946\n",
      "Iteration: 2498000 | Loss: 0.060085313978485946\n",
      "Iteration: 2499000 | Loss: 0.060085313978485946\n",
      "Iteration: 2500000 | Loss: 0.060085313978485946\n",
      "Iteration: 2501000 | Loss: 0.060085313978485946\n",
      "Iteration: 2502000 | Loss: 0.060085313978485946\n",
      "Iteration: 2503000 | Loss: 0.060085313978485946\n",
      "Iteration: 2504000 | Loss: 0.060085313978485946\n",
      "Iteration: 2505000 | Loss: 0.060085313978485946\n",
      "Iteration: 2506000 | Loss: 0.060085313978485946\n",
      "Iteration: 2507000 | Loss: 0.060085313978485946\n",
      "Iteration: 2508000 | Loss: 0.060085313978485946\n",
      "Iteration: 2509000 | Loss: 0.060085313978485946\n",
      "Iteration: 2510000 | Loss: 0.060085313978485946\n",
      "Iteration: 2511000 | Loss: 0.060085313978485946\n",
      "Iteration: 2512000 | Loss: 0.060085313978485946\n",
      "Iteration: 2513000 | Loss: 0.060085313978485946\n",
      "Iteration: 2514000 | Loss: 0.060085313978485946\n",
      "Iteration: 2515000 | Loss: 0.060085313978485946\n",
      "Iteration: 2516000 | Loss: 0.060085313978485946\n",
      "Iteration: 2517000 | Loss: 0.060085313978485946\n",
      "Iteration: 2518000 | Loss: 0.060085313978485946\n",
      "Iteration: 2519000 | Loss: 0.060085313978485946\n",
      "Iteration: 2520000 | Loss: 0.060085313978485946\n",
      "Iteration: 2521000 | Loss: 0.060085313978485946\n",
      "Iteration: 2522000 | Loss: 0.060085313978485946\n",
      "Iteration: 2523000 | Loss: 0.060085313978485946\n",
      "Iteration: 2524000 | Loss: 0.060085313978485946\n",
      "Iteration: 2525000 | Loss: 0.060085313978485946\n",
      "Iteration: 2526000 | Loss: 0.060085313978485946\n",
      "Iteration: 2527000 | Loss: 0.060085313978485946\n",
      "Iteration: 2528000 | Loss: 0.060085313978485946\n",
      "Iteration: 2529000 | Loss: 0.060085313978485946\n",
      "Iteration: 2530000 | Loss: 0.060085313978485946\n",
      "Iteration: 2531000 | Loss: 0.060085313978485946\n",
      "Iteration: 2532000 | Loss: 0.060085313978485946\n",
      "Iteration: 2533000 | Loss: 0.060085313978485946\n",
      "Iteration: 2534000 | Loss: 0.060085313978485946\n",
      "Iteration: 2535000 | Loss: 0.060085313978485946\n",
      "Iteration: 2536000 | Loss: 0.060085313978485946\n",
      "Iteration: 2537000 | Loss: 0.060085313978485946\n",
      "Iteration: 2538000 | Loss: 0.060085313978485946\n",
      "Iteration: 2539000 | Loss: 0.060085313978485946\n",
      "Iteration: 2540000 | Loss: 0.060085313978485946\n",
      "Iteration: 2541000 | Loss: 0.060085313978485946\n",
      "Iteration: 2542000 | Loss: 0.060085313978485946\n",
      "Iteration: 2543000 | Loss: 0.060085313978485946\n",
      "Iteration: 2544000 | Loss: 0.060085313978485946\n",
      "Iteration: 2545000 | Loss: 0.060085313978485946\n",
      "Iteration: 2546000 | Loss: 0.060085313978485946\n",
      "Iteration: 2547000 | Loss: 0.060085313978485946\n",
      "Iteration: 2548000 | Loss: 0.060085313978485946\n",
      "Iteration: 2549000 | Loss: 0.060085313978485946\n",
      "Iteration: 2550000 | Loss: 0.060085313978485946\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m y = np.where(data[\u001b[33m\"\u001b[39m\u001b[33mHogwarts House\u001b[39m\u001b[33m\"\u001b[39m] == h, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m).astype(np.uint8)\n\u001b[32m      7\u001b[39m y_train = y.reshape(\u001b[32m1\u001b[39m, m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m w, b = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m w_denorm = w / std\n\u001b[32m     13\u001b[39m b_denorm = b - np.sum(w * mean / std)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[124]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(x, y, alpha, iter, limit)\u001b[39m\n\u001b[32m     11\u001b[39m b = \u001b[32m0\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28miter\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     p = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     loss = -(\u001b[32m1\u001b[39m/m) * np.sum(y*np.log(p) + (\u001b[32m1\u001b[39m-y)*np.log(\u001b[32m1\u001b[39m-p))\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (i % \u001b[32m1000\u001b[39m == \u001b[32m0\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[124]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(w, x, b)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(w, x, b):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     z = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m + b\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m / (\u001b[32m1\u001b[39m + np.exp(-z))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "w_all = np.zeros((n,k))\n",
    "b_all = np.zeros((k,1))\n",
    "\n",
    "for i, h in enumerate(houses):\n",
    "    print(f\"Train for {h} house\")\n",
    "    y = np.where(data[\"Hogwarts House\"] == h, 1, 0).astype(np.uint8)\n",
    "    y_train = y.reshape(1, m)\n",
    "\n",
    "\n",
    "    w, b = train(x_train, y_train)\n",
    "\n",
    "    w_denorm = w / std\n",
    "    b_denorm = b - np.sum(w * mean / std)\n",
    "    print(w)\n",
    "    print(b)\n",
    "    print(\"---------\")\n",
    "\n",
    "    w_all[:, i:i + 1] = w_denorm\n",
    "    b_all[i, 0] = b_denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = predict(w_all, x_test, b_all)\n",
    "answer = np.argmax(y_predict, axis=0)\n",
    "print(answer)\n",
    "print(answer.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = data[\"Hogwarts House\"]\n",
    "\n",
    "output = []\n",
    "for i in answer:\n",
    "    output.append(houses[i])\n",
    "\n",
    "count = 0\n",
    "for i,j in zip(validate, output):\n",
    "    if (i == j): count += 1\n",
    "\n",
    "print(count / 1600 * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
